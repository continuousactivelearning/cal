{"Learn Machine Learning Like a GENIUS and Not Waste Time": [{"content": "so you want to learn machine learning and you somehow ended up here well I've got good news and bad news the bad news I'm not here to sell you some become an ml engineer in 3 months fantasy could it happen sure people also win the lottery the good news I've been exactly where you are about 8 years ago I thought I knew enough Basics to just apply for jobs and learn the rest while working spoiler alert I failed miserably but those failures taught me exactly what works and what doesn't and that's what I'm sharing today I've since taught all of this to hundreds of students in several countries so I think I have a good idea on what works and what doesn't hopefully I can save you months of frustration by showing you the smart way to learn machine learning learning data science was one of the best decisions I ever made and most of you can do it and you will learn some cool stuff on the way that even if you don't become a data scientist or machine learning engineer you will have learned programming how to build apps how to analyze and visualize data you will have strong statistics and research skills and be able to communicate data clearly many amazing job options will be open to you even if you don't become a data scientist but you will have to work hard but what should you work hard on and how do we even start that's what I'm here to tell you learning how to learn before we even touch machine learning let's talk about something crucial learning how to learn why because machine learning and AI like most things in Tech are constantly evolving and what matters isn't just what you know but how quickly you can adapt and learn new things a little secret I actually suck at at programming and algorithms but I am really good at learning new stuff here's why this matters specifically for machine learning technology changes fast new platforms and Frameworks drop constantly and new papers come out daily what's hot today might be obsolete tomorrow problem solving is everything machine learning isn't about memorizing algorithms it's about understanding data and patterns about breaking down complex problems and finding Creative Solutions confidence AKA don't get overwhelmed or scared of big problems people who know how to learn and problem solve don't get paralyzed when faced with a new big problem they develop a strategy for how to look at a new problem and break it down into manageable problems they have faced before they know how to look up Solutions and find tools necessary to solve new problems they adapt more quickly when Tech changes efficiency if you know how to learn you won't waste time on unnecessary things time is money learn what you actually need to get where you want to be there's no one size fits all solution for learning something it depends on your style of learning but also on your goals not everyone needs to learn everything so how do you learn how to learn this one you kind of have to figure out for yourself because what works for one person doesn't necessarily work for the next some people learn well with graphs and diagrams others with text others maybe with voice notes some people need to understand the theory before applying it others need to jump right in and use an algorithm before asking what it actually does in this video I will try to show you what worked for me while giving you resources that I believe will get you there as quickly as possible I will just mention a principle that has helped me a lot throughout my career the the Paro principle sometimes called 8020 principle it says that 80% of the results come from 20% of the effort constantly ask yourself why am I doing this is this actually getting me where I want to be or can I do something more useful with my time well the answer to this question isn't always the same for everyone I will try to now give you the 20% of the work that would have gotten me 80% of the way to becoming a data scientist adapt as needed but where do I start now let's build your machine Learning Foundation the right way here's your road map python while the next skill is at least as important I would start with learning python the main reason is that you will get a feeling of achievement fairly quickly and python is super simple why python python is the main language of data analytics data science and machine learning while also being a full-fledged programming language allowing you to write scripts build apps and websites and much more python will allow you to actually start writing real code within days without having to learn super complicated computer science Concepts like pointers memory allocation and garbage collection also with python you will be able to get a job as a programmer or data analyst or web developer even if you don't learn all the hard machine learning stuff I suggest you first install jupyter notebooks as they make learning much easier and jupyter notebooks are also a core tool for data analysts and data scientists all over the world then learn about these Core Concepts programming fundamentals basic syntax indentation rules comments and so on variables math if else Loops printing data types like strings ins floats booleans lists dictionaries functions classes and objects modules packages and importing do a pandas tutorial pandas is Python's primary data manipulation Library built for handling tabular data through data frame objects imagine it as Excel spreadsheets on steroids it will be your main tool for data analysis cleaning and transformation with powerful functions for merging reshaping and analyzing data the library strength lies in combining the power of numpy arrays with spreadsheet like functionality and SQL database like joints it also comes with built-in plotting functionality built on top of Python's powerful met plot lib libraries pandas is a true data analysis Powerhouse if you truly Master pandas you will excel at most data analysis positions in the world also because exploratory data analysis and data preparation are about 60 to 80% of a data scientist job it will also lay the foundation for that 8020 principle remember your First Data analysis project so before you get into any machine learning I would take the time here to work on an actual project to deepen your python pandas and data analysis knowledge as I mentioned in my previous videos real projects beat tutorials at developing a good data scientist find some data you want to analyze maybe from one of your old jobs or school maybe you can export some data from your favorite health tracker or ask some friends if they have some data they want analyzed or maybe download public data from the government the World Bank or a nonprofit any topic you're interested in it could be economics Sports politics video games the board games this last one was a passion of one of my former students work on importing the data into pandas clean up the data make the units uniform decide what to do about missing data and outliers plot the different variables look at correlations between variables and come up with some hypothesis about the data and test them by making more plots turn your results into a slideshow with nice graphs that tell a story that you can present to friends and family Pro tip Jupiter notebooks with data and plots can be turned directly into a slideshow this will also be the first project for your port portfolio which you can show when applying for jobs as a data analyst essential math for machine learning this might be the part that most of you fear the most but I think it is the most important part for anyone wanting to learn machine learning you should take this seriously you don't need to be a math genius or know about all of math to become good at machine learning but you need to really understand the Core Concepts from the areas I'm about to mention for more details on math for machine learning check out my video on the topic basic statistics and probability this for me is the most important Branch as a data analyst and data scientist now there are many online resources for statistics but I highly suggest taking the Con Academy statistics and probability course this course is completely free and is the one I took when I prepared for my first job as a data scientist the full course is probably around 50 hours of content so if you have prior math knowledge you probably won't spend more than 100 hours on this but it might take you longer that's around 2 3 weeks of full-time self-study more if much of this is completely new to you but please take the time to do this it will make everything that follows so much easier and save you much more than 100 hours of headaches later on ideally while you learn new Concepts here you go to your data set from the previous data analysis project phase and try to apply them there to deepen your intuition linear algebra fundamentals while also important linear algebra for machine learning is much more about learning some tools and rules this should be much quicker than learning probability and statistics Concepts the main thing you want to learn is how to operate with vectors and matrices and learn what the different operations mean this is more about mathem iCal tools and notations than Concepts I think learning this will take about a quarter to a third of the time it took you to learn the statistics Concepts so one or two weeks of studying should be enough for people with prior math knowledge I will also leave the link to the Khan Academy linear algebra course in the description calculus here again it's about learning some tools but also understanding what derivatives are conceptually and how they help in optimization problems you should really understand how functions and their derivatives work and know the basic rules of differentiation like the chain rule I would again calculate with one or two weeks if you have prior math knowledge I will also leave a con Academy Link in the description Pro tip you need working knowledge not a math PhD focus on intuition over proofs spend most your time on statistical concepts for linear algebra and calculus focus on learning the tools like Matrix operations and how to take the derivative of a function the core machine learning Concepts and algorithms now here's where many people mess up they jump straight to Deep learning but that's a mistake in my opinion you should spend most of your time on simple algorithms the reasons for that are manifold and discussed in my previous videos but basically many problems don't require complicated solution simple algorithms like linear regression are quicker to run they're more generalizable more interpretable and easier to learn from and communicate and more importantly these algorithms form the basis for the more complicated algorithms like neural networks so truly understanding them will help you understand the more complicated algorithms better too check out my video on machine learning algorithms but basically before getting into neural networks or even svm make sure you understand how linear regression and logistic regression work then look at decision trees and Ensemble algorithms like random forests and gradient boosting I learned most of these topics from the book an introduction to statistical learning the majority of you will prefer learning from videos so just watch the Youtube video series about this book by the authors themselves completely for free on YouTube I will leave a link in the description all the videos together are about 20 hours but since you will want to pause and take notes and read up on certain Concepts I think this will be another 100 hours or so of study time so that should be another two or more weeks of full-time self-study all these numbers are estimates as everyone learns at different speeds do a scikit learn tutorial scit learn is the number one machine learning library in the world for basic machine learning algorithms you can do a basic sklearn tutorial in a day or two and the good thing is that the simple and consistent syntax makes it such that once you know how to use the library for one algorithm you know how to use it for any algorithm as long as you know what algorithm is meant for what which you now know because you just learned it pyit learn also comes with great documentation and toy data sets to play around with I suggest you start using psyit learn while you are learning about the algorithms in the statistical learning course the genius move while you learn about the theory behind new algorithms for example going through the statistical learning course and starting with linear regression Implement and use the algorithm in the following three three ways implemented from scratch using basic python implemented using scikit learn using a toy data set then use both your own implementation and the syit learn toolkit to try out the algorithm on a real data set that you have prepared yourself now there's a common Pitfall that many beginners get stuck in tutorial hell it's where you essentially just keep following tutorials without striking out on your own and actually building something most learning comes from the trial and error of building an application so if you always follow a tutorial you get Stu at a basic level how do you not get stuck there do just one or two tutorials per area Max and then work on a real project your first machine learning project here you can either continue with your data analysis project from before or find a new more interesting data set for a machine learning project but don't forget to still use pandas to do an exploratory data analysis to prepare your data for modeling and form hypothesis about your data more often than not the goal of a machine learning project will be to predict some variable from other variables research the industry of your project a bit look at the data and make some hypothesis about what might influence your target variable either based on intuition about the industry or from looking at correlations and Scatter Plots of different variables design new features based on your knowledge of the problem then start modeling but start with simple algorithms like linear regression logistic regression and decision trees then move on to more complex algorithms like svm random forests or gradient boosting note how as complexity increases accuracy usually increases but interpretability decreases your goal is usually to find a sweet spot also don't forget over fitting as you increase in model complexity keep validation and test sets aside before starting to model and compare your models using the test set at the very end many times the more complex algorithms don't look as good anymore once you use the final test set it might be a good idea to work with data sets that have been published on sites like kaggle to then compare your Solutions and accuracies to other people's Solutions and get an idea of how well your models are in comparison to others but don't get frustrated a lot of people on kaggle are professionals with years of experience if you get anywhere close in accuracy you should be happy don't know what to work on you can start with a tutorial but instead of following it directly after building the core features add some features change some features swap out the data set and try to break your code and then fix it this is one of the best ways to learn while not getting stuck in tutorial hell collaborate and share your projects with others learning ML and isolation is the slowest way to learn instead find coding buddies to work on a project with present your work to friends and family or post it publicly on GitHub or in machine learning communities have someone more advanced than you give you feedback this will speed up your learning 10 times don't know anyone to work on a project with participate in a hackathon or write to people with similar interests on kaggle GitHub Discord Reddit LinkedIn Etc the connections you form this way will not only help you learn better but boost your career in unexpected ways check out my most recent video to learn more about the importance of networking and data science Advanced topics only now should you look at more advanced topics deep learning architectures cnns for computer vision RNN for sequential data or Transformers for NLP Advanced optimization techniques model deployment strategies and the latest research papers remember learn these by need not by fomo you don't need to know everything just learn these techniques if they are important to your project here some dos and don'ts don't don't get stuck in tutorial hell don't try to memorize everything don't learn in isolation don't chase every new trend don't copypaste code without understanding don't try to learn every new fancy tool or research paper instead build real projects focus on understanding share your progress join communities Master fundamentals first Implement from scratch learn by doing if you found this video helpful share it with someone who you think might also like it and get started on one of the tutorials in the description or on this very Channel also consider liking the video and subscri subcribing to be notified about similar content in the future thanks for watching"}], "5 Beginner AWS Cloud Projects To Get You Hired (2025)": [{"content": "hey everyone this is Lucy and in this video I'll be walking you through five beginner friendly AWS Cloud projects now as I've said on this channel over and over again the best way to build your Hands-On skills with AWS is by creating a project certifications are a great starting point but to really bridge that gap between your theoretical knowledge and what's required to Le a job in the cloud it's important for you to think about how you can use multiple AWS Services together to build a solution this solution could be a static website a mobile application or even a chat bot that can respond to simple queries the possibilities are endless but the problem is how do you get started should you read through hundreds of pages of documentation first or should you just jump straight into it and hope for the best well to be honest there's no one correct approach when starting a cloud project Some people prefer to follow a step-by-step tutorial While others might want the flexibility to build something without the exact instructions already provided to them my personal preference and what I recommend to beginners is to follow guided tutorials for your first few Cloud projects more importantly learn how to document them and speak about your projects during Cloud interviews and so over the next few months I'll be releasing a series of videos to help you build AWS Cloud projects at three different skill levels beginner intermediate and advanced if you want to stay updated make sure you subscribe to the channel and turn on notifications all right let's just dive straight into it the first beginner Cloud project is to build a daily task schedule application using party rock this platform allows you to create an application by simply describing what you want making it a great choice for beginners looking to build AI applications to get started visit party Rock's website and create an account select the build your own app option and this will open up an interface for you to create your own application now you might be wondering what can party rock actually be used for well as cheesy as it sounds the possibilities are endless you can create applications for your own personal use such as a to-do list or Resume Builder you could also create an application for your workplace such as a project management tool with Party Rock people have even built things like motivational quote generators and personality quizzes if you'd like to learn how to build a daily task schedule application I've included the full tutorial in the description below I've also created a guide book with the complete step-by-step instructions to all five projects in this video so feel free to check that out as well but yeah here are the overall steps you need to take if you'd like to build it out so start by entering a detailed prompt that describes the daily task schedule application you envision make sure you're descriptive enough so that partyy rock can understand exactly what you want once you submit your prompt the AI gets to work creating an application that fits your needs after the application is generated you'll be introduced to the customization process this gives you the option to add widgets like user input static text image generation and even a chatbot you can also change the layout of your application to match your brand or personal preferences once you finalize your application you can publish it and share it with others the estimated time for this project is around 15 to 20 minutes but of course it all depends on how complex you want your application to be be and how many features you'd like the cost for this project is $0 since party rock is offering all users a free trial to their service all right project number two is to build an image labels generator using Amazon recognition now this project is another fun one because we'll be processing images and labeling them for example if you have a photo of a cat amaz recognition will be able to identify what it is and label the image as a cat as mentioned I have the complete guide book for all five projects in the description below but here's the architectural diagram and the overall steps you'll need to take to build out the project so the Journey Begins with setting up an Amazon S3 bucket which will serve as the repository for the images you wish to analyze next you'll create an IM am roll and make sure Amazon recognition and S3 have access to each other after that you'll need to install the AWS C and write some code to use the detect labels option for images and finally use a python Library called map plot Li to visualize labels and add bounding boxes to items identified in the images this is the result of what one of your images could look like you could see that one use case of Amazon recognition could be in a smart surveillance system to recognize suspicious objects and activities on the road other potential use cases include identifying products in a store for inventory management analyzing customer behavior on retail stores and providing accessibility options to those who are visually impaired as you can probably tell Amazon recognition is a pretty useful service that can be applied in many Industries so I would recommend building a project to get some experience with it and to see it in action the project will take you about 20 minutes to build and Falls within the free tier now before we move on to the next project I'd like to share with you a helpful tool that will significantly help you on your journey of building AWS Cloud projects some of you might have heard of M before they're a platform that offers an innovation workspace for teams to collaborate well miror has recently released a really cool feature called AWS Cloud view AWS Cloud view allows you to instantly visualize your Cloud architecture by directly importing data from your aw account creating a clear view in just 20 seconds as you all know architectural diagrams are a very important part of documenting every cloud project so instead of manually creating your own diagrams you can create them with the help of miror here's how you can use mirror's edu as Cloud view first either link a cross account roll or upload a Json file containing data about your AWS resources next follow the instructions to select the relevant account and region you wish to visualize and finally sit back while they generate the diagram here's an example AWS diagram generated through Cloud view if you're looking to present your Cloud projects professionally or just want a faster way to create Cloud architectures AWS Cloud view in Miro is a complete Game Changer I'll leave a link to it in the description below moving on to the third project this one is to develop a text narrator using Amazon poly now Amazon poly is a service that turns text to speech allowing you to create an application that can talk now this is great when you don't feel like reading something and just want to listen to the audio version one example is is converting a blog post into an audio book here's the architectural diagram for the project and the steps you need to take so firstly find a piece of text that you'd like spoken out this could be anything from books and articles to newsletters and scripts next create an AWS Lambda function that acts as a bridge between your text and Amazon poly after that customize the voice in Amazon poly to match the tone and style of your content adjusting parameters like pitch and speed now even though this project may seem simple it does require a good understanding of AWS services and how to integrate them it also gives you a taste of how powerful text to speech capabilities can be in enhancing customer experience the estimated time to complete this project is 20 minutes and it also falls within the free tier the fourth Cloud project to help you get highed in 2024 is to build a language translation Bard this project uses three AWS Services AWS Lambda Amazon Lex and Amazon translate so for example if you want to translate a word or sentence into another language all you have to do is type into the chat bot and it will output the translation sounds straightforward enough right here's the architectural diagram and the steps you need to take firstly create a chatbot in Amazon Lex and Define clear user intents next specify utterances or phrases that users might say to interact with your Bot once that's done Define slots within the intents such as language or text to capture the specific information needed for the translation after that we're going to need a Lambda function that takes the slot data and perform a translation using Amazon trans translate and finally we'll integrate the Lambda function back into the Amazon Lex chatbot and deliver the translation smoothly to the user some potential use cases of an Amazon Lex translation bot include assisting businesses in communicating with International clients and helping Travelers communicate with locals from different languages you might be wondering why can't I use a translation app that has already been made well the answer is that businesses often require customized translation services especially when dealing with technical terms or industry specific language by using Amazon Lex you have the flexibility to tailor your Bot based on your specific needs overall building a language translation bot not only showcases your knowledge of using AWS services but is also a skill set for companies looking to build chatbots this project will take you about 1 to 2 hours to build and can be done for free through the aeds free tier the fifth and final project for today is to deploy a bucket list tracker application on AWS amplify this project once you build it out will help you keep a track of all the things you want to do in life you can enter bucket list items and delete them once they're complete now you can see that the architectural diagram for this project looks a bit more complex than the other ones and that's because we'll need multiple ads services to build this application the first step is to build your application with react focusing on userfriendly design and functionality that allows users to manage the bucket list items effectively next initialize a GitHub repo and connect your local development environment to GitHub after that use AWS amplifier to host your front end and Implement amplifier authentication to to add user authentication features like login and sign up once that's done develop the back end using AWS appsync and a graph Cur API for efficient data handling you can then integrate it with Dynamo DB for data storage finally deploy your application on AWS amplify test it out and make any necessary adjustments like all the other projects mentioned in this video this one Falls within the free tier however this final project will take you a bit longer to build around 1 and 1/2 to 2 hours and there you have it five AWS Cloud projects to help you get handson get hired and Advance your career if you found this video helpful please remember to give it a like and let me know in the comments which project was your favorite I'd also recommend checking out this video I made on how to document your AWS Cloud projects thanks so much for watching and I'll see you soon bye for now"}], "Justice: What's The Right Thing To Do? Episode 01 \"THE MORAL SIDE OF MURDER\"": [{"content": "Funding for this program is provided by: Additional funding provided by This is a course about Justice and we begin\nwith a story suppose you're the driver of a trolley car, and your trolley car is hurdling down\nthe track at sixty miles an hour and at the end of the track you notice\nfive workers working on the track you tried to stop but you can't your brakes don't work you feel desperate because you know that if you crash into these five workers they will all die let's assume you know that for sure and so you feel helpless until you notice that there is off to the right a side track at the end of that track there's one worker working on track you're steering wheel works so you can turn the trolley car if you want to onto this side track killing the one but sparing the five. Here's our first question what's the right thing to do? What would you do? Let's take a poll, how many would turn the trolley car onto the side track? How many wouldn't? How many would go straight ahead keep your hands up, those of you who'd go straight\nahead. A handful of people would, the vast majority\nwould turn let's hear first now we need to begin to investigate the reasons\nwhy you think it's the right thing to do. Let's begin with\nthose in the majority, who would turn to go onto side track? Why would you do it, what would be your reason?"}, {"content": "Who's willing to volunteer a reason? Go ahead, stand up. Because it can't be right to kill five people\nwhen you can only kill one person instead. it wouldn't be right to kill five if you could kill one person instead that's a good reason that's a good reason who else? does everybody agree with that reason? go ahead. Well I was thinking it was the same reason it was on 9/11 we regard the people who flew the plane who flew the plane into the Pennsylvania field as heroes because they chose to kill the people on the\nplane and not kill more people in big buildings. So the principle there was the same on 9/11 it's tragic circumstance, but better to kill one so that five can\nlive is that the reason most of you have, those\nof you who would turn, yes? Let's hear now from those in the minority those who wouldn't turn. Well I think that same type of mentality that\njustifies genocide and totalitarianism in order to save one type of race you\nwipe out the other. so what would you do in this case? You would to avoid the horrors of genocide you would crash into the five and kill them? Presumably yes."}, {"content": "okay who else?"}, {"content": "That's a brave answer, thank you. Let's consider another trolley car case and see whether those of you in the majority want to adhere to the principle, better that one should die so that five\nshould live. This time you're not the driver of the trolley\ncar, you're an onlooker standing on a bridge overlooking a trolley car track and down the track comes a trolley car at the end of the track are five workers the brakes don't work the trolley car is about to careen into the\nfive and kill them and now you're not the driver you really feel helpless until you notice standing next to you leaning over the bridge is it very fat man. And you could give him a shove he would fall over the bridge onto the track right in the way of the trolley car he would die but he would spare the five. Now, how many would push the fat man over the bridge? Raise your hand. How many wouldn't? Most people wouldn't. Here's the obvious question, what became of the principle better to save five lives even if it means\nsacrificing one, what became of the principal that almost everyone endorsed in the first case I need to hear from someone who was in the\nmajority in both cases is how do you explain the difference between\nthe two? The second one I guess involves an\nactive choice of  pushing a person and down which I guess that that person himself would otherwise not \nhave been involved in the situation at all and so to choose on his behalf I guess to  involve him in something that he otherwise would\nhave this escaped is I guess more than what you have in the first case where the three parties, the driver and the two sets of workers are already I guess in this situation. but the guy working, the one on the track\noff to the side he didn't choose to sacrifice his life any\nmore than the fat guy did, did he? That's true, but he was on the tracks. this guy was on the bridge. Go ahead, you can come back if you want. Alright, it's a hard question but you did well you did very well it's a\nhard question. who else can find a way of reconciling the reaction of the majority in these two cases? Yes? Well I guess in the first case where you have the one worker and the five it's a  choice between those two, and you have to  make a certain choice and people are going to die \nbecause of the trolley car  not necessarily because of your direct actions. The trolley car is a runway, thing and you need to make in a split second choice whereas pushing the fat man over is an actual\nact of murder on your part you have control over that whereas you may not have control over the trolley car. So I think that it's a slightly different situation."}, {"content": "Alright who has a reply? Is that, who has a reply to that? no that was good, who has a way who wants to reply? Is that a way out of this? I don't think that's a very good reason because\nyou choose either way you have to choose who dies\nbecause you either choose to turn and kill a person which is an act of conscious thought to turn, or you choose to push the fat man  over which is also an active conscious action so either way you're making a choice. Do you want to reply? Well I'm not really sure that that's the case, it just still\nseems kind of different, the act of actually pushing someone over onto the tracks and killing them, you are actually killing him yourself, you're pushing\nhim with your own hands you're pushing and  that's different than steering something that is going to\ncause death into another...you know it doesn't really sound right saying it now when I'm up here. No that's good, what's your name?"}, {"content": "Andrew. Andrew and let me ask you this question Andrew, suppose standing on the bridge next to the fat man I didn't have to push him, suppose he was standing over a trap door that I could open by turning\na steering wheel like that would you turn it? For some reason that still just seems more  more wrong. I mean maybe if you just accidentally like leaned into\nthis steering wheel or something like that or but,  or say that the car is  hurdling towards a switch that will drop the trap then I could agree with that. Fair enough, it still seems  wrong in a way that it doesn't seem wrong in the\nfirst case to turn, you say An in another way, I mean in the first situation you're\ninvolved directly with the situation in the second one you're an onlooker as well. So you have the choice of becoming involved\nor not by pushing the fat man. Let's forget for the moment about this case, that's good, but let's imagine a different case. This time\nyour doctor in an emergency room and six patients come to you they've been in a terrible trolley car wreck five of them sustained moderate injuries one\nis severely injured you could spend all day caring for the one severely injured victim, but in that time the five would die, or you could\nlook after the five, restore them to health, but during that time the one severely injured person would die. How many would save  the five now as the doctor? How many would save the one? Very few people, just a handful of people. Same reason I assume, one life versus five. Now consider another doctor case this time you're a transplant surgeon and you have five patients each in desperate\nneed of an organ transplant in order to survive on needs a heart one a lung, one a kidney,  one a liver and the fifth a pancreas. And you have no organ donors you are about to see you them die and then it occurs to you that in the next room there's a healthy guy who came in for a checkup. and he is you like that and he's taking a nap you could go in very quietly yank out the five organs, that person would\ndie but you can save the five. How many would do it? Anyone? How many? Put your hands up if you would do it. Anyone in the balcony? You would? Be careful don't lean over too much How many wouldn't? All right. What do you say, speak up in the balcony, you\nwho would yank out the organs, why? I'd actually like to explore slightly alternate possibility of just taking the one of the five he needs an organ who dies first and using their four healthy organs to save the other\nfour That's a pretty good idea. That's a great idea except for the fact that you just wrecked the philosophical point. Let's step back from these stories and these arguments to notice a couple of things about the way the arguments have began to unfold. Certain moral principles have already begun to emerge from the discussions we've had and let's consider what those moral principles look like the first moral principle that emerged from the \ndiscussion said that the right thing to do the moral thing to do depends on the consequences that will result from your action at the end of the day better that five should live even if one must die. That's an example of consequentialist moral reasoning. consequentialist moral reasoning locates morality\nin the consequences of an act. In the state of the  world that will result  from the thing you do but then we went a little further, we considered\nthose other cases and people weren't so sure  about consequentialist moral reasoning when people hesitated to push the fat man over the bridge or to yank out the organs of the innocent patient people gestured towards reasons having to do with the intrinsic quality of the act itself. Consequences be what they may. People were reluctant people thought it was just wrong categorically wrong to kill a person an innocent person even for the sake of saving five lives, at least these people thought that in the second version of each story we reconsidered so this points a second categorical way of thinking about moral reasoning categorical moral reasoning locates morality\nin certain absolute moral requirements in certain categorical duties and rights regardless of the consequences. We're going to explore in the days and weeks to come the contrast\nbetween consequentialist and categorical moral principles. The most influential example of consequential moral reasoning is utilitarianism,\na doctrine invented by Jeremy Bentham, the eighteenth century English\npolitical philosopher. The most important philosopher of categorical moral reasoning is the eighteenth century German philosopher\nEmmanuel Kant. So we will look at those two different modes of moral reasoning assess them and also consider others. If you look at the syllabus, you'll notice\nthat we read a number of great and famous books. Books by Aristotle John Locke Emanuel Kant, John Stuart Mill, and others. You'll notice too from the syllabus that\nwe don't only read these books, we also all take up contemporary political and legal controversies\nthat raise philosophical questions. We will debate equality and inequality, affirmative action, free speech versus hate speech, same sex marriage, military conscription, a range of practical questions, why not just to enliven these abstract and distant\nbooks but to make clear to bring out what's at stake\nin our everyday lives including our political lives, for philosophy. So we will read these books and we will debate these issues and we'll see how each informs and\nilluminates the other. This may sound appealing enough but here I have to issue a warning, and the warning is this to read these books in this way, as an exercise in self-knowledge, to read them in this way carry certain risks risks that are both personal and political, risks that every student of political philosophy have known. These risks spring from that fact that philosophy teaches us and unsettles us by confronting us with what we already know. There's an irony the difficulty of this course consists in the\nfact that it teaches what you already know. It works by taking what we know from familiar unquestioned settings, and making it strange. That's how those examples worked worked the hypotheticals with which we began with their\nmix of playfulness and sobriety. it's also how these philosophical books work. Philosophy  estranges us from the familiar not by supplying new information but by inviting and provoking a new way of seeing but, and here's the risk, once the familiar turns strange, it's never quite the same again. Self-knowledge is like lost innocence, however unsettling you find it, it can never be unthought or unknown what makes this enterprise difficult but also riveting, is that moral and political philosophy is a story and you don't know where this story will lead\nbut what you do know is that the story is about you. Those are the personal risks, now what of the political risks. one way of introducing of course like this would be to promise you that by reading these books and debating these issues you will become a better more responsible\ncitizen. You will examine the presuppositions of\npublic policy, you will hone your political judgment you'll become a more effective participant\nin public affairs but this would be a partial and misleading promise political philosophy for the most part hasn't\nworked that way. You have to allow for the possibility that political philosophy may make you a worse\ncitizen rather than a better one or at least a worse citizen before it makes you a better one and that's because philosophy is a distancing even debilitating activity And you see this going back to Socrates there's a dialogue, the Gorgias in which one of Socrates\u2019 friends Calicles tries to talk him out of philosophizing. calicles tells Socrates philosophy is a pretty toy if one indulges in it with moderation at\nthe right time of life but if one pursues it further than one should\nit is absolute ruin. Take my advice calicles says, abandon argument learn the accomplishments of active\nlife, take for your models not those people who spend\ntheir time on these petty quibbles, but those who have a good livelihood and reputation and many other blessings. So Calicles is really saying to Socrates quit philosophizing, get real go to business school and calicles did have a point he had a point because philosophy distances us from conventions from established assumptions and from settled beliefs. those are the risks, personal and political and in the face of these risks there is a\ncharacteristic evasion, the name of the evasion is skepticism. It's\nthe idea well it goes something like this we didn't resolve, once and for all, either the cases or the principles we were\narguing when we began and if Aristotle and Locke and Kant and Mill haven't solved these questions\nafter all of these years who are we to think that we here in Sanders Theatre over the\ncourse a semester can resolve them and so maybe it's just a matter of each person having his or her own principles\nand there's nothing more to be said about it no way of reasoning that's the evasion. The evasion of skepticism  to which I would offer the following reply: it's true these questions have been debated for a very\nlong time but the very fact that they have reoccurred and persisted may suggest that though they're impossible in one sense their unavoidable in another and the reason they're unavoidable the reason they're inescapable is that we live\nsome answer to these questions every day. So skepticism, just throwing up their hands\nand giving up on moral reflection, is no solution Emanuel Kant described very well the problem with skepticism\nwhen he wrote skepticism is a resting place for human reason  where it can reflect upon its dogmatic wanderings but it is no dwelling place for permanent settlement. Simply to acquiesce in skepticism, Kant wrote, can never suffice to overcome the restless\nof reason. I've tried to suggest through theses stories\nand these arguments some sense of the risks and temptations of the perils and the possibilities I would\nsimply conclude by saying that the aim of this course is to awaken the restlessness of reason and to see where it might lead thank you very much. Like, in a situation that desperate, you have to do what you have to do to survive. You have to do what you have to do you? You've gotta do What you  gotta do. pretty much,  If you've been going nineteen days without any food someone has to take the sacrifice, someone has to make the sacrifice  \nand people can survive. Alright that's good, what's your name?"}, {"content": "Marcus."}, {"content": "Marcus, what do you say to Marcus? Last time we started out last time with some stores with some moral dilemmas about trolley cars and about doctors and healthy patients vulnerable to being victims of organ transplantation we noticed two things about the arguments we had one had to do with the way we were arguing it began with our judgments in particular cases we tried to articulate the reasons or the\nprinciples lying behind our judgments and then confronted with a new case we found ourselves re-examining those principles revising each in the light of the other and we noticed the built-in pressure to try\nto bring into alignment our judgments about particular cases and the principles we would endorse on reflection we also noticed something about the substance\nof the arguments that emerged from the discussion. We noticed that sometimes we were tempted\nto locate the morality of an act in the consequences in the results, in the state of the world that\nit brought about. We called is consequentialist moral reason. But we also noticed that in some cases we weren't swayed only  by the results sometimes, many of us felt, that not just consequences but also the intrinsic\nquality or character of the act matters morally. Some people argued that there are certain things\nthat are just categorically wrong even if they bring about a good result even if they save five people at the cost of one life. So we contrasted consequentialist moral principles with categorical ones. Today and in the next few days we will begin to examine one of the\nmost influential versions of consequentialist moral theory and that's the philosophy of utilitarianism. Jeremy Bentham, the eighteenth century English political philosopher gave first the first clear systematic expression to the utilitarian moral theory. And Bentham's idea, his essential idea is a very simple one with a lot of  morally intuitive appeal. Bentham's idea is the following the right thing to do the just thing to do it's to maximize utility. What did he mean by utility? He meant by utility the balance of pleasure over pain, happiness over suffering. Here's how we arrived  at the principle of maximizing utility. He started out by observing that all of us all human beings are governed by two sovereign masters, pain and pleasure. We human beings like pleasure and dislike pain and so we should base morality whether we are thinking of what to do in our own lives or whether as legislators or citizens we are thinking about what the law should be, the right thing to do individually or collectively is to maximize, act in a way that maximizes the overall level of happiness. Bentham's utilitarianism is sometimes summed\nup with the slogan the greatest good for the greatest number. With this basic principle of utility on hand, let's begin to test it and to examine it by turning to another case another story but this time not a hypothetical story, a real-life story the case of the Queen versus Dudley and Stephens. This was a nineteenth-century British law case that's famous and much debated in law schools. Here's what happened in the case I'll summarize the story and then I want to hear how you would rule imagining that you are the jury. A newspaper account of the time described the background: A sadder story of disaster at sea was never told than that of the survivors of the yacht Mignonette. The ship foundered in the south Atlantic thirteen hundred miles from the cape there were four in the crew, Dudley was the captain Stephens was the first mate Brooks was a sailor, all men of excellent character, or so the newspaper account tells us. The fourth crew member was the cabin boy, Richard Parker seventeen years old. He was an orphan he had no family and he was on his first long voyage at sea. He went, the news account tells us, rather against the advice of his friends. He went in the hopefulness of youthful ambition thinking the journey would make a man of him. Sadly it was not to be, the facts of the case were not in dispute, a wave hit the ship and the Mignonette went down. The four crew members escaped to a lifeboat the only food they had were two cans of preserved turnips no fresh water for the first three days they ate nothing on the fourth day that opened one of the cans of\nturnips and ate it. The next day they caught a turtle together with the other can of turnips  the turtle enabled them to subsist for the next few days and then for eight days they had nothing no food no water. Imagine yourself in a situation like that what would you do? Here's what they did by now the cabin boy Parker is lying at the\nbottom of the lifeboat in a corner because he had drunk sea water against the advice of the others and he had become ill and he appeared to be dying so on the nineteenth day Dudley, the captain, suggested that they should all have a lottery. That they should all draw lots to see who would die to save the rest. Brooks refused he didn't like the lottery idea we don't know whether this was because he didn't want to take that chance\nor because he believed in categorical moral principles but in any case no lots were drawn. The next day there was still no ship in sight so a Dudley told Brooks to avert his gaze  and he motioned to Stephens that the boy Parker had better be killed. Dudley offered a prayer he told a the boy his time had come and he killed him with a pen knife stabbing him in the jugular vein. Brooks emerged from his conscientious objection\nto share in the gruesome bounty. For four days the three of them fed on the body and blood\nof the cabin boy. True story. And then they were rescued. Dudley describes their rescue in his diary with staggering euphemism, quote: \"on the twenty fourth day as we were having our breakfast a ship appeared at last.\" The three survivors were picked up by a German ship. They were taken back to Falmouth in England where they were arrested and tried Brooks turned state's witness Dudley and Stephens went to trial. They didn't\ndispute the facts they claimed they had acted out of necessity that was their defense they argued in effect better that one should die so that three could survive the prosecutor wasn't swayed by that argument he said murder is murder and so the case went to trial. Now imagine\nyou are the jury and just to simplify the discussion put aside the question of law, and let's assume that you as the jury are charged with deciding whether what they did was morally permissible or not. How many would vote not guilty, that what they did was morally\npermissible? And how many would vote guilty what they did was morally wrong? A pretty sizable majority."}, {"content": "Now let's see what people's reasons are, and let me\nbegin with those who are in the minority. Let's hear first from the defense of Dudley and Stephens. Why would you morally exonerate them? What are your reasons? I think it's I think it is morally reprehensible but I think that there's a distinction between\nwhat's morally reprehensible what makes someone legally accountable in other words the night as the judge said\nwhat's  always moral isn't necessarily against the law and while I don't think that\nnecessity justifies theft or murder any illegal act,  at some point your degree of necessity does\nin fact exonerate you form any guilt. ok. other defenders, other voices for the defense? Moral justifications for what they did? yes, thank you I just feel like  in a situation that desperate you have to do\nwhat you have to do to survive. You have to do what you have to do ya, you gotta do what you gotta do, pretty much. If you've been going nineteen days without any food you know someone just has to take the sacrifice\nhas to make sacrifices and people can survive and furthermore from that let's say they survived and then they become productive\nmembers of society who go home and then start like a million charity organizations and this and that and this and that,\nI mean they benefit everybody in the end so I mean I don't know what they did afterwards, I mean\nthey might have gone on and killed more people but whatever. what? what if they were going home and turned out to be assassins? What if they were going home and turned out to be assassins? You would want to know who they assassinated. That's true too, that's fair I would wanna know who they assassinated. alright that's good, what's your name?"}, {"content": "Marcus. We've heard a defense a couple voices for the defense now we need to hear from the prosecution most people think what they did was wrong, why? One of the first things that I was thinking was, oh well if they  \nhaven't been eating for a really long time,  maybe then they're mentally affected that could be used for the defense,  a possible argument that oh, that they weren't in a proper state of mind, they were making decisions that they otherwise wouldn't be making, and if that's an  \nappealing argument that you have to be in an altered mindset to do something\nlike that it suggests that people who find that argument convincing do you think that they're acting immorally. But I want to know what you think you're defending you k\n0:37:41.249,0:37:45.549\nyou voted to convict right? yeah\n I don't think that they acted in morally  appropriate way. And why not? What do you say,\nHere's Marcus he just defended them, he said, you heard what he said, yes I did yes that you've got to do what you've got to do in a\ncase like that. What do you say to Marcus? They didn't, that there is no situation that would allow human\nbeings to take  the idea of fate or the other people's\nlives into their own hands that we don't have that kind of power. Good, okay thanks you, and what's your name?"}, {"content": "Britt? okay. who else? What do you say? Stand up I'm wondering if Dudley and Stephens had asked for Richard Parker's  \nconsent in, you know, dying,  if that would would that exonerate them from an act of murder, and if so is that still morally\njustifiable? That's interesting, alright consent, now hang on, what's your name? Kathleen."}, {"content": "Kathleen says suppose so what would that scenario look like? so in the story Dudley is there, pen knife in hand, but instead of the prayer or before the prayer, he says, Parker, would you mind we're desperately hungry, as Marcus empathizes with we're desperately hungry you're not going to last long anyhow, you can be a martyr, would you be a martyr how about it Parker? Then, then then what do you think, would\nbe morally justified then? Suppose Parker in his semi-stupor  says okay  I don't think it'll be morally justifiable but I'm wondering. Even then, even then it wouldn't be? No You don't think that even with consent it would be morally justified. Are there people who think who want to take up Kathleen's  consent idea and who think that that would make it\nmorally justified? Raise your hand if it would if you think it would. That's very interesting Why would consent  make a moral difference? Why would it? Well I just think that if he was making his own original\nidea and it was his idea to start with then that would be the only situation in which I\nwould see it being appropriate in anyway\n \n0:40:25.940,0:40:28.359\nbecause that way you couldn't make the argument\nthat he was pressured you know it\u2019s three to one or whatever the ratio was, and I think that if he was making a decision to give his life\nthen he took on the agency to sacrifice himself which some \npeople might see as admirable and other people  might disagree with that decision. So if he came up with the idea that's the only kind of consent we could have\nconfidence in morally, then it would be okay otherwise it would be kind of coerced consent under the circumstances you think. Is there anyone who thinks that the even the consent of Parker would not justify their killing him? Who thinks that? Yes, tell us why, stand up I think that Parker would be killed with the hope that the other crew members\nwould be rescued so there's no definite reason that he should\nbe killed because you don't know  when they're going to get rescued so if you kill him you're killing him  \nin vain do you keep killing a crew member until you're rescued and then you're  \nleft with no one? because someone's going to die eventually? Well the moral logic of the situation seems to\nbe that. That they would keep on picking off the weakest maybe, one by\none, until they were rescued and in this case luckily when three at least were still alive. Now if if Parker did give his consent would it be all right do you think or not? No, it still wouldn't be right."}, {"content": "Tell us why wouldn't be all right. First of all, cannibalism, I believe is morally incorrect so you shouldn\u2019t be eating a human anyway. So cannibalism is morally objectionable outside so then even in the scenario of waiting until someone died still it would be objectionable. Yes, to me personally I feel like of it all depends on one's personal morals, like we can't just, like this is just my opinion of course other people are going to disagree. Well let's see, let's hear what their disagreements\nare and then we'll see if they have reasons that can persuade you or not. Let's try that Let's now is there someone who can explain, those of you who are tempted\nby consent can you explain why consent makes such a moral difference, what about the lottery idea does that count as consent. Remember at\nthe beginning Dudley proposed a lottery suppose that they had agreed to a lottery then how many would then say it was all right. Say there was a lottery, cabin boy lost, and the rest of the story unfolded. How\nmany people would say it's morally permissible? So the numbers are rising if we add a lottery,\nlet's hear from one of you for whom the lottery would make a moral difference why would it? I think the essential element, in my mind that makes it a crime is the idea that they decided at some point that\ntheir lives were more important than his, and that I mean that's kind of the basis for really\nany crime right? It's like my needs, my desire is a more important than yours\nand mine take precedent and if they had done a lottery were everyone\nconsented that someone should die and it's sort of like they're all sacrificing \nthemselves, to save the rest, Then it would be all right? A little grotesque but, But morally permissible? Yes."}, {"content": "what's your name?"}, {"content": "Matt. so, Matt for you what bothers you is not the cannibalism, but the lack of due process. I guess you could say that And can someone who agrees with Matt say a little bit more about why  a lottery would make it, in your view, morally permissible. The way I understood it originally was that that was the\nwhole issue is that the cabin boy was never consulted about whether or not it something was going\nto happen to him even though with the original lottery whether or not he would be a part of that\nit was just decided that he was the one that was going to die. Yes that's what happened in the actual case but if there were a lottery and they all agreed\nto the procedure you think that would be okay? Right, because everyone knows that there's gonna be\na death whereas you know the cabin boy didn't know that this discussion was even happening there was no you know forewarning for him to know that hey, I may be the one\nthat's dying. Okay, now suppose the everyone agrees to the lottery they have the lottery the cabin\nboy loses any changes his mind. You've already decided, it's like a verbal contract, you can't go back  \non that. You've decided the decision was made you know if you know you're dying for the \n reason for at others to live, you would, you know if the someone else had died you know that you would consume them, so But then he could say I know, but I lost. I just think that that's the whole moral issue is that there was\nno consulting of the cabin boy and that that's what makes it the most horrible is that he had no idea what was even\ngoing on, that if he had known what was going on it would be a bit more understandable. Alright, good, now I want to hear so there's some who think it's morally permissible but only about twenty percent, led by Marcus, then there are some who say the real problem here is the lack of consent whether the lack of consent to a lottery to\na fair procedure or Kathleen's idea, lack of consent at the moment of death and if we add consent then more people are willing to consider the sacrifice morally justified. I want to hear now finally from those of you who think even with consent even with a lottery even with a final  murmur of consent from Parker at the very last moment it would still be wrong and why would it be wrong that's what I want to hear. well the whole time I've been leaning towards the categorical moral reasoning and I think that there's a possibility I'd be okay with the\nidea of the lottery and then loser taking into their own hands to kill themselves so there wouldn't be an act of murder but\nI still think that even that way it's coerced and also I don't\nthink that there's any remorse like in Dudley's diary we're getting our breakfast it seems as though he's just sort of like, oh, you know that whole idea of not valuing someone else's life so that makes me feel like I have to take the categorical stance. You want to throw the  \nbook at him. when he lacks remorse or a sense of having done\nanything wrong. Right. Alright, good so are there any other defenders who who say it's just categorically wrong, with or without consent, yes  \nstand up. Why? I think undoubtedly the way our society is shaped, murder\nis murder murder is murder and every way our society looks down at it in the same  \nlight and I don't think it's any different in any case. Good now let \nme ask you a question, there were three lives at stake versus one, the one, that the cabin boy, he  had no family he had no dependents, these other three had families back home\nin England they had dependents they had wives and children think back to Bentham, Bentham says we have to consider the welfare, the utility, the happiness of everybody. We have to add it all up so it's not just numbers three against one it's also all of those people at home in fact the London newspaper at the time and popular opinion sympathized with them Dudley in Stephens and the paper said if they weren't motivated by affection and concern for their loved ones at\nhome and dependents, surely they wouldn't have done this. Yeah, and how is that any different from people on the corner trying to having the same desire to feed their family,\nI don't think it's any different. I think in any case if I'm murdering you to advance my status, that's murder and I think  \nthat we should look at all of that in the same light. Instead of criminalizing certain activities and making certain things seem more\nviolent and savage when in that same case it's all the same act and mentality  that goes into the murder, a necessity\nto feed their families. Suppose there weren't three, supposed there were thirty, three hundred, one life to save three hundred or in more time, three thousand or suppose the stakes were even bigger."}, {"content": "Suppose the stakes were even bigger I think it's still the same deal. Do you think Bentham was wrong to say the right thing\nto do is to add up the collected happiness, you think he's\nwrong about that? I don't think he is wrong, but I think murder is murder in any case. Well then Bentham has to be wrong if you're right he's wrong. okay then he's wrong. Alright thank you, well done. Alright, let's step back from this discussion and notice how many objections have we heard to what they did. we heard some defenses of what they did the defense has had to do with  necessity the dire circumstance and, implicitly at least, the idea that numbers matter and not only numbers matter but the wider effects matter their families back home, their dependents Parker was an orphan, no one would miss him. so if you add up if you tried to calculate the balance of happiness and suffering you might have a case for  saying what they did was the right thing then we heard at least three different types\nof objections, we heard an objection that's said what they did was categorically wrong, right here at the end categorically wrong. Murder is murder it's always wrong even if it increases the overall happiness of society the categorical objection. But we still need to investigate why murder is categorically wrong. Is it because even cabin boys have certain fundamental rights? And if that's the reason where do those rights come from if not from\nsome idea of the larger welfare or utility or happiness? Question number one. Others said a lottery would make a difference a fair procedure, Matt said. And some people were swayed by that. That's not a categorical objection exactly it's saying everybody has to be counted as an equal even though, at the end of the day one can be sacrificed for the general welfare. That leaves us with another question to investigate, Why does agreement to certain procedure,  even a fair procedure, justify whatever result flows from the operation of that procedure? Question number two. and question number three the basic idea of consent. Kathleen got us on to this. If the cabin boy had agreed himself and not under duress as was added then it would be all right to take his life \nto save the rest. Even more people signed on to that idea but that raises a third philosophical question what is the moral work that consent does? Why does an act of consent make such a moral difference that an act that would be wrong, taking a life,\nwithout consent is morally permissible with consent? To investigate those three questions we're going to have to read some philosophers and starting next time we're going to read Bentham, and John Stuart Mill, utilitarian philosophers. Don't miss the chance to interact online with other viewers\nof Justice join the conversation, take a pop quiz, watch lectures you've missed, and a lot more. Visit  \nwww.justiceharvard.org. It's the right thing to do. Funding for the program is provided by  Additional funding provided by"}], "Naomi Oreskes: \"The Scientist as Sentinel\"": [{"content": " Hey, hi. Hi. Hey. It's really nice of you to come tonight. My name is Melissa Franklin. I'm a physicist. You can clap now. I'm really excited about this talk tonight. I just want to say that I invited Professor Eskies to give this talk before the election. So obviously I'm brilliant. And I'm so happy that she's giving this talk tonight because it's so important, so incredibly important. This topic, the scientist, is sentinel is probably the most important thing for a lot of us right now. What do we do now? How do we make a contribution? So Naomi Eskies is kind of an interesting person. I've known her for just a little while because she arrived at Harvard just a few years ago as a professor in the history of science department. And in the Earth and Planetary Sciences department. And she's very cool. But most cool is that she got her degree from the School of Mines. I love School of Mines at the Imperial College in England, the place where there is now Brexit. And she left early and came back and went to Stanford University to do her PhD. But she didn't want to just do a normal PhD. She had to make it up herself because it's not in just one department, which I also like. So I just like her a lot in many ways. But maybe possibly other than the incredible work she does right now, which is so important to us, is her work with the Pope. Sorry, I know that sounds funny. But she wrote an introduction to the encyclical on climate change and inequality with Pope Francis. I've never really worked with the Pope. But I hear he's a great guy. And I wish he'd asked me, and even though I don't know anything about anything really, about climate change. Also, she's just incredibly prolific. She wrote a book called 2014 called The Collapse of Western Civilization, which was a positive thing. And she's also given really good TED talks, if you like that kind of thing. And she's just an incredible historian, but also she knows science. And she also wrote some books that I don't even know. The words about, like, do we believe in climate change?"}, {"content": "That's really important. So sorry, I think the thing that I'm looking forward to tonight is hearing from a really sane person who's very creative. And she's going to tell us what to do. She's going to tell us what to do. So please welcome her. Well, thank you for that great introduction. One of the things I've always struggled with as a historian and philosopher of science, who studies science and thinks about what scientists should do, is in my experience, most scientists do not want historians to tell them what to do. So I'm really, really happy that we've come to this moment. It's not turned on. I thought I'd turn it on. Okay, we've come to this moment where a physicist wants me to tell her what to do. That's pretty special."}, {"content": "I also thank you for that generous introduction. When I was studying at the Royal School of Mines, which is part of Imperial College London, and people would ask me where I went to school, and I would say go to the Royal School of Mines, and they would say, the Royal School of Mines? Are you studying philosophy? So yes, the Royal School of Mines, I studied mining geology. Also, when you said I'm very interesting, my mother is the kindest, sweetest person on earth, and never, ever, ever likes to say anything bad about anyone. But if you put on an article of clothing, the she thinks is a little not so flattering, she'll say, oh, that's interesting. So my family being interesting is not necessarily a compliment, but I will take it as a compliment here tonight. What I want to talk to you tonight about is work I've actually been doing for a number of years about this question of what the role of scientists should really be in relation to talking about contested public policy issues. I developed this specific talk for AAAAS that was here in Boston last month. I had the honor to do a keynote speech talk there. So I developed this talk as a talk about science for scientists. So in this talk, I'm going to use the word we when I refer to scientists. For those of you who aren't scientists, you can just say they, but the message I think is relevant for all of us in thinking through what our role needs to be in terms of thinking about contested issues of public policy. So some of you may have, and I'm going to come out from behind this podium because I don't like podiums. I don't like to be separated from my people. So some of you may have seen this that ran in the New Yorker a few weeks ago. Those smug pilots have lost touch with regular passengers like us. Who thinks I should fly the plane? Now of course we all laugh at that because to us it's obvious that the public ignores expertise and it's peril. And as people associated with a great university like Harvard, we have an expectation that our expertise should be respected and in many cases acted on. But as we've seen of late, many of our political leaders not only don't act on our expertise, but they actually rejected. And in some cases they actively misrepresented. And that creates a very difficult situation for us. What should we do when our work, our expertise, is being rejected, dispatched, and in some cases misrepresented? Should we speak up in public? Should we be speaking up in public on tricky, sensitive topics like evolution or the safety of vaccinations or in my case climate change? And if so, how? And what exactly does it mean to say that we should respect expertise? What are the boundaries of expertise? And if we as experts embrace a public role, what does that entail? So I want to start by talking about a scientist that I've studied in some detail, a man by the name of Roger Revelle. How many of you have heard of Revelle before? Oh a lot."}, {"content": "Wow, this is a great audience."}, {"content": "And not just the Earth Science professors. So Revelle, as many of you know, is a very famous chemical oceanographer. He was also one of the directors of the Scripps Institution of Oceanography in San Diego. And he was also the mentor to Al Gore. It's because of Roger Revelle that Al Gore first learned about climate change and began to think of it as a serious issue. In 1965, Revelle was serving as part of the President's Science Advisory Committee, a group that was writing a report on the state of the environment. And this report had an appendix that was co-author with four of his prominent geoscientific colleagues, including Dave Killing. And the title of this appendix was atmospheric CO2, the invisible pollutant. And in this appendix, Revelle and his colleagues warned that in due course, not tomorrow, not next year, but in due course, increased atmospheric carbon dioxide would likely alter the climate in serious and adverse ways. They wrote, throughout his worldwide industrial civilization, men is unwittingly conducting a vast geophysical experiment. By the year 2000, the increase in atmospheric CO2 will be close to 25%. This may be sufficient to produce measurable and perhaps market changes in climate. And as we all know today now, that prediction came true. So we can say that these leading scientists of a previous generation were acting as sentinels. They were calling attention to an issue that was not yet publicly recognized, in fact not even recognized by most of their scientific colleagues at this time. And they were pointing out that while the issue of visible pollution was getting a lot of attention in the media and in halls of power, particularly smog and Los Angeles, or the terrible London fogs that had killed people in the 1950s, there were other invisible pollutants that were also important. And carbon dioxide was probably the most important of these invisible pollutants. So they reached out to political leaders, in this case to the president of the United States, about their scientific research that implied a societal threat. Now, in our research and the Revell archives, we've never found any evidence that Revell worried that this might somehow not be an appropriate thing to do. On the contrary, in the context of growing public concern about air pollution in the 1960s, Revell considered to be obviously appropriate to alert political leaders to this other form of pollution that was not as obvious but could also have serious long term effects. And we also have seen from our research that most of the political leaders to whom he reached out did seem to be at least cautiously receptive to being made aware of this issue. And in current research that I'm doing here with two of my graduate students here at Harvard in the history of science department, Hannah Conway and Colleen Linear-Kristenson, we've identified a number of political leaders in the 1960s who took an interest in this issue and who thanked Revell and his colleagues for sending these materials to them. In some cases, followed up and asked for more information."}, {"content": "So those were, it was a very different time. Now, today though, many of us are reluctant to be sentinels. Many of us are worried that if we speak up in public beyond the confines of scientific publications or scientific meetings and conferences, that this will lead to us being viewed as advocates or activists, and that we will politicize our science and will lose credibility. So, I think that if you have heard this in last few weeks, maybe some of you have been involved in conversations with your students or your colleagues here at Harvard about whether we should participate in the March for Science and whether or not that threatens to politicize science in an undesirable way. So this is a question that colleagues and I have been looking at actually for a few years. Well, before the March on Science or March for Science or whatever March on Science, no. Guess it's a March for Science Donald Trump is marching on science. Well, before the current political situation, my colleagues and I have been interested in this question of how scientists think about their role in relation to political questions. So I've been for several years now part of a project that's coming wrapping up now called assessing assessments. My colleagues on this are Dale Jamison who just talked at the law school today about other work and Michael Oppenheimer and several other postdocs and graduate students. So in our work, this was one of the things that we asked scientists about. We asked them how do you think about the relationship between science and policy and how do you think about your role in relation to that question. And what we found was a very consistent pattern where the vast majority of scientists that we asked expressed a great deal of reluctance to take on any role other than simply presenting factual information in the context of scientific assessments. So not expressing opinions on policy and not even presenting those facts in other contexts outside of the assessment framework. And when we probe this and ask why many expressed the idea that there is or needs to be a bright line between science and the one hand and policy on the other. And that speaking up in public, even about the facts threatens to dull that line. And therefore scientists said, scientists said things like, well, you should do your work, but you should not go public. Some said using imperative, you must not go public. You must not cross the line. And when we said, well, why?"}, {"content": "They said, well, because if you do, you'll lose your credibility. The IPCC, the Intergovernmental Panel on Climate Change has addressed this issue explicitly through its rubric of being policy relevant, but not policy prescriptive. IPCC leaders acknowledge that their work is not pure science. That climate science is linked to major public policy issues. And that the IPCC exists because of its link to governance through the United Nations Framework Convention on Climate Change. But nevertheless, even though they acknowledge that the IPCC itself is a kind of hybrid organization, most climate scientists working within the IPCC still say that they should refrain from taking any kind of public policy. And they say, well, they should not be taking any kind of public role and stay removed from discussion of policy implications and considerations. And one of the most common refrains that we've heard both in the context of this research and more broadly is scientists saying that we should let the facts speak for themselves. The climate science colleague, James Hanson, has also written about this issue, and he's referred to this as redisense. He said that scientists in general are reluctant to speak up about what they know about climate change, so not just about the policy things, but even to speak up in public about the facts. And again, because they believe that we need to let the facts speak for themselves. Now, those of you who saw the poster for this talk saw that one of the pictures on it is this picture of Jim Hanson getting arrested, protesting at the White House over the lack of action on climate change. Many scientists who have we have spoken to have invoked Jim Hanson as proof. Now, Hanson has become a major figure not only because he speaks up about the evidence of climate change, which he does, but also because he's become an advocate for particular solutions. So he is an advocate for a carbon price established through a fee and dividend system. And in support of this work, he has been arrested several times. But I want to ask the question tonight, what exactly is Hanson proof of other than maybe that scientists are uncomfortable with his position? And it's not just climate science. This is an issue that affects scientists in many, many areas. So people who work in re-biology and conservation, people who study lead or other toxic in the environment, endocrine disrupting chemicals, neo-nicotonoid pesticides, and their potential impacts on pollinators, genetically modified crops, vaccine safety, the harms of sugar in the American diet, deaths and injury from gun violence, all of these are issues on which scientists do scientific work collect data factual information, but they have policy implications, policy implications that may be highly contested. So scientists in many fields face this sentinel problem. And I want to argue that scientists in the past have faced this problem too. That although this moment we're living in may feel unique, it certainly feels distinctive and troubling in our lifetimes, but it isn't actually a unique moment in terms of scientists facing this question of what their roles should be. So we could think of this problem as having a kind of spectrum of choices. At one end we might say, as many scientists do say, that we should just do our science and leave it to others to communicate it, to explain why it matters, and we're needed to propose remedies. And we could call this the pure science ideal. At the other end we could think about Jim Hanson, who does speak out, does get involved, does propose remedies, and in his case does even get arrested, we could call that the activist ideal. So what I want to do tonight is to argue for a middle ground. Now as a person who works on climate change, I adamantly reject the idea that the truth is always in the middle, because it's often not, but tonight I do want to suggest that there is a kind of middle ground that we might think about occupying. And then in any case thinking about the spectrum helps us think about where we want to be on that spectrum, because at the end of the day there isn't actually a right or wrong answer to this. These are judgments, but historical experience, historical evidence can help us make those judgments. Oh, thank you very much, and help us judge where we want to be in relation to this question. So my argument tonight has three parts. The first is to talk about historical precedent. To look at an example of scientists in the past who did step up and act as sentinels, not just on the fact of the problem, but also on policy solutions, and to argue that this precedent refutes our worry or our anxiety that taking a public position on an urgent issue undermines the credibility of our science, and then to argue to conclude that I do believe we need to speak because facts don't in fact speak for themselves. So what is the historical precedent? Well, some of you may already know, maybe you've heard me talk before, but it's obviously it's the precedent of nuclear weaponry. Many climate scientists feel that we are today in an existential crisis. Scientists in 1945 knew that they were. There was no question among physicists who worked on the Manhattan Project, who worked on nuclear weapons, that the potential for an arms race meant the potential to eliminate life on Earth as we knew it. And in this context, particularly as 1945 became 1948 and the Soviet Union exploded its first hydrogen bomb, and then the, sorry, it's atomic bomb, and then the United States developed a hydrogen bomb, and then the Soviet Union developed a hydrogen bomb, and pretty soon we were in an arms race. Many leading physicists felt that they had a moral obligation to speak out against nuclear proliferation. As many of you know, they had played an essential role in creating these weapons, and these weapons now threatened human safety and potentially even human survival. And therefore they felt it was actually rather obvious that they had an obligation to raise an alarm and suggest means to control this threat. So, drawing on the framework of scientific rationality, they argued that it was rational to be alarmed and irrational to be complacent. And therefore they did have an obligation. But one of the interesting things about this discussion that takes place in the late 40s and 50s is that many of these physicists argue that their obligation is not just to speak up on the technical aspects of nuclear weaponry, to explain how they worked and how they killed people and why they were so damaging, but also to address the problem of what to do about them, about how to control them. Because to them it was eminently clear that these things did need to be controlled. There was no real plausible argument that an unrestricted arms race would be a good thing for the world. The most famous example as many of you know is Niels Bohr, who spoke out actually even before the end of World War II, and predicted the arms race that would follow if there were not some kind of international dream in between the US and the Soviet Union. And also Albert Einstein, who in later years famously became an advocate for international peace and arms control. But it wasn't just Bohr and Einstein. Sometimes people have said to me, well Bohr could afford it, he was so famous or Einstein could afford to speak out. But it wasn't just these incredibly conspicuously famous figures. Actually a wide range of physicists, Hans Betta, Leo Zalard, James Frong, Philip Morrison, who taught for many years in MIT, and many, many others. There are dozens of physicists that we could name who became involved in a variety of different ways, large and small, to help alert the world to the threat of nuclear weapons and engage people in a conversation about arms control and disarmament. These men spoke to the moral imperative to control nuclear weapons, and they became advocates. The core of their argument is something that I've labeled epistemic proximity. And I think it's an important argument to understand because it's not just about a kind of moral obligation that arose from having built the weapons, but it also has specifically to do with their role as they understand it as experts. So the argument goes like this. not just that they helped build these weapons, but it's that as physicists, they had a uniquely vivid appreciation and understanding of the damage that these weapons could wreak. That they could explain things that other people really didn't and maybe even couldn't fully understand about what an arms race and a large-scale nuclear exchange would really mean. So people had seen the destruction of Hiroshima and Nagasaki. John Hersey had written about it very beautifully in his book Hiroshima, but many people said, well, yes, it's true, lots of people died, but how is that worse or different than the fire bombing in Dresden or the fire bombing of Tokyo? So for many people, it wasn't actually clear why these weapons were substantially worse. Now, this seems hard to conceptualize today and previously the slide said today, all the world leaders understand what a major nuclear explain would do. Okay, well, when you do contemporary history, you have to stand your toes. But clearly, in the late 40s and 50s, that was not the case. Some of you may know that President Harry Truman when confronted with the announcement of the Soviet atomic bomb and when he was asked, well, does this mean there will be an arms race, he said yes, and we will win it. Douglas MacArthur during the Korean conflict requested permission to use nuclear weapons. So it's not the case that people understood that using nuclear weapons would necessarily lead to some kind of terrible conflagration. So these scientists felt that the need to understand fully and viscerally what a large-scale nuclear exchange would mean that this need was severe and that they had to step up to that challenge and many of them did so in both public and private ways. So I think a comparable argument can be made about climate change today. I've given something like 300 public talks on climate change and I've spoken, I'm going to South Dakota tomorrow, so I now will have been to 47 or 50 states and I've talked in Idaho and North Dakota and Texas and Oklahoma and California. And one of the things that I feel I've learned is that many people, including many people who do not deny climate change or do not disparage climate science, still don't really quite get why this issue really matters. They don't quite understand just how serious uncontrolled climate change will be. One of my colleagues, quite famous and distinguished political scientists, said to me once over lunch, so tell me why I should be worried about polar bears. And this is part of why Eric Conway and I wrote the collapse of Western civilization because we were trying to think about, what could we do, what kind of story could we tell that would convey to people why climate change really matters and why this is not just a question of polar bears as much as I personally do love and worry about polar bears. Okay, so part two, I want to argue that this historical press and offers evidence that refutes our worry that taking a public position on an urgent issue will undermine our scientific credibility. And this argument is actually extremely short. The evidence simply doesn't support this hypothesis. If we think about Albert Einstein, I know of no evidence and maybe someone can come up with it but I know of no evidence that the theory of relativity or his work on the photoelectric effect ever lost credibility because of his advocacy of arms control. Now, there were anti-Semites in Germany who didn't like Einstein, but that was not because of his public advocacy. That was because of a whole set of other complicated issues. Hans Betta, as many of you know, won the Nobel Prize for his work on nuclear fusion fusion. No one ever suggested revoking that prize or that somehow that work was doubted or dubious because he was an arms control advocate. And Bohr is such an interesting character. Some of you know, many of Bohr's colleagues were dubious about the Copenhagen interpretation of quantum mechanics. Bohr wrote a lot of philosophical essays that lots of his colleagues thought were completely off the rails. But it wasn't, but not his arms control advocacy. Millions of schoolchildren learned about the Bohr model of the atom. If you took high school physics or college physics, you learned about the liquid drop model of fish and you learned about his crucial scientific contributions. And no one ever said that those contributions were undermined because he advocated arms control. Now what about Robert Oppenheimer? Some people say to me, well, what about Oppenheimer? Oppenheimer is a famous case of a scientist who got discredited. But what exactly happened to Oppenheimer? He lost his security clearance because of his opposition to the hydrogen bomb. And also because Edward Teller held a personal grudge against him. And he saw this as an opportunity to undermine him. So Oppenheimer lost political standing inside the US government. He lost his clearance. He lost his capacity to give advice to political leaders on certain delicate issues. But losing political standing with politicians is a very different thing than losing scientific credibility. And in fact, Oppenheimer became a hero in many circles. I mean, many of you have heard of Oppenheimer because of this, more than because of his science. So among many people, he gained credibility. So when we talk about credibility, we actually have to be more precise. We have to ask, are we talking about credibility with political leaders? Are we talking about credibility with the public? Are we talking about credibility with our own colleagues? Or what?"}, {"content": "These are different things. There's no evidence that Oppenheimer lost scientific credibility with any of his colleagues because of this work. So I want to argue that the fear of losing scientific credibility is exactly that. It's a fear. It's an anxiety. And there's actually very little evidence to support the worry. And you can call me naive, but I do think we should be making our decisions based on evidence. Even though I know that's a very controversial claim to make in the stage. And some of you may have seen that there's actually a study that just came out a couple weeks ago."}, {"content": "And I apologize I haven't had a time to make a slide of it. But a recent study that actually interviewed people of the public and posed to them some scenarios where scientists spoke out in public, made policy recommendations, actually showed that there's very little evidence to suggest that this causes you to lose credibility with the public either. So it's actually an interesting question. And it will be a question for another talk about, actually, why we are so worried about this issue when there's actually so little evidence to support it. But I haven't done that work to answer that question yet. OK, so part three, facts don't speak for themselves. Well, why do I say that? Why don't facts speak for themselves? Well, the simple answer. And when I started saying this 7, 8, 9, 10 years ago, this was considered controversial. Now it seems obvious. So that's good. I can make the talk shorter. We live in a world where many people are trying to silence facts. And as you know, as many of us now understand, these arguments are not actually about the facts. They're not just about the facts. In most cases, they're not even actually about the facts at all. Many of the arguments that are being used to undermine climate science, to be able to undermine evolution, to undermine vaccine safety. These are arguments about political beliefs, about economic interests, and about values. You cannot refute a claim about values with facts, or claim about facts with values. That's what philosophers would call a category mistake. We're conflating two different domains. If people are rejecting climate science because of values, then we have to think about what those values are, and why those values are perceived to be in conflict with our facts. And this was essentially the conclusion of the work I did with my colleague Eric Conway when we wrote the book Merchants of Doub."}, {"content": "When we started this project, we were frankly mystified. We had come across a story of some very famous scientists that we actually knew, one of whom had been the director of the script's institution of oceanography, where I was working at the time. And these prominent distinguished famous scientists had become climate change deniers. And there was no possibility that this was scientific illiteracy, because these were some of the most brilliant and successful scientists of the 20th century. It included Frederick Sites, who was the president of the US National Academy of Sciences. So the question we had was, why would these people reject the scientific work of their own colleagues? How do you make sense of that? And what we found overwhelmingly, not just are these men that we studied in our book, but in general that the rejection of climate scientific facts was not about scientific illiteracy or lack of scientific understanding. But actually, it was driven by an anxiety, by fear, by a worry, the worry that addressing climate change would lead to bigger government, higher taxes, and loss of personal freedom. And those concerns and the solutions that people were proposing for climate science were seen as clustering with conservative values. And that's why we've seen this enormous politicization of the issue because of conservatives believing that the implications of climate science threaten their values. It's this clash of values, then, that explains the polarization, and also some of the otherwise strange alliances that we see on this issue. The perception that addressing climate change, sorry, that addressing climate change will require big government or higher taxes, explains a good deal of the political polarization around the issue because opponents of big government are ideologically motivated to reject climate scientific events. And they've made common cause, then, with industries that reject the science because it threatens their profit. So the obvious part of this story, the economic mode of this economic self-interest aligns with a more subtle and complicated story about people seeing climate science as clashing with and threatening their values. So just to sum this up, I want to show you a short clip from the film that we were made of our movie. And this is just kind of merchants of doubt. And in that shell, it shows you who these people are and the sorts of arguments that they make to try to undermine scientific findings. Bill O'Keefe is Executive Vice President of the American Petroleum Institute. He's also a board member of the Global Climate Coalition, made up of oil and electric companies, automakers, and others. We believe it was the war on the oil. They had an off-hoyle agenda. Climate change was part of that. I think that it's unfortunate that the science is so distorted and mistated. And without it... The science is complicated. There are lots of different factors. So you really have to understand the whole picture. There is a natural variability that has nothing to do with me. Climate is changing naturally. Has to do with sunspots and has to do with the wobble of the earth. And so it's not too difficult to persuade some of the public that we really don't know for sure. So maybe that's way to wild. We need to have more proof. We need more data. The science isn't there to make that determination. There is no need for us to rush to this kind of judgment to respond. Others put out ads saying more pollution is going to be good for us. A doubling of the CO2 content to the atmosphere will produce a tremendous greening of planet Earth. CO2 is a benefit to plant life. It's increasing the bounty and the productivity of the planet, our ability to feed populations in this world. What you're seeing here from the coal industry is perfectly analogous to what the tobacco industry is to do. They refuse to change, refuse to shift. And they're trying to convince us that it's actually good for us, the way they used to say, luckies make you healthy. OK, so in that clip, you see sort of the basic, you see the merchants have doubt doing their thing. But in that clip, you're seeing people, mostly who represent the fossil fuel industry. So Lee Raymond from Exxon Mobil, Don Blankenship from Massey, Energy, Bill O'Kee from the American Petroleum Institute. But again, as I already mentioned, part of what we were trying to do in our work was to understand why would scientists, why would other people who don't have stock and exome mobile, why would they make common cause with this sort of work? And again, as I've already suggested, it's this confluence of money and ideology that explains the pattern that we saw. And this also helps to explain why climate change now is so much more prevalent in the United States than elsewhere. Because of our powerful commitment to individualism in the United States, and the historic American skepticism about the federal government going back to the founding of the Republican skepticism about centralized decision making. And if you think about it, think about the articles of confederation, think about the separation of powers. This country was rooted in an idea that investing too much power in centralized government would undermine the individual freedoms of the states and the people in them. We have a deeply rooted belief in the United States that the government that governs best governs least. And that's a belief that informs a huge amount of climate change denial. So climate skeptics, contrairions, deniers, whatever you want to call them, they play on these cultural norms, insisting that addressing climate change will lead to an expansion of the government and a constriction of our freedoms. And you've seen this kind of ideology on display in the last few weeks. And this resonates very strongly with many ordinary Americans, particularly in what we've come to call the red states. And therefore, people resist accepting the findings of climate science, and they're open to the suggestion that our findings are exaggerated or even perhaps a hoax. So I want to just give one example of how this works in sort of one scientist that we study that I think is a particularly illustrative example of how this ideological piece comes together with rejecting the findings of science. So one of the people that we studied was a physicist named Fred Singer, who some of you may be are familiar with. Singer was not a climate scientist. He was a physicist. In fact, he was the proverbial rocket scientist. He was the first director of the US whether satellite service and was involved in the early years of the US rocketry and space programs. But in addition to his scientific work, he was also involved in campaigns to challenge the scientific evidence of acid rain, of the ozone hole, of climate change, and also of the harms of tobacco. Fred Singer, in the early 1990s, worked with the Philip Morris tobacco company to attack the US Environmental Protection Agency over the issue of secondhand smoke. Now some of you know that we have known since the 1980s that secondhand smoke can cause cancer. The same chemicals that are in primary smoke also occur in the exiled smoke or in smoke that comes from a cigarette that's just burning. And if you breathe that smoke, you also can be subject to cancer and many of the other diseases that affect smoking, smokeers. This was first stated unequivocally in 1986 in a report of the US surgeon general in which the surgeon general declared that involuntary smoking, that was the term he used, is a cause of disease including lung cancer and healthy non-smokers, especially children. And based on this, as well as an independent review of over 6,000 peer-reviewed scientific papers, in the early 1990s, the EPA declared secondhand smoke to be a class A or proven carcinogen. In 1994, working with the tobacco industry, Fred Singer wrote a report attacking these scientific findings. And one of the reasons, this is a copy of out of the tobacco legacy documents of the cover page for this report. And I made this slide because Fred Singer is still alive and he accused me of being a liar. He has said in public that he never worked with the tobacco industry. So, yeah, there it is. Okay, so I love documents."}, {"content": "I love my job. So, Singer had been working as a consultant to Philip Morris and he was hooked up, I'm not sure exactly how, but he became, he started working with a lawyer named Kent Jeffries, a lawyer who was affiliated with the Kato Institute and the competitive enterprise institute. And some of you know these are things that promote free market solutions to social policy problems. The report was actually published by the Alexis de Toekeville Institute but funded by the tobacco institute, which was the so-called research arm of the tobacco industry. So, this report illustrates in a nutshell how this works. There's a kind of shell game where the tobacco industry would give money to the tobacco institute claiming that that was for research. Tobacco Institute would hire lawyers out of thing tanks like the Kato Institute. They would then work with a scientist who would give the thing scientific credibility and produce a report that would be issued by yet another thing tank. In this case, the Alexis de Toekeville Institute whose name would conjure up notions of freedom and democracy in America. Now, the interest of the tobacco industry in attacking the EPA is obvious. And I think the interest of these thing tanks in opposing regulation is nearly as obvious. But why would a physicist attack the scientific evidence of the harms of tobacco? Well, I would assume that singer was paid for this work but that's not the key part of the story in my view. The key part, I think, comes from his own words. So, in the introduction to this report, he explains why it's important to push back against the EPA. And he says, quote, if we do not carefully delineate the government's role in regulating dangers, there's essentially no limit to how much government can ultimately control our lives. And in our book and in our films, we document many, many examples of this argument. If we allow the government to regulate X, then soon it will also regulate Y and Z and we will lose our freedom. Acid rain today, the Bill of Rights tomorrow. This argument comes directly from the work of the Chicago economist Milton Friedman. And it's an argument that I call the capitalism and freedom argument. And indeed, we've seen this argument being resurrected in the last few months. It was used by Ronald Reagan in the 1990s to justify lower taxation, less government and to foster a marketplace deregulation. And that set of arguments has really been guiding conservative thinking in the United States since the Reagan administration. The two key texts are Milton Friedman's book by that name, capitalism and freedom, which was inspired and turned by the work of the Austrian neoliberal economist Friedrich von Haack. So if you're interested in this problem, these are the two books that you need to read to understand the intellectual framework that is guiding this whole argument. But if you go back to von Haack, his basic argument is he's making this argument towards the end of World War II, he's saying if we allow Western democracies to have national health insurance or other forms of intervention in the marketplace, we're going to be on the road to surf dumb. And it's only a matter of time."}, {"content": "It's a kind of inevitable creeping of government controlled into different aspects of life. So this is the common thread of science denial. And in fact, the common thread between climate change, acid rain, tobacco, and other things that otherwise might seem to be totally different issues, that scientists discover a problem, typically inadvertently, I mean, the scientists who were working on acid rain didn't set out to discover acid rain. They were studying forest ecology and watershed hydrology. But scientists discover a problem. And the solution to this problem appears to require some sort of government action, whether it's putting a price on carbon or banning CFCs or limiting sulfur emissions from coal-fired power plants. And so people who don't want that government action, either for economic reasons or philosophical ones, question the science and attack the scientists. Sociologists call this implacatory denial. You deny something because you don't like its implications. And it's a common pattern in human life. It's not restricted to climate change denial. But if you deny the evidence that your partner is having an affair, maybe that's OK. Life goes on. If you deny the evidence that the climate is changing, the consequences are pretty serious. So science has been politicized to bring this now back to our question. Science has been politicized as a means to undermine it by groups and individuals who do not like what they interpret to be the political implications of our scientific findings. So here's the crucial point, though. When scientists were attacked, when the scientists who worked on tobacco or acid rain or the ozone hole were attacked, it wasn't because they had crossed the line into policy. Most of the scientists who were attacked in these stories that we wrote about had actually not played any role in public policy at all. They had done what most of us think we're supposed to do. Do important work, publish and period your journals. Talk about. out of the meetings, but their scientific research had revealed or affirmed serious problems like deaths from tobacco use or the threat to life on Earth from ozone depletion. So these scientists did not become targets because they had spoken out. They became targets because of the importance and significance of their work. So I think that many of us in the scientific community have actually misinterpreted cause and effect. The causal arrow is the reverse of what most of us think. Now it is true that today there are some climate scientists like Mike Mann and like Jim Hanson who have spoken out, who have become public figures, but even these men, even Mike Mann and Jim Hanson, both of whom I know, they became public figures after they were attacked. They were scientists doing science. They got attacked and being attacked made them decide that they needed to stand up and be counted. So it may help to understand this also to know that there is actually a very long history in the United States of claiming that government intervention in the marketplace threatens our freedom. And this is from some new work I am doing now trying to understand the deeper roots of this argument, which it turns out go back to at least the 1920s. And one of the ironies of this is that these arguments have actually often been used to protect products, products, profits. And in some cases actually to restrict competition even when people are claiming to support a free market society. So I just thought this is such a very interesting advertisement that I found. And I thought I would ask you, what do you think this might be an ad for? And my postdoc is not allowed to answer, but anybody else? Yeah, Barbara wire, that is the usual answer. Sometimes people say hats. The answer is privately generated electricity. This was part of an ad campaign run in the early 1960s by a group of private sector electrical utilities who did not want the federal government to generate electricity at the Hoover Dam or other places in the United States. Now we can argue about the benefits of government electricity, but the point is to see that the argument is not being made, it's not about the merits of different ways of generating electricity. The argument is this fear mongering campaign that if we allow the government to generate electricity, pretty soon we'll be living behind barbed wire. So what does all of this tell us about facts and values? Well, we see that in all these stories, the facts and values are conflated and complicated in difficult ways that are difficult to sort out. But the key insight I think is to understand that these arguments are not about the scientific facts and because they're not about facts, they can't be refuted with facts. But they can be addressed with political or historical evidence or with other arguments about values. So for example, one thing we can do is to challenge the assertion that addressing climate change necessarily requires bigger government or higher taxes. And a good example of this is the history of acid rain. So some people in the audience here I know remember that acid rain, which was a very serious problem, was addressed in the 1990s through amendments to the Clean Air Act that created emissions trading, a market-based mechanism that was supported by both Democrats and Republicans and signed into law by Republican President George H.W. Bush. This law did not lead to the expansion of the federal government, it did not lead to higher taxes, nor did it lead to a loss of liberty of people living in the Midwest where acid rain was a problem. And in fact, the price of electricity in the American Midwest fell. The second thing I think that's important for us to think about is that I think we shouldn't be afraid to address values. For two reasons, first of all, because these are values, questions we have to address the values involved. If we just keep throwing more facts on people, it won't address the worry, the concern that they have. So if our fellow citizens in South Dakota, Ohio, or Oklahoma are worried about bigger government or worried about values, then we have to be able to talk about that. And I think that preventing disruptive climate change actually lines up with the fundamental values that many of our fellow Americans share. In fact, I think it lines up with more values that many of our fellow Americans share than simply the value of constraining big government. So think about it. The value of fairness, which includes protecting innocent people from getting hurt. We controlled secondhand smoke in part because there was so much overwhelming evidence that secondhand smoke hurt children. And that was one of the very powerful arguments that was made for the right of the EPA to regulate secondhand smoke in order to prevent hurt or harm to innocent people like non-smokers and children who were not choosing to smoke. Or the value of accountability that the people who made a problem have an obligation to address it. Or the value of being realistic, of accepting that market failures are reality, and sometimes there is the need for the government to nudge the market in the right direction. We saw that during the housing crisis we've seen it in the financial crisis. People know that markets don't always work the way we want them to. Or the value of technological leadership and hard work of rolling up our sleeves and getting the job done, something that Americans have always done and prided themselves in doing. And of course, most importantly is the argument that there are values that the market does not protect like the basic inherent dignity of all people. And this is the central argument that Pope Francis makes in the encyclical on climate change and inequality, that there is an inherent dignity to all humans, and that that is something that we all have a right to defend and protect. Freedom is important, but so are many other things. And in the long run, climate change deniers are not actually protecting our freedom. In fact, they're threatening it. And this I think is one of the most powerful arguments we can make. That while the climate change deniers say freedom, freedom, freedom, which they do, in reality, the shoe is on that other foot. So I want to just show you one other clip from the film where I'm speaking and addressing this issue. As sea level rises and hurricanes become more intense, people get killed. Their houses and communities get destroyed. But think about heat waves and droughts that ruin agricultural communities. All of these are problems that it will require government intervention to address. The great irony of the story to me is that people who don't like big government are going to get more of it. And we're going to see more money being spent on dealing with the aftermath of these disasters. There will be billions of dollars in real estate losses, but more than that, people die. That's why it matters. That's why this is meaningful for us and not just for polar bears or people in Bangladesh. That's why so many people in the scientific community now are really starting to talk in very worried tones. Because there's, I think, a growing sense in scientific community that we're running out of time to prevent a train ride. So obviously my argument is that we do need to speak up because we need to counter the disinformation, the misinformation, and the false value arguments that are being made by other people. But I want to end with one more thought which gets back to this idea of epistemic proximity. So if we go back to Roger Revelle in the 1960s, Revelle spoke up because he knew about something, the possibility of disruptive climate change that few other people were aware of. And like Born Einstein and Beta before them, Revelle and killing and their colleagues, we're speaking from their proximate expertise. Meaning about something that they understood by virtue of their expertise as scientists that other people did not understand. But they also respected the expertise of others to propose and formulate the solutions. And Revelle worked on climate change his whole life. He studied it from many different angles. But he always was very cautious about any response to a question about what the right policy solution was. And I think this points to an important distinction. And it's not the fact value distinction as people have normally understood it, but it is related to it. It's about the limits of expertise. It's about who really knows how to fly that plane. So there are many things which is natural scientists or social scientists depending on what our expertise is. There are many things which we're not experts about and not particularly qualified to speak about. So in the case of climate change, if you're a climate scientist, if you do work on the physical science of climate change, you're not particularly knowledgeable in most cases about the social and economic aspects of impacts or the details of policy. Earth scientists cannot say, oh sorry, Earth scientists can say that if we're to prevent dangerous anthropogenic interference in the climate system, which is what the UN Framework Convention commits us to, then we must do something to control greenhouse gases because greenhouse gases and deforestation are the causes of this problem. Just as CFCs were the causes of ozone depletion and second-hand smoke was the cause of lung cancer and otherwise healthy non-smokers. And that means preventing the continued dumping of CO2 into the atmosphere. That is a conclusion that falls directly from our science. We could call it a direct deductive consequence. And therefore I want to argue we should not hesitate to say things that fall out directly from our scientific knowledge and understanding. Indeed, I would argue that it is our responsibility to do so because we are the people who have that epistemic proximity, who understand the problem best. And in my model for this, then I said in the beginning I was going to put forward an idea of the responsible scientist and I think we have a model of someone who played that role in the United States and that's Sherry Rowling, who won the Nobel Prize in the mid-1990s for his work accurately predicting that chlorinated fluorocarbons would deplete stratospheric ozone. In the 1980s Rowling and his colleagues realized that unless we control CFCs, then destruction of stratospheric ozone would threaten the future of life on Earth. And because of that he began to speak publicly and like his nuclear physics colleagues beforehand he became an advocate for action to control these chemicals that were the cause of ozone depletion. So for him policy was a deductive consequence. Rowling felt that he couldn't do this because the need to control CFCs was a direct consequence of the scientific work. So we can think of the argument as going like this, CFCs destroyed ozone. stratospheric ozone protects life on Earth. So if we want to protect life on Earth, if we want life to continue, we must somehow control CFCs. Now, this didn't involve an implicit value premise, but that value premise was the value of life on Earth. And really, who was going to challenge that? I mean, that's a debate that I'd be happy to take on with any climate change denier. But here's the important point. His advocacy didn't undermine his scientific credibility. He did his key work in the 70s and early 80s and he became an advocate for action in the middle to later 80s and played a role actually in the development of the Montrel Protocol to control the substances that deplete stratospheric ozone. But in 1995, he was awarded the Nobel Prize in chemistry for this work along with Paul Krutzen and Mario Molina. I think that if anything, there's an argument to say that his advocacy actually cemented his scientific legacy that we know more about Sherry Rowling's scientific work today in part because of what he did as a public, as a responsible scientist. So is there a comparable position for climate scientists? Yes, absolutely. Greenhouse gases are causing climate change. Climate change is dangerous. As I say in the film, it threatens people's lives, it threatens our homes, our well-being, our prosperity, and it also threatens polar bears and many other species, coral reefs and others. So if we want to protect humans and other species from the damages of disruptive climate change, then we must dramatically reduce and eventually phase out greenhouse gas emissions. And this is a deductive consequence that follows logically from our scientific work. But, however, as natural scientists, we don't have the expertise to answer questions such as, which is better a carbon tax or emissions trading system. If we go for an emissions trading system, should it be revenue neutral? Sorry, if we go for carbon tax, should it be revenue neutral? And if so, should we do it through fee and dividend or through cutting tariffs and taxes elsewhere? And how useful are fee and tariffs in stimulating renewable energy production? Should we focus on grid integration or energy storage? And what about nuclear power? These are all matters of social science, law, policy, and politics."}, {"content": "It doesn't mean we can't have an opinion on these questions, of course, as citizens we can. And Jim Hansen has a right to be an advocate for the fee and dividend system if he wants to as a citizen. But I do think it's important for us to be clear about the limits of our own expertise because let's face it, we aren't the people, unless you have a pilot's license, we aren't the people to fly that plane. So I want to argue that we should be reticent about areas outside our expertise. We should respect the expertise of others who are expert in those domains, whether they're economists, psychologists, lawyers, or other natural scientists. And if we want to address these topics because we've concluded that they're essential to the solution, then we should forge collaborations with colleagues in those domains. Put another way, if we expect people to respect our expertise, then we also have to respect theirs. That seems like common sense. But we should not be reticent about talking about the things we know and understand, the things we know to be true. And we should not be reticent about calling out others who say things that we know to be untrue. Experience of the past several decades has shown that when it comes to facts about the natural world, there are many people prepared to speak against the facts for many diverse reasons. And therefore, someone has to speak for the facts. And that's someone, I think, is us."}, {"content": "Thank you very much. So, who's going to the science march? That was wonderful. If there are any questions, please ask them."}, {"content": "Yes. Just call on people. Yeah."}, {"content": "Oh. Oh, here we go."}, {"content": "Thank you. Is this on? Yes. Oh, boy. It's very on. So I'm a great admirer of your work. And I found your chain of logic persuasive this evening, but loses me at one point. You suggest, but never quite say, that if more climate scientists spoke out about climate change, it would make a difference. So to put it in question form, do you believe that in spite of evidence that Peter Froomehoff speaks out James McCarthy writes letters to the globe last week, Somerville, et cetera, et cetera. Any climate scientists are speaking out. It's not clear to me what difference that's making. Yeah, that's a fair question. Of course, with anything evolving, social change, these are very hard things to judge, what makes a difference, what moves the needle. But I think that if you think about it, I mean, you named four or five people and I could probably name four or five more. But there are something like 10,000 climate scientists in America. And when we think about the people who have spoken out, the same dozen names comes to mind all the time. And I've served on committees that give out prizes for climate science communication. And I can tell you that the lists of people that get nominated are distressingly small. So I think that actually the numbers of people who have really been involved making the effort are small compared to the pool of people who are potentially available to do the work. And I think it's very important to have a larger pool for a couple of reasons. One is that we know we do have good evidence from social science research about the so-called trusted messenger problem. People respond to messages in part based on who's telling it. And that makes it really important that it isn't just a couple of people. It isn't just Jim Hansen and Richard Somerville and Peter Fremhoff, much as I love all those people. No, I don't love Jim Hansen. No, just kidding. Not just I honor and respect all three of those men. We need more different people. And everyone talks about Catherine Haleho now because she's this famous evangelical Christian scientist. And it's absolutely fabulous what Catherine is doing. But I mean, she is so incredibly lonely. And she's not the only climate scientist in America who is a religious believer. So why are we always talking about Catherine Hale? I mean, where are the other Christian scientists, not Christian scientists, but scientists who are Christians? I mean, where are they, right? And we know we do have evidence from the evolution debate that it does make a difference. When students hear about, and the person doesn't even have to come to class, there was a great talk at Trippoliest just last month or whatever we were there. I don't know."}, {"content": "Time has stood still since Donald Trump got elected. But there was this great talk about an experiment that faculty at ASU have done where in class, in a biology class, they talk about scientists, evolutionary biologists who are also Christians like Ken Miller, Brown. And it doesn't, you don't need Ken to come to the class. Just talking about it, just having the students read something that he wrote about how he personally recognizes his religious faith with his scientific work. That makes a difference in how students receive the scientific information that they're getting. So we have evidence to say that it does make a difference. And so, and again, though, it's not just about writing a letter to the editor. I think the evidence also tells us that, no, I don't think writing more letters to the Boston Globe is the key thing right now. Oh, forgive me, but that is how I feel. But I think getting out, talking to people in communities, explaining to people how you became a climate scientist, what you've learned, and why it matters. Why it matters to people in the places they live. I think we do have evidence that that can make a difference. We also know that most people, when they vote, you know, they're not voting about, people didn't vote for Donald Trump because he said climate change was a hoax, right? And part of the problem is that people don't see climate change as a problem that affects them and their lives. So we need to do more to talk about what the relationship is between climate change and jobs and storms that do affect you or that affect your crops. And that's a message that I think has not been articulated nearly as fully as it needs to be. Yeah."}, {"content": "Oh, sorry, well, that's right. Okay, so it's alternate sides. I don't know who I'm talking to. Oh, hi. Yeah. I wonder if you could clarify something and just didn't focus quite for me."}, {"content": "And the most thing the last part of you talk. You said you distinguish science from the values and you said the people who are the deniers are really motivated by values. They associate their position with freedom and so on. Now are you saying that the scientists should get in a debate with them about values? You quickly outlined a few values like fairness and accountability and so on. But the scientists aren't expert about values necessarily. And besides which the deniers, it's not like they're... are leading with their values, they're denying the science. And that's something the scientists do know. So how much do you want the scientists to be talking about values and why? Yeah."}, {"content": "OK, that's a great question."}, {"content": "I think you're right, because this is tricky. So the point is, though, when climate change denires attack the science, and scientists then try to answer it with science, it doesn't work. Because first of all, now you're in a debate about the science. And that just, one of the claims of climate change denial is that the science is unsettling. There's a big debate. So if you participate in a debate, now they have won, because you've demonstrated that there's a debate. And we learned this again in the evolution situation, too. If an evolutionary biologist debates a creationist, the evolutionary biologist always loses. Because what the audience hears is, oh, there's a big debate. We don't really know. So the debate framework, when you're debating science, just doesn't work. So then the question is, well, what are some of the alternatives? And so what I'm trying to get at, and it is a little subtle, so maybe I didn't explain clearly, is to expose, to say, look, I understand that there's a value premise here, right? And I understand that you don't want to see the expansion of big government. So let's talk about how we could solve this with small government solutions. So it's a way of shifting the argument. And then I think a scientist can talk about values if they are your own values. Because we all have values. You don't have to be an expert on values to talk about your values. So one of the things I do sometimes is I do talk about accountability. And I say, look, most of us believe in accountability. So let's talk about who made this problem, and who's got the responsibility to fix it. Because one of the strategies that we've also seen being used is the idea that this is the fault of China or India, right? And so it's a way of saying, well, let's talk about the US contribution to climate change. We made this problem, but we also can fix it."}, {"content": "And we can fix it through technologically innovation. And then we can move the conversation into a discussion about grid integration and energy storage. And that moves the conversation where I want it. Because I don't want to be debating whether or not climate change is happening. I want to be debating how do we get better grid integration and energy storage. And then I've got the conversation where I want it to be. And then I can talk to my audience about all this cool stuff that's going on in the technological domain and all the jobs that have been created in green energy in this country, which it turns out almost nobody knows about. Here's a good question."}, {"content": "Again, my postdoc is not allowed to answer. But how many jobs do you think there are in coal in the United States? OK, most estimates say between 20 and 30,000. So this is a highly educated audience. And even you think it's much more than it is. Most people will tell you a million or 500,000, right? There are actually incredibly few jobs in coal mining in this country, despite all the fusing and rhetoric that we've been hearing about the one coal, right? How many jobs do we have now today, not in the future, but today in renewable energy? Anybody care to guess? 500,000? Do I? OK, this is a ridiculously educated audience."}, {"content": "This doesn't work as well. The correct answer, though, even in this wildly educated Harvard audience, 3.5 million. Yeah, who knows that?"}, {"content": "So that's the point. We want to be take, if people are worried about jobs, let's talk about jobs, because actually we have really good evidence on that job front. So does that kind of clarify it a bit?"}, {"content": "Good."}, {"content": "Thank you. Hi."}, {"content": "And I need to add something over here. I don't want this to get into a debate about religion, but I do have a point to make a question to ask. I'm actually from Texas. Don't worry, I'm on your side. And I'm a science advocate among my people. I just mentioned that. My family is chocked full of very religious people. My dad's a Southern Baptist minister. Most of the people in my family are in the ministry. And when I talk to them about this stuff, they don't deny the science. They deny that we'll be here long enough for it to matter. They keep telling me that don't worry, Jesus is coming. And so I wonder where the argument is, what the point we can make is, and if there's hope for even any progress with these kind of people. Yeah."}, {"content": "I don't think there's anything you can do, honestly. No, really."}, {"content": "I mean, I'm teaching science and religion in America, and one of the things that's so interesting about religious belief in America is how incredibly diverse it is. But if people are Millenarians who believe that Jesus is coming, that's all going in pretty soon anyway, I'm not really sure there's much of an argument you can make that would change those people's minds. So it might be better to just move on and work on, you know, I mean, Texas already has a feed and tariff for wind power. But to think about, you know, things you could do to support renewable energy that people might support for other reasons, like it's economically sensible, or some other issue that they might like. I don't know."}, {"content": "I'm sorry, what? I'm sorry. I know you're going to be a little bit more confused. Sorry. What was that?"}, {"content": "What? Do you think that the problem with religious belief is that we care to care to care to be back? We think that. Right. But if you think it's all about to end, right? I mean, if you really, and especially, no, but I mean, this does raise an important issue. I mean, one of the challenges that scientists often face is that things that for us are clearly evidence to support our theories are not necessarily evidence of that for other people. So if you have an eschatological philosophy, and you do believe that the world is about to end, then the intensification of hurricanes, you know, heating of the ocean, depth of coral reefs, things that for us are clearly evidence of climate disruption, for those people could be evidence that we're really getting close. So you can't really win that argument, right?"}, {"content": "And so you might just decide, you know, you need to move on, right? But the fact is, let's face it. I mean, political change doesn't come because everyone agrees on everything. Political change comes because enough people agree on enough things. And so I think that's where again, there are people who are evangelical Christians who might disagree with me on a whole heck of a lot of things, but still might be willing to support solar power because they could see the way in which it might empower their communities, right? Or they might see the way it could bring jobs to their communities. So yeah, yeah."}, {"content": "Oh, sorry, you're next. Okay, go ahead."}, {"content": "Hi. About a month ago, I went to Denver for three days of training with Al Gore's group, the Climate Reality Project. And as part of this free training, I've got an obligation to participate or be involved or organized 10 events during the year. Oh, gosh. As I was thinking about how to meet my obligations, one thing that occurred to me was to turn to my work. I work for a national company in healthcare. It's a billion dollar company. So I sent an email to the owner of the company and he said, oh, sure, let's talk about it. I had a conversation with him yesterday in which he said, well, you know, this is a really good thing, but I concerned about the political angle. Some of our customers and employees might not agree with the message. So as we talked over about half an hour, I was able to pull him around to thinking about this. This is a green initiative. We're doing something good. It's going to benefit people. So we take it out of the political angle. Well, today, Michael Mann gets into it with a Lamar Smith and with Judith Curry at the House Science Committee meetings and it's going to be in New York Times tomorrow and my boss is going to read that. So we've got this political environment going on that's making it difficult for people to take positions because they're afraid of the polarization. You're out there speaking. Catherine Heyho is. Michael Mann is. But where are the rest of the scientists? Well, I mean, that was the question we had earlier, right? And that is part of my argument is that I think that more people and more diverse people need to be involved in this issue. And the more different kinds of people are out there talking, the less this would look like, it would just be a particular political point of view. I mean, the hearing today was an interesting when I got approached by the committee last week. And this is theater, right? So we have to borrow from our colleagues in the theater department and think about how do you respond to a theatrical performance? And so when I'd recommend it, it was too late because they'd already invited Mike to come. And that's okay, Mike's great. But I said don't invite a scientist to respond, right? This is a charade, you know, I mean, it's ridiculous."}, {"content": "You can find three people say almost anything anywhere if you look hard enough. I think what you should do is just fill the chair with all the reports, you know, all the government reports, all the IPCC reports, just stack them and have a giant pile and say that's our response, right? You know, so, you know, we could begin to think creatively."}, {"content": "We don't have to just be pulled in all the time to these, you know, frameworks that we know are wrong and misleading. But we do get sucked into them and it's hard not to, right? It's hard not to think. I mean, it was an interesting moment for me when I realized the House Science Committee, well, the minority is calling me. And I'm telling them don't get a scientist to testify, you know, just bring in a pile of reports, right? And after I wrote, you know, I said that. I hung up the phone and thought, wow, that's an interesting moment, you know, right? So, but, I mean, we do have to be creative. We have to think differently about this, I think, than we have in the past. Okay, thank you. I'm actually related to what you just addressed. But so I'm a PhD student at this point without much public visibility or platform. And I'm just curious what you think are positive and productive venues for scientists to express their expertise to affect real change. Go to a local school, go talk in your church. I mean, we're all part of organizations and networks. And I think what you said about your job and your work is a really important insight. Sometimes we think we don't have access because we don't get invited to Congress so we don't get invited. But, you know, public opinion isn't really being made on the front page of the New York Times as much as the editors and New York Times would like to think that it is. Public opinion is being made by people talking to their friends and their neighbors and in their churches and in their synagogues and in their mosques and in their community groups. So there are opportunities to reach out to people all the time, but we sometimes don't see them because we take for granted what's around us. So I would say, you know, wherever you live, maybe the local library has a lecture series that you could volunteer to speak in. Or give me your phone number and I will tell them to invite you. And I mean, seriously, I get so many more invitations and I could possibly handle. And I'm always looking for other colleagues who I can suggest. So if you want to do talks, let me know. And I'll send, you know, I mean, obviously not everything I get invited to do, you know, they'll take a substitute, but some of those they will. But the point is they're all kinds of opportunities. And, you know, I was thinking about this the other day about being a Harvard professor and I'm going to South Dakota State tomorrow. You know, I think if most of us get invited to speak at Princeton or Chicago or Caltech, of course we go because we see the obvious value for our professional stature to do that. But I think that a lot of colleagues if they got invited to go to South Dakota State would just say no thanks, I'm busy, right? And my thinking about that is completely inverted now. I mean, I should say myself, 15 years ago, I would have probably thought that."}, {"content": "Now it's the other way around. I get invited to go to Princeton, I say, you guys don't need me, South Dakota State, they need me, right? So where I'm going to speak, what I'm accepting now is very different than even five years ago, because I'm really thinking in terms of places where outreach could make more of a difference. So I'm not doing any more teachers and teachers in Cambridge, I'm already told people that. Okay, so anyone's thinking about it, because I don't think this is where we need the action. And I think that all of us should be thinking about what are our points of connection to places where it could make a difference. And that, for a lot of us, means not on the Harvard campus, but it might be in our communities because lots of us live in places where, as I said, people might not be climate deniers, but they may not be very engaged in understanding why this issue is important. So let's just have two more questions, is that okay?"}, {"content": "Yeah, that'd be great, thank you. And then I'm sure, I know we would be happy to. Do what, go home and have a good night's sleep."}, {"content": "Yeah, yeah, yeah, okay. There are other contexts in which scientists are asked to make moral choices. A couple of years ago, Steven Hawking refused to attend a major conference in Israel because he was asked to observe the academic boycott there. Should scientists take a moral stand on very pressing issues of the day, if it's not directly related to their field of inquiry, even though it entails moral obligation in which some of their activities may come in contact with the circumstances that are resulting in various forms of repression in human suffering. Look, I mean, I can't tell other people what to do."}, {"content": "I think those kinds of issues are quite difficult and vexed and people have to decide for themselves. But in general, my view would be, would be no. I do think that as climate scientists or as toxicologists, or as marine biologists, or whatever our field is, that we have a particular role to play as experts. I mean, that's why I use the cartoon about applying the plane. And that's what I'm really most interested in. Now, of course, as human beings, we're going to be making choices all the time about what we think are more or more, or we might make choices about our own safety. I mean, speaking of Texas, I've been to Texas more than once. But I do have reservations now about going back. Now that Texas and universities are allowing students to carry guns on campus. I mean, I find that very problematic and actually potentially a threat to my own personal safety. So I think that we might make choices. We might decide, in particular, situations that we might not go somewhere because it offends our personal sensibilities or because we think it threatens our safety. Or we might just feel that we just need to take a stand. But at the same time, there's always that question of who you're hurting, right? Because when I went to Houston, I guess it was a year or two ago, it was right around the time that the legislature was debating that thing about carrying guns on campus. And I actually almost didn't go. And of course, my colleagues there said the obvious thing, which is if you don't come, you'll hurt us, right? We want to hear you. We, our students need to hear you. So what good does it do if you don't come, right? So there's always that question about who are you impacting through your actions. So I think when you get out and when you talk to people and when you try to be, to listen and be empathetic and understand people's questions and answer them honestly and take people's questions seriously, that's almost always a good thing to do. When you say, I can't go here because of X or Y, I think that's much more complicated, much more fraught. I think that's a good thing."}, {"content": "All right, let's start. I'll turn it on. I can speak through the stuff. I know it's on the screen for you. No, I won't be able to go up. Listen to that now."}, {"content": "Okay, my name's Andrew Bergman. I'm a PhD student here in applied physics and a member of a new group called the Environmental Data and Governance Initiative. And this question is something I'm experiencing, but I'll frame it in terms of the conversation about climate change. I think that sometimes what I notice, and it's sort of related to this question, but more explicitly about expertise within a very specific field. Even when you say someone is a climate scientist, that is a lot of different types of scientists working on a totally disparate set of issues. And sometimes when you go testify in Congress, you're talking about the general science of climate. But the specificity with which people like Oppenheimer and others really understood the nuclear physics they were working on, doesn't necessarily apply in the same sort of general way to climate scientists. And I support scientists who have sort of peripheral or solid understanding advocating. But when we want the specific sort of expertise driven, sort of as you said, like somebody who really is an expert has a very different platform which they can stand and speak, should we as a scientific community be more discerning and actually say like, when you decide to speak out as an expert, be clear about the specificity of your expertise. And don't show up to schools or Congress and say you're an expert just because you have a degree in physics. I mean, I don't think when my friends ask me, tell me about climate science, I say I really don't know. I'm trusting other scientists. And that's the reality."}, {"content": "This is a really important point."}, {"content": "Thank you for raising it. So one of the reasons why I've been thinking about this whole issue of approximate expertise is because it's actually essential if we're going to be able to refute merchants of doubt type claims, right? Because one of the ways that the whole doubt-mongering strategy works is to recruit scientists to be part of this, right? And that was a key strategy that the tobacco industry invented, which was to find scientists to come and speak. Now, in many cases, those people were actually scientists of some kind. They had some kind of scientific training, but they weren't oncologists. They weren't public health officials. They weren't physicians. And Fred Singer, who I talked about, is a classic case in point. I mean, the man was a very intelligent, very highly educated person, but he knew nothing about cancer or bronchitis or emphysema or epidemiology or any of the disciplines that could have been potentially relevant to that case. And that's the key point about what you're saying. So when it comes to climate science, there are many disciplines that are relevant. And there are many angles from which you might enter into the topic with legitimate strong expertise. Just as with tobacco, you could have been a physician. You could have been an epidemiologist. You could have been an oncologist. Many different expertise could have been relevant there. And Singer had none of them. So that should have been a red flag. It should have been a red flag to his colleagues. It should have been a red flag to the media. But it's not, in part, because we don't discern. And that is why I think it's so important that we are discerning and that we also exercise a certain amount of restraint. Right? And I work hard, really hard on this, because I get asked about all kinds of things. And you know, I have, I mean, just the other day, I got asked this question. I went and talked to the EPS graduate students and someone wanted to talk about immigration. And the first thing I said is, I, I, I, I, you know, no, I'm like, I feel like I know a lot of things and immigration isn't one of them. I don't feel like, you know, and I just said, let's talk about other things, right? So being able to say, it's not my area. I really don't know. If I answer that question, I just be giving you my personal opinion. I think that's really important."}, {"content": "Now that said, though, there is one other nuance to add to this. Expertise is not absolute, it's relative. So depending on the context, it might be that even though you're a physicist, you might actually be pretty knowledgeable about evolutionary biology. Maybe you've even read the origin of species. And if somebody asked you a question about it, you might be able to say, well, look, I'm not an evolutionary biologist, but I do know certain things. Or something I sometimes say when I'm asked, I'm not an economist, you know, but some of my best friends are economists. But my economist, my economics colleagues, say that carbon pricing is one of the most effective things we could do to level playing field and pay the true cost, not the price, but the cost of carbon. So you can invoke the authority of other experts that you know or that you've read. And then that invites your audience to say, okay, so if we want to learn more about this, you know, next year we invite an economist to come and speak to you. And you can even give them the names. You could say, well, I am friends with Nick Stern and here's what Nick says about it, right? And that's, I think, legitimate because you've talked to the person you've played attention to their arguments. One time years ago, when I was talking to a group of grad students, a student, and I forget, she was studying choral reefs. It was something to do with marine biology. And she said that she was in a choral group, a singing group, in which one of the other people in the group had asked her about climate change. And it was some element of climate change that was quite far away from what she worked on. And she said she felt really awkward because she felt like she wasn't an expert. But I said to her, you know, that's true. You're not an expert on, you know, tropospheric warming. But in that group, you are the local expert. And people are turning to you because they know that you're getting a PhD. This was at UC Davis. They know you're at Davis. They know Davis is a good school. And by asking you, they're actually saying that they trust you. They want to know what you know about this. And in that situation, I think it is reasonable to say, well, it's not my specialty, but here's what I know. And I think that, so expertise is contextual and relative. And it's about, in a way, it's just about being thoughtful about where your limits of expertise are and being honest about that. And when it goes too far to say, okay, I really can't answer that. I'm sorry. So, and on that note, I can't answer that. On that note. Thank you. Thank you. Thank you."}], "Naomi Oreskes: Why we should trust scientists": [{"content": "Every day we face issues like climate change or the safety of vaccines where we have to answer questions whose answers rely heavily on scientific information. Scientists tell us that the world is warming. Scientists tell us that vaccines are safe. But how do we know if they are right? Why should be believe the science? The fact is, many of us actually\ndon't believe the science. Public opinion polls consistently show that significant proportions of the American people don't believe the climate is\nwarming due to human activities, don't think that there is\nevolution by natural selection, and aren't persuaded by the safety of vaccines. So why should we believe the science? Well, scientists don't like talking about \nscience as a matter of belief. In fact, they would contrast science with faith, and they would say belief is the domain of faith. And faith is a separate thing\napart and distinct from science. Indeed they would say religion is based on faith or maybe the calculus of Pascal's wager. Blaise Pascal was a 17th-century mathematician who tried to bring scientific\nreasoning to the question of whether or not he should believe in God, and his wager went like this: Well, if God doesn't exist but I decide to believe in him nothing much is really lost. Maybe a few hours on Sunday."}, {"content": "(Laughter) But if he does exist and I don't believe in him, then I'm in deep trouble. And so Pascal said, we'd better believe in God. Or as one of my college professors said, \"He clutched for the handrail of faith.\" He made that leap of faith leaving science and rationalism behind. Now the fact is though, for most of us, most scientific claims are a leap of faith. We can't really judge scientific\nclaims for ourselves in most cases. And indeed this is actually\ntrue for most scientists as well outside of their own specialties. So if you think about it, a geologist can't tell you whether a vaccine is safe. Most chemists are not experts in evolutionary theory. A physicist cannot tell you, despite the claims of some of them, whether or not tobacco causes cancer. So, if even scientists themselves have to make a leap of faith outside their own fields, then why do they accept the\nclaims of other scientists? Why do they believe each other's claims? And should we believe those claims? So what I'd like to argue is yes, we should, but not for the reason that most of us think. Most of us were taught in school\nthat the reason we should believe in science is because of the scientific method. We were taught that scientists follow a method and that this method guarantees the truth of their claims. The method that most of us were taught in school, we can call it the textbook method, is the hypothetical deductive method. According to the standard\nmodel, the textbook model, scientists develop hypotheses, they deduce the consequences of those hypotheses, and then they go out into the world and they say, \"Okay, well are those consequences true?\" Can we observe them taking\nplace in the natural world? And if they are true, then the scientists say, \"Great, we know the hypothesis is correct.\" So there are many famous examples in the history of science of scientists doing exactly this. One of the most famous examples comes from the work of Albert Einstein. When Einstein developed the\ntheory of general relativity, one of the consequences of his theory was that space-time wasn't just an empty void but that it actually had a fabric. And that that fabric was bent in the presence of massive objects like the sun. So if this theory were true then it meant that light as it passed the sun should actually be bent around it. That was a pretty startling prediction and it took a few years before scientists were able to test it but they did test it in 1919, and lo and behold it turned out to be true. Starlight actually does bend\nas it travels around the sun. This was a huge confirmation of the theory."}, {"content": "It was considered proof of the truth of this radical new idea, and it was written up in many newspapers around the globe. Now, sometimes this theory or this model is referred to as the deductive-nomological model, mainly because academics like \nto make things complicated. But also because in the ideal case, it's about laws. So nomological means having to do with laws. And in the ideal case, the hypothesis isn't just an idea: ideally, it is a law of nature. Why does it matter that it is a law of nature? Because if it is a law, it can't be broken. If it's a law then it will always be true in all times and all places no matter what the circumstances are. And all of you know of at least\none example of a famous law: Einstein's famous equation, E=MC2, which tells us what the relationship is between energy and mass. And that relationship is true no matter what."}, {"content": "Now, it turns out, though, that there \nare several problems with this model. The main problem is that it's wrong."}, {"content": "It's just not true. (Laughter) And I'm going to talk about\nthree reasons why it's wrong. So the first reason is a logical reason."}, {"content": "It's the problem of the fallacy\nof affirming the consequent. So that's another fancy, academic way of saying that false theories can make true predictions. So just because the prediction comes true doesn't actually logically\nprove that the theory is correct. And I have a good example of that too, \nagain from the history of science. This is a picture of the Ptolemaic universe with the Earth at the center of the universe and the sun and the planets going around it. The Ptolemaic model was believed by many very smart people for many centuries. Well, why? Well the answer is because it made \nlots of predictions that came true. The Ptolemaic system enabled astronomers to make accurate predictions\nof the motions of the planet, in fact more accurate predictions at first than the Copernican theory\nwhich we now would say is true. So that's one problem with the textbook model."}, {"content": "A second problem is a practical problem, and it's the problem of auxiliary hypotheses. Auxiliary hypotheses are assumptions that scientists are making that they may or may not even\nbe aware that they're making. So an important example of this comes from the Copernican model, which ultimately replaced the Ptolemaic system. So when Nicolaus Copernicus said, actually the Earth is not the center of the universe, the sun is the center of the solar system, the Earth moves around the sun. Scientists said, well okay, Nicolaus, if that's true we ought to be able to detect the motion of the Earth around the sun. And so this slide here illustrates a concept known as stellar parallax. And astronomers said, if the Earth is moving and we look at a prominent star, let's say, Sirius -- well I know I'm in Manhattan\nso you guys can't see the stars, but imagine you're out in the country, \nimagine you chose that rural life \u2014 and we look at a star in December, we see that star against the backdrop of distant stars. If we now make the same observation six months later when the Earth has moved to this position in June, we look at that same star and we \nsee it against a different backdrop. That difference, that angular\ndifference, is the stellar parallax. So this is a prediction that the Copernican model makes. Astronomers looked for the stellar parallax and they found nothing, nothing at all. And many people argued that this proved \nthat the Copernican model was false. So what happened? Well, in hindsight we can say \nthat astronomers were making two auxiliary hypotheses, both of which we would now say were incorrect. The first was an assumption \nabout the size of the Earth's orbit. Astronomers were assuming \nthat the Earth's orbit was large relative to the distance to the stars. Today we would draw the picture more like this, this comes from NASA, and you see the Earth's orbit is actually quite small. In fact, it's actually much\nsmaller even than shown here. The stellar parallax therefore, is very small and actually very hard to detect. And that leads to the second reason why the prediction didn't work, because scientists were also assuming that the telescopes they had were sensitive enough to detect the parallax. And that turned out not to be true. It wasn't until the 19th century that scientists were able to detect the stellar parallax. So, there's a third problem as well. The third problem is simply a factual problem, that a lot of science doesn't fit the textbook model. A lot of science isn't deductive at all, it's actually inductive. And by that we mean that scientists don't necessarily start with theories and hypotheses, often they just start with observations of stuff going on in the world. And the most famous example\nof that is one of the most famous scientists who ever lived, Charles Darwin. When Darwin went out as a young \nman on the voyage of the Beagle, he didn't have a hypothesis, he didn't have a theory. He just knew that he wanted\nto have a career as a scientist and he started to collect data. Mainly he knew that he hated medicine because the sight of blood made him sick so he had to have an alternative career path. So he started collecting data. And he collected many things, \nincluding his famous finches. When he collected these finches,\nhe threw them in a bag and he had no idea what they meant. Many years later back in London, Darwin looked at his data again and began to develop an explanation, and that explanation was the\ntheory of natural selection. Besides inductive science, scientists also often participate in modeling. One of the things scientists want to do in life is to explain the causes of things. And how do we do that? Well, one way you can do it is to build a model that tests an idea. So this is a picture of Henry Cadell, who was a Scottish geologist in the 19th century."}, {"content": "You can tell he's Scottish because he's wearing a deerstalker cap and Wellington boots. (Laughter) And Cadell wanted to answer the question, how are mountains formed? And one of the things he had observed is that if you look at mountains\nlike the Appalachians, you often find that the rocks in them are folded, and they're folded in a particular way, which suggested to him that they were actually being\ncompressed from the side. And this idea would later play a major role in discussions of continental drift. So he built this model, this crazy contraption with levers and wood, and here's his wheelbarrow, buckets, a big sledgehammer. I don't know why he's got the Wellington boots. Maybe it's going to rain. And he created this physical model in order to demonstrate that you could, in fact, create patterns in rocks, or at least, in this case, in mud, that looked a lot like mountains if you compressed them from the side. So it was an argument about\nthe cause of mountains. Nowadays, most scientists prefer to work inside, so they don't build physical models so much as to make computer simulations. But a computer simulation is a kind of a model. It's a model that's made with mathematics, and like the physical models of the 19th century, it's very important for thinking about causes. So one of the big questions\nto do with climate change, we have tremendous amounts of evidence that the Earth is warming up. This slide here, the black line shows the measurements that scientists have taken for the last 150 years showing that the Earth's temperature has steadily increased, and you can see in particular\nthat in the last 50 years there's been this dramatic increase of nearly one degree centigrade, or almost two degrees Fahrenheit. So what, though, is driving that change? How can we know what's causing the observed warming? Well, scientists can model it using a computer simulation. So this diagram illustrates a computer simulation that has looked at all the different factors that we know can influence the Earth's climate, so sulfate particles from air pollution, volcanic dust from volcanic eruptions, changes in solar radiation, and, of course, greenhouse gases. And they asked the question, what set of variables put into a model will reproduce what we actually see in real life? So here is the real life in black. Here's the model in this light gray, and the answer is a model that includes, it's the answer E on that SAT, all of the above. The only way you can reproduce the observed temperature measurements is with all of these things put together, including greenhouse gases, and in particular you can see that the increase in greenhouse gases tracks this very dramatic increase in temperature over the last 50 years. And so this is why climate scientists say it's not just that we know that\nclimate change is happening, we know that greenhouse gases are a major part of the reason why. So now because there all these different things that scientists do, the philosopher Paul Feyerabend famously said, \"The only principle in science that doesn't inhibit progress is: anything goes.\" Now this quotation has often\nbeen taken out of context, because Feyerabend was not actually saying that in science anything goes. What he was saying was, actually the full quotation is, \"If you press me to say what is the method of science, I would have to say: anything goes.\" What he was trying to say is that scientists do a lot of different things. Scientists are creative. But then this pushes the question back: If scientists don't use a single method, then how do they decide what's right and what's wrong? And who judges? And the answer is, scientists judge, and they judge by judging evidence. Scientists collect evidence in many different ways, but however they collect it, they have to subject it to scrutiny. And this led the sociologist Robert Merton to focus on this question of how scientists scrutinize data and evidence, and he said they do it in a way he called \"organized skepticism.\" And by that he meant it's organized because they do it collectively, they do it as a group, and skepticism, because they do it from a position of distrust. That is to say, the burden of proof is on the person with a novel claim. And in this sense, science\nis intrinsically conservative. It's quite hard to persuade the scientific community to say, \"Yes, we know something, this is true.\" So despite the popularity of the concept of paradigm shifts, what we find is that actually, really major changes in scientific thinking are relatively rare in the history of science. So finally that brings us to one more idea: If scientists judge evidence collectively, this has led historians to focus on the question of consensus, and to say that at the end of the day, what science is, what scientific knowledge is, is the consensus of the scientific experts who through this process of organized scrutiny, collective scrutiny, have judged the evidence and come to a conclusion about it, either yea or nay. So we can think of scientific knowledge as a consensus of experts. We can also think of science as being a kind of a jury, except it's a very special kind of jury. It's not a jury of your peers, it's a jury of geeks. It's a jury of men and women with Ph.D.s, and unlike a conventional jury, which has only two choices, guilty or not guilty, the scientific jury actually has a number of choices. Scientists can say yes, something's true. Scientists can say no, it's false. Or, they can say, well it might be true but we need to work more\nand collect more evidence. Or, they can say it might be true, but we don't know how to answer the question and we're going to put it aside and maybe we'll come back to it later. That's what scientists call \"intractable.\" But this leads us to one final problem: If science is what scientists say it is, then isn't that just an appeal to authority? And weren't we all taught in school that the appeal to authority is a logical fallacy? Well, here's the paradox of modern science, the paradox of the conclusion I think historians and philosophers and sociologists have come to, that actually science is the appeal to authority, but it's not the authority of the individual, no matter how smart that individual is, like Plato or Socrates or Einstein. It's the authority of the collective community. You can think of it is a kind of wisdom of the crowd, but a very special kind of crowd. Science does appeal to authority, but it's not based on any individual, no matter how smart that individual may be. It's based on the collective wisdom, the collective knowledge, the collective work, of all of the scientists who have worked on a particular problem. Scientists have a kind of culture of collective distrust, this \"show me\" culture, illustrated by this nice woman here showing her colleagues her evidence. Of course, these people don't\nreally look like scientists, because they're much too happy. (Laughter) Okay, so that brings me to my final point."}, {"content": "Most of us get up in the morning. Most of us trust our cars. Well, see, now I'm thinking, I'm in Manhattan, this is a bad analogy, but most Americans who don't live in Manhattan get up in the morning and get in their cars and turn on that ignition, and their cars work, and they work incredibly well. The modern automobile hardly ever breaks down. So why is that? Why do cars work so well? It's not because of the genius of Henry Ford or Karl Benz or even Elon Musk. It's because the modern automobile is the product of more than 100 years of work by hundreds and thousands and tens of thousands of people. The modern automobile is the product of the collected work and wisdom and experience of every man and woman who has ever worked on a car, and the reliability of the technology is the result of that accumulated effort. We benefit not just from the genius of Benz and Ford and Musk but from the collective intelligence and hard work of all of the people who have worked on the modern car. And the same is true of science, only science is even older. Our basis for trust in science is actually the same as our basis in trust in technology, and the same as our basis for trust in anything, namely, experience. But it shouldn't be blind trust any more than we would have blind trust in anything. Our trust in science, like science itself, should be based on evidence, and that means that scientists have to become better communicators. They have to explain to us not just what they know but how they know it, and it means that we have\nto become better listeners. Thank you very much."}, {"content": "(Applause)"}], "1. Introduction and Supply & Demand": [{"content": "[SQUEAKING] [RUSTLING] [CLICKING] JONATHAN GRUBER: This is 14.01. I'm John Gruber, and\nthis is microeconomics. Today, I want to\ncover three things. I want to talk about\nthe course details. I want to talk about\nwhat is microeconomics. And then I'll start the\nsubstance of the course by talking about\nsupply and demand. Couple of the points about\nthe course-- the course will have a distinct sort\nof policy angle to it. I sort of do economic policy,\ngovernment policy is my thing. So I think it's what\nmakes economics exciting and it sort of offers, I\nthink, an interesting angle to understand why we're\nlearning what we're learning. I think sometimes\nin an intro class, it's sort of hard to\nunderstand why the heck you're doing things. However, that's just\nsort of a slight flavor. If you're really more\ninterested in this, I teach a whole\ncourse called 1441. I'm not teaching it\nthis year, but it will be taught by a visitor\nin the spring, Kristin Butcher from Wellesley."}, {"content": "And I'll be teaching next year. That dives much more\ninto these policy issues. So I'm going to use government\npolicy as sort of an organizing theme, but it won't be the\ndominant theme of the class. Finally, three points\nabout my teaching style. I don't write\neverything on the board. We're not in high\nschool anymore. You're actually responsible for\nwhat I say, not what I write. Partly that's because my\nhandwriting is brutal, as you can tell already. So what that means is,\nplease, please do not be afraid to ask me what the\nhell I just wrote on the board. There's no shame in that. Don't just lean to your\nneighbors, and say, what the hell did he\njust write in the board. Ask, me, because if\nyou can't read it, I'm sure someone else can't\nread it, so feel free to ask. And in general, please\nfeel free to engage with questions in this class. The other point of my teaching\nstyle is I talk way too fast. And the longer I go-- there's\na mathematical function, which is the longer I\ngo without interruption, the faster I speak,\nuntil I just spin off. So basically, please\nask questions. If anything is not\nclear, or you just want to ask questions\nabout some related tangent or whatever, please\nfeel free to do so. You might think, how would\nthat work in a class this big? There's always way too\nfew questions, even a class this big. So never be afraid that it\nwill slow me down or whatever. Ask me questions. We have plenty of\ntime on the class. And you'll be doing\nyour classmates a favor, because it'll slow me down. Finally, last point, I\nhave this terrible tendency to use the term \"guys\"\nin a gender neutral way. So this class, I\nlike to see, looks like it's a fairly\nhealthy representation both males and females. When I say \"guys,\"\nI don't mean men. I mean people. I mean people. So women, don't\ntake it personally. \"Guys\" means economic agent. It means people. It doesn't mean men. Just the way-- just\na bad tendency. It drives my wife crazy,\nbut I've decided better to just apologize up front\nthan try to fix it throughout, which is impossible. So let's talk about\nwhat is microeconomics. So fundamentally,\nmicroeconomics-- how people took AP high school Econ? How many people--\nfor how many people was it taught really well? That's about right. That's why I did my high\nschool online class."}, {"content": "That's the answer\nI wanted to hear. So tell your friends\nstill in high school who are taking high school\nEcon, if your high school teacher isn't great,\ntell them to go on EdX and take the class. And help out your friends\nstill in high school. So what is microeconomics? Microeconomics is\nthe study of how individuals and\nfirms make decisions in a world of scarcity. Scarcity is what\ndrives microeconomics. Basically, what\nmicroeconomics is is a series of constrained\noptimization exercises, where economic agents, be\nthey firms or individuals, try to make themselves\nas well off as possible given their constraints. Yeah. AUDIENCE: Will this\ncover irrationality? JONATHAN GRUBER: I will,\nbut not as much as I should. Essentially, we\nhave another course in the department called 1413,\nBehavioral Economics, which gets into that much more. I will sprinkle it\nthroughout, but not as much as I actually\nbelieve in it. In other words, the way\nwe think about economics is it's best to sort\nof get the basics down before you start worrying\nabout the deviations. Find it's better\nto climb the tree before you start going\nout in the branches. So basically, what this\ncourse is then about is it's about trade-offs. It's about given that\nyou're constrained, how do you trade off things\nto make yourself as well off as possible? And behind this notion of\ntrade-offs is going to be-- I'll say about 100 times this\nis the most important thing in the course, so\njust ignore that. But this is one of the\nmost important things. I'll say \"one of the\nmost important\" things in the course, is the\nnotion of opportunity cost. Opportunity cost is a\nvery important concept that we teach, sort of the\nfirst concept we teach, which is that every\naction or every inaction has a cost in that you\ncould've been doing something else instead. So if you buy a shirt, you\ncould have bought pants. If you stayed at\nhome and watched TV, you could have been out working. Everything you do has\na next best alternative you could have done instead. And that is called the\n\"opportunity cost.\" And that's a critical\nconcept in economics, and that is why,\nin some sense, we are referred to casually\nas the \"dismal science.\" Economics is referred to\nas the dismal science. First of all, I'm flattered\nwe're considered a science. But it's called the\n\"dismal science\" because our whole point\nis that nothing is free. There is always a trade-off."}, {"content": "There's always an\nopportunity cost. Anything you do, you could be\ndoing something else instead. And your constrained\noptimization means you're going to\nhave to pass up one thing to do another. Now, some may call it\n\"dismal,\" but as a former MIT undergraduate, I call it \"fun.\" And this is why I think\nMIT is the perfect place to be teaching economics,\nbecause MIT engineering is all about constrained\noptimization. That's what engineering is. And economics is\njust the engine. It's just the principles\nyou learn in engineering applied in different contexts. So if we think about the\n2.007 contests-- that still exist with the robots, 2.007? Yeah, the 2.007 contests,\nthose, as you know, are contests where you're given\na limited set of materials. And you have to build a\nrobot that does some task, like pushing ping-pong balls off\na table or something like that. That's just constraint\noptimization. It's got nothing to\ndo with economics, but it's constrained\noptimization. So just think of microeconomics\nas like engineering, but actually interesting. So think of microeconomics\nas engineering, but instead of\nbuilding something to push a ping-pong ball\noff tables, you actually build people's lives,\nand businesses, and understand the decisions\nthat drive our economy. So same principles\nyou could think of for your engineering classes,\nbut applied to people's lives. And that's why, in fact, modern\neconomics was born in this room, this room or 26.100 by\nPaul Samuelson in the 1940s and '50s, who wrote the\nfundamental textbook that gave birth to modern economics. Because he was here and\napplied the kind of engineering principles of MIT\nto actually develop the field of modern economics. What we'll learn today\nwas developed at MIT, so it's a great place\nto be learning it. Now, with that as background--\nany questions about that, about what is microeconomics? With that as\nbackground, let's turn to our first model we'll talk\nabout this semester, which is the supply and demand model. Supply and demand--\nnow, the way we're going to proceed in this course\nis going to drive you crazy, because we're going to\nproceed by teaching, as the very first\nquestion pointed out, by teaching very\nsimplified models. We're going to essentially--\nwhat is a model? A model is technically\na description between any two or more economic\nvariables or any two or more variables. But unlike the models used\nin all your other classes, these aren't laws, by and\nlarge, they're models. So we don't have a relation\nbetween energy and mass which you can write down. It's a law and you're done."}, {"content": "We have models which are\nnever 100% true, but always pretty true, \"pretty\"\nbeing somewhere between 10% and 95% true. So basically, the idea\nis to make a trade-off. We want to write\ndown in our models a set of simplifying\nassumptions that allow us, with a relatively\nsmall set of steps, to capture relatively\nbroad phenomena. So it's essentially a trade-off. On the one hand,\nwe'd like a model that captures as well as\npossible the phenomena in the real world, like\nE equals Mc squared. But we want to do so in the\nmost tractable possible way so that we can teach it\nfrom first principles, and don't need an arrow to teach\nevery single insight we have. So basically in\neconomics, we tend to resolve that by erring\non the side of tractability. That is why I can teach\nyou the entire field of microeconomics--\nwhich is really sort of-- macro is kind of\na fun application. Micro is really economics. I can teach you the entire\nfield of microeconomics in the semester,\nbecause I'm going to make a whole huge set\nof simplifying assumptions to make things tractable. But the key thing\nis that you will be amazed at what these\nmodels will be able to do. With a fairly simple\nset of models, we will be able to offer\ninsights and explain a whole huge variety\nof phenomena, never perfectly, but\nalways pretty well, generally pretty well. And so that is\nessentially the trade-off we're going to try\nto do this semester. So the line I like\nis the statistician George Box said that all models\nare wrong, but some are useful. Now obviously, it doesn't apply\nto models in the hard sciences, but in the social\nsciences, that's true. And basically, I'm\ngoing to write down a set of models like that. Now, with every model I write\ndown, I'm going to try-- my goal is to have you\nunderstand it at three levels. The first and most\nimportant level is the intuitive\nlevel, the level which you sort of understand. I call it \"passing\nthe Mom Test.\" You can go home and explain\nit to your mom at Thanksgiving or at the end of semester. No offense to dads, just\ncalled it \"the Mom Test.\" So basically, that's\nthe intuitive level. You really understand it in a\nway that you could explain it."}, {"content": "The second is graphical. We were going to do--\nmost of our models here were developed in a\ngraphical framework using x/y graphs that really in\neconomics, we think delivers a lot of shorthand power. And the third is mathematical. The mathematical is probably\nthe least important, but it's the easiest\nto test you on."}, {"content": "So we're going to need to know\nthings mathematically as well. So let's start by considering\nthe supply and demand model by using\nthe famous example brought up by Adam Smith. Adam Smith is sort of considered\nthe father of economics. If Paul Samuelson is the\nfather of modern economics, Adam Smith is the\nfather of all economics. His 1776 book, The\nWealth of Nations did an incredible job\nof actually laying out the entire core of\nthe economics field-- no math, just words,\nbut he just nailed it. And one of his most\nfamous examples was the water diamond paradox. He said, think about\nwater and diamonds. He said, start with water. Nothing is more important\nfor life than water. It's the building\nblock of all of life. Even when we look for\nlife on other planets, we always start by\nlooking for water. Now think of diamonds, one\nof the more frivolous things you can buy, certainly\nirrelevant to leading a successful or happy or\nproductive life, or any life. Yet for most of us,\nwater's free and diamonds are super expensive. How can this be,\nAdam Smith asked. Well, the answer he posed is\nthat what I first described was just demand. That is, we demand\nlots of water. We demand fewer diamonds. But we have to match that\nwith the concept of supply. And the supply of water\nis almost infinite, while the supply of diamonds--\nmaybe not naturally, maybe it's through decisions\nof various businesses-- but it's somewhat limited. So basically what\nhe developed is what we call the \"supply\nand demand scissors\"-- that you can't just think of\nsupply or demand in isolation. You have to put\nthem together if you want to explain the real world\nphenomena we see, like the fact that water is cheap and\ndiamonds are expensive. So let's just about an example. So there's one graph\nthat was handed out in the back, which\nis, let's talk about the market for roses. So in the market for roses,\nwe have a demand curve and a supply curve. So what we have here-- this\nis the kind of x/y graph we're going to look at all\nthroughout the semester. On the x-axis is the\nquantity of roses. On the y-axis is\nthe price of roses. The blue, downward-sloping\nline is the demand curve. Now, what I'm going to do here,\nI'm just giving you a overview. We are going, over the next\nfive or six lectures, dive into where this demand\ncurve comes from. We'll go to first principles\nand build it back up. But for now, what\nwe know of a demand curve is it simply\nrepresents the relationship between the price of a good\nand how much people want it. Therefore, we assume\nit is downward sloping. At higher prices, people\nwant less of the good. And we'll derive where\nthat comes from shortly, starting next lecture. But for now, I think\nit's pretty intuitive that if the price\nof roses is higher, people want fewer of them. And that's why it's\ndownward sloping. Basically, as the\nprice of roses goes up, people want fewer roses. The yellow curve is\nthe supply curve. Now, after we've derived\nthe demand curve, we'll then go and\nspend about 12 lectures deriving the supply curve. That's a bit harder. But once again, we'll\nstart from first principles and build it up. For now, you just need to\nknow that's how much firms are willing to supply,\ngiven the price. So basically, as\nthe price goes up, firms want to\nproduce more roses. The higher price means\nyou make more money, so you want to\nproduce more of them. This is slightly less\nintuitive than demand, but we'll derive it and\nexplain how it can be. But for now, just go\nwith the basic intuition that if you're making\nsomething, and you can sell it in the market for\na higher price, you're going to want\nto make more of it. And that leads to the\nupward sloping supply curve. Where the points meet is\nthe market equilibrium. Where supply and demand meets\nis the market equilibrium. And that is the point where\nboth consumers and producers are happy to make a transaction. Consumers are happy because\non their demand curve is the $3 and 600 roses. That is, they are willing\nto buy 600 roses at $3. Producers are happy,\nbecause on their supply curve is the same point. They are willing to\nsupply 600 roses at $3. That is the one point\nwhere consumers are happy and producers are happy. Therefore, it's\nthe equilibrium-- highly non-technical, but\nthat's the basic intuition. The point at which they're\nboth willing to make that transaction, the\npoint at which they're both satisfied with\nthat transaction, is the equilibrium, which\nin this case is $3 per rose and 600 roses. Now, this raises\nlots of questions. Where did the curves come from? How does equilibrium\nget achieved? Why the heck do we give roses? These are a bunch of questions."}, {"content": "We will come to\nall these questions over the next set of lectures. But the basic thing\nis to understand this intuition of Adam Smith's\nsupply and demand model. Questions about that? Now, this model also raises\nanother important distinction that we'll focus\non this semester and is easy to get mixed up. So I want you to, if\nyou're ever unclear, I want you to ask me about it. And that's the distinction\nbetween positive versus normative analyses--\npositive versus normative. Positive analysis is the\nstudy of the way things are, while normative\nanalyses is the study of the way things should be. A positive analysis is the\nstudy of the way things are, while normative\nanalysis is the study of the way things should be. Let me give you a great\nexample, which is eBay auctions."}, {"content": "Auctions are a terrific example. They're like the\ntextbook example of a competitive market. You can see it in your head-- demand comes as a bunch of\npeople going on and bidding. People who want\nit more bid more, so you actually\nget a demand curve. The higher the price, the fewer\npeople you're getting to bid. Supply is how many units\nof it are for sale on eBay. You bid until those two meet. And then you have a\nmarket equilibrium at that bidded price. Now, one example\nof an eBay auction that got a lot of attention\na number of years ago, early in the days\nof eBay, was someone offered their\nkidney for auction. They said, look,\nI got two kidneys."}, {"content": "You only need one to live. There are people out\nthere who need a kidney. I'm putting my kidney\non eBay for auction. And what happened,\nbidding went nuts. It started at $25,000. It climbed to $5 million before\nthe auction was shut down, and eBay decided\nthey wouldn't allow you to sell your body on\neBay, bodily parts on eBay. So this raises two questions. The first is the\npositive question, why did the price go so high? So what's the answer to that? What's the answer to\nthe positive question? AUDIENCE: Somebody\nwanted a kidney. JONATHAN GRUBER: Good\nanswer, but let's raise hands and give answers. That's part of it."}, {"content": "Yeah. AUDIENCE: Low\nsupply, high demand. JONATHAN GRUBER: Low\nsupply, high demand. Demand is incredibly high,\nbecause I'd die without it. Supply is low, because\nlike not a lot of us are willing to\nsell their kidneys on eBay So low supply, high\ndemand led to a high price-- Adam Smith at work. That's the positive analysis. But then there's the\nnormative question, which is, should you be allowed to\nsell your kidneys on eBay? That's the normative question."}, {"content": "The positive question is,\nwhat happens if you do? The normative question\nis, should you? Now, the standard\neconomics answer to start would be, of course you should. We're in a world where\nthousands of people die every year because there's\na waiting list for a kidney transplant. and these are people who would\nhappily pay a lot of money to stay alive, I presume. Meanwhile, there's\nhundreds of millions of people walking around with\ntwo kidneys who only need one. And many of these\npeople are poor. And lives could be changed\nby being paid $1 million for their kidney, and might be\nhappy to take the risk that one kidney will be fine, as\nit is for most everyone for most of their\nlife, in return for having a life-changing\npayment from a stranger. So economists say, look-- here's a transaction that\nmakes both parties better off. The person who gets the\nkidney gets to stay alive, and they are willing to\npay a huge amount for that. The person who sells the\nkidney in most probability is fine, because\nalmost all of us can make it through life\nfine with one kidney, and create a life-changing\namount of money that could allow them to pursue\ntheir dreams in various ways. So that's the standard\nargument, would be, yeah, you should be able to\nsell your kidneys on eBay. So the question is, why not?"}, {"content": "Why would we want to\nstop this transaction? What are the\ncounter-arguments to that?"}, {"content": "Let's raise our hands."}, {"content": "Yeah. AUDIENCE: Potentially, I\nthink maybe the issue is because on eBay, there's\nno way to regulate it or you don't necessarily know. People could be like selling\nfake kidneys, per se. JONATHAN GRUBER: Right. So the first type\nof problem comes out of the category we\ncall \"market failures.\" Market failures are reasons\nwhy the market doesn't work in the wonderful\nway economists like to think it should. So for example,\nthis answer puts up there could be the\nproblem of fraud. People might not be\nable to tell if they're getting a legit kidney or not. There could be the example\nof imperfect information. Do you know what the\nodds are that you can spend the rest of your\nlife with only one kidney? I don't either. We ought to know that before\nwe start selling our kidneys. There could be\nimperfect information."}, {"content": "This is one type of problem,\nwhich is the market, maybe the market may fail. Yeah. AUDIENCE: Well, the\ncurrent system also holds people who are poor\nand have a failed kidney-- and which are people who would\nbe completely screwed otherwise in the [INAUDIBLE] system. JONATHAN GRUBER:\nA second problem is what we call\n\"equity\" or \"fairness.\" Equity or fairness, which is\nwe would end up with a world where only rich people\nwould get kidneys. Currently, there's a bunch of\nvoluntary donors and people who are in accidents who\nhave kidneys left over. And those go to people\non the basis of where they are on a waiting list. It's actually a\nprioritized waiting list. It's kind of a cool-- one of my colleagues, Nikhil\nAgarwal, if you think about-- I'll talk a lot this semester\nabout the imperialistic view of economics, all the\ncool things we can study. So he actually uses\neconomic models to study the optimal way to\nallocate organs to individuals. now it's just done\nbased on a waiting list, but it may be that someone\nfurther down the waiting list needs it more than someone\nhigher up the waiting list because they're more\ncritical or whatever. So there's various\noptimal ways to allocate. But certainly, the\noptimal way to allocate wouldn't be the rich\nguy gets it first. That would be unlikely to be\nwhat society would necessarily want. So there's an equity\nconcern with that. What else?"}, {"content": "What other-- yeah. AUDIENCE: In that\nsituation, since you know you can make money\noff of selling kidneys, and you take advantage\nof people, it's very bad, the black market for kidneys. JONATHAN GRUBER: Right, so\nthere's sort of a third-- it's related to\nfraud, but there's sort of a third\nclass of failures that gets into the question\nabout behavioral economics that was raised earlier, which\nwe could just call behavioral-- it's called\n\"behavioral economics,\" for want of a better term,\nwhich is essentially, people don't always\nmake decisions in the perfectly rational,\nlogical way we will model them as doing so this semester. People make mistakes. That's a word we hate\nusing in economics. We hate saying \"mistakes.\" Ooh, boo, mistakes--\nnobody makes mistakes. We're all perfectly\neconomic beings. But we know that's not true. Increasingly over the\npast several decades, economists have started\nincorporating insights from psychology into our\nmodels, to not just say people make mistakes,\nthat their lackadaisical, but to rigorously model the\nnature of those mistakes and understand how\nmistakes can actually happen due to various cognitive\nbiases and other things. In this world, you can imagine\npeople could make mistakes. They could not really\nsit down and quite understand what\nthey're doing, and they could have sold their\nkidney when it's really not in their own long-term interest. Yeah. AUDIENCE: Would\nanother example be if there's a family that\nis in extreme poverty, even though they\nonly have one kidney, they might sell the other\none, just to get more money for the family, per se? JONATHAN GRUBER: Well, in\nsome sense that would be, once again-- if we took this factor out,\nif the market works well with its behavioral\neffects, we'd say, you know, that's their decision. If they otherwise they\nstarve, who are you to say? But once you choose\nthis, say, wait a second, maybe they're not evaluating\nthe trade-offs correctly. Even if there's no fraud, even\nif there's perfect information, they may not know how to process\nthat information correctly. But that is not\nstandard economics."}, {"content": "That's not what we'll spend a\nlot of time on in the semester, but it's obviously realistic. So those are a bunch of good\ncomments, great comments. And yeah. AUDIENCE: Also, in\ninelastic demand, such that people\nalways need kidneys-- JONATHAN GRUBER: That won't\nturn out to be a problem. That doesn't turn\nout to be a problem. We'll come back--\nthat's a great comeback that we talk about the\nshape of demand curves. We want to return to that\nquestion in a few lectures, but that doesn't\nactually cause a problem. It's just that's more of\na positive thing about why the price is so high, but it's\nnot a normative issue about whether you should\nallow it or not. So basically,\nthese are exactly-- to me, honestly, I spend\nmy life thinking a lot about these things. I think these are really\ninteresting issues. But you can't get to\nthe normative issues without the positive analysis. You do the positive\nanalysis to understand the economic framework\nbefore you start jumping to drawing conclusions. That's no fun. We all want to jump\nto draw conclusions, saying this should happen,\nthis shouldn't happen. You can't do that."}, {"content": "We have to be disciplined. We have to start with the\nfundamental economic framework. And basically, the bottom line-- I said I'll teach this\ncourse with a policy bent, but you have to recognize\nthat economics at its core is a right-wing science. Economics at its\ncore is all about how the market knows best, and that\nbasically governments only mess things up. That's sort of the\nbasic, a lot of what we'll learn this semester. As the semester\ngoes on, we'll talk about what's wrong\nwith that view and how governments\ncan improve things. Indeed, I teach a whole\ncourse about the proper role of government the economy. But the standard of economics\nis, \"the market knows best.\" And that leads us to the last\nthing I want to talk about, which is basically, how freely\nshould an economy function? Let's step back to\nthe giant picture. Let's step back from\na market for roses to the entire economy. How freely should a market,\nshould an economy function? We have what's known as\na \"capitalistic economy.\" In a capitalistic economy,\nfirms and individuals decide what to\nproduce and consume, maybe subject to some rules of\nthe road set by the government. There's some minimum\nrules of the road to try to avoid fraud\nor misinformation, but otherwise, we\nlet the dice roll. Firms let consumers\ndecide sort of what to do. Now, this has led to\ntremendous growth. America was not\na wealthy nation, was not a very wealthy\nnation 100 years ago, or 150 years ago. Led to tremendous\ngrowth, where we are now the most powerful, still the\nmost powerful and wealthiest nation the world, largely driven\nby the capitalistic nature of our economy. On the other hand,\nwe are a nation with tremendous inequality. We are by far the most unequal\nmajor nation in the world. The top 1% of Americans has a\nmuch higher share of our income than in any other large\ncountry in the world, any other large developed\ncountry in the world. The bottom 99% has less of\nour income corresponding with anywhere else. So it's led to major inequality. And it's led to other problems. It turns out that the\ngovernment can't appropriately set the rules of the road to\navoid things like fraud, as we saw with Enron, if you\nremember back to that, or a lot of what happened\nin the financial meltdown. It turns out it's\nhard to get people perfect information, et cetera. So we've seen the problems. We've grown very\nwealthy as a nation. We've introduced a whole set of\nproblems through this system. Now, the other extreme is what's\ncalled the \"command economy.\" Rather than a\ncapitalist economy, it's what's called\na \"command economy.\" In this case, the government\nmakes all the production and consumption decisions. The government doesn't just\nset the rules of the road, the government owns the road. The government says, we're\ngoing to use this many cars this year. And people can get\nthem in some way. It could be a lottery,\ncould be waiting in line. How do we decide how\nto allocate them? We're not going to let\nthe market allocate them. We, the government,\nwill allocate them. We'll allocate how many get\nproduced and who gets them. And this was the model\nof the Soviet Union that I grew up with. This was the pre-1989\nSoviet Union. The government decided how many\nshirts, cars, TVs, everything. It's sort of bizarre\nto think that literally everything the government\ndecided how much to produce. And by and large, the government\ndecided who got it partly through corruption-- that\nis, the party members, party leaders got it first-- and often just through waiting\nin line for the remaining application. Now in theory,\nthis ensured equity by making sure that\neverybody had shot at things. In practice, it didn't\nwork well at all and actually was\nwhat dragged down the collapse of the\nold Soviet economy, was that the command\nmodel simply doesn't work. Partly there's just too many\nopportunities for corruption. When the government\ncontrols everything, that means there's no checks\nand balances on the opportunity for enormous corruption. The capitalist economy puts\nsome natural checks and balances on that. And partly because it\nturns out that it's hard to control human nature. And Adam Smith had it right. Adam Smith talks about\nthe \"invisible hand\" of the capitalist economy. The invisible hand is\nbasically the notion that the capitalist\neconomy will manage to distribute things roughly in\nproportion to what people want. And that's where\nfolks want to be."}, {"content": "Folks who want a\ncertain kind of car are going to want to\nget to that kind of car, and if the government\nhas it wrong, they're going to get upset. And it's going to lead to\na less functional economy. So basically, Adam\nSmith's view is that-- the invisible hand view is that\nconsumers and firms serving their own best interest will\ndo what is best for society. So the fundamental core\nof the capitalistic view is that consumers and firms\nserving their own best interest will do what ends up\nbeing best for society. And that's essentially\nthe model we'll learn to start in this course. Yeah. AUDIENCE: In that\ndefinition, are we defining the best for\nsociety as in everybody has the most money? Or everyone has the best health\nor the best standard of living? What is the best [INAUDIBLE]? JONATHAN GRUBER: Great question."}, {"content": "We're going to spend a lot\nof the semester talking about that. For now, we're going to\ndefine \"best for society\" as the most stuff gets\nproduced and consumed. That's how we're\ngoing to find it-- obviously raises a set\nof issues about what about pollution, what\nabout health, et cetera. We're going to come to those,\nbut for the first two-thirds of the course \"best\nfor society\" means what we're going to call\n\"maximum surplus,\" which is the most stuff gets\nproduced that people value. So that's how we're\ngoing to do it. And in his view, the\ninvisible hand does that. And by and large, it's a very\nhelpful framework to turn to. However, at least it\ncan lead to outcomes that are not very fair. So the way we're going\nto proceed in this course is we're going to start\nby talking about how Adam Smith's magic works. How does the magic happen? How does individuals\nand firms acting in their own self-interest,\nwithout caring about anybody else, end up yielding\nthe largest possible productive economy? How does that happen?"}, {"content": "And we're going to\ntalk about that. We'll start with\ndemand, which is how do consumers\ndecide what they want given their resources. We'll talk about the principle\nof utility maximization, the idea that I have\na utility function that I can mathematically\nwrite down what I want. I'll have a budget constraint,\nwhich is the resources I have, and those two\nconstrain optimization. We'll say given what I want\nand the resource I have, what decisions do I make? Boom, we get the demand curve. Then we'll turn to supply, and\nwe'll talk about how do firms decide what to produce. That's much more\ncomplicated, because firms have to decide\nwhat inputs to use and what outputs to produce. And we'll talk about\nhow firms can operate in very different markets. There is a competitive market\nthat Adam Smith envisioned, but that doesn't always work. Sometimes we get\nmonopoly markets, where one firm dominates. And you can actually\nhave outcomes which aren't the best\npossible outcome, even with the invisible hand. So we'll talk about\ndifferent kinds of markets. Then we'll put it together\nto get market equilibrium, and talk about\nSmith's principles. And then from there, we'll\ntalk about how it breaks down in reality, different\nchange in reality, how there are various\nmarket failures that can get in the way, why we\nhave to care about equity and what implications that has,\nabout behavioral economics, about a set of other factors. So that's basically how we're\ngoing to proceed this semester. As I said, the\nlectures are important, but the recitations are as well. Once we're sort of\nin steady state, the recitations will be about\nhalf new material and half working through problems\nto help you prepare for that next problem set. So the way the problem\nsets are going to work is the problem set\nthat's assigned will cover material that's\ntaught up to that date. So for example, problem\nset one is going to be assigned next Friday. That will cover everything\nyou've learned up through next Wednesday. Therefore, in section\non next Friday, we'll do a practice problem\nwhich you should understand because it'll cover things\nthat were taught in class, and help prepare you\nfor the problems. And we'll do that every week. That's about half the section. The other half of the\nsection will be new material. This Friday, the section on\nFriday is all new material. What we do on Friday is\ncover the mathematics. I don't like doing math. I always get it wrong. So I leave math for the TAs,\nwho are smarter than I am. So this Friday, we'll be doing\nthe mathematics of supply and demand, and how you\ntake the intuition here and the simple\ngraphics, and actually turn it into mathematical\nrepresentations, which is what you need for the problem sets. That's this Friday. Then we'll come back\non Monday and start talking about what's\nunderneath the demand curve. All right, any other questions? I'll see you on Monday."}], "1. Course Introduction and Newtonian Mechanics": [{"content": "Professor Ramamurti\nShankar: This is a first part of the year-long course\nintroducing you to all the major ideas in physics,\nstarting from Galileo and Newton right up to the big\nrevolutions of the last century, which was on relativity and\nquantum mechanics. The target audience for this\ncourse is really very broad. In fact, I've always been\nsurprised at how broad the representation is. I don't know what your major is; I don't know what you are going\nto do later so I picked the topics that all of us in physics\nfind fascinating. Some may or may not be useful,\nbut you just don't know. Some of you are probably going\nto be doctors and you don't know why I'm going to do special\nrelativity or quantum mechanics, but you don't know when it will\ncome in handy. If you're a doctor and you've\ngot a patient who's running away from you at the speed of light,\nyou'll know what to do. Or, if you're a pediatrician\nwith a really small patient who will not sit still,\nit's because the laws of quantum mechanics don't allow an\nobject to have a definite position and momentum. So these are all things you just don't know when they will\ncome in handy, and I teach them because these\nare the things that turn me on and got me going into physics\nand whether or not you go into physics,\nyou should certainly learn about the biggest and most\ninteresting revolutions right up to present day physics. All right. So that's what the subject\nmatter's going to be, and I'm going to tell you a\nlittle bit about how the course is organized. First thing is, this year it's going to be\ntaped. You can see some people in the\nback with cameras as part of an experimental pilot program\nfunded by the Hewlett Foundation and at some point they will\ndecide what they will do with these lectures. Most probably they'll post them somewhere so people elsewhere\ncan have the benefit of what you have sitting in the classroom. So I've been told that from now on we just ignore the camera and\ndo business as usual. Nothing's going to be changed. I tried to negotiate a laugh track so that if the jokes don't\nwork we can superimpose some laughter. I was told \"no.\" I just got to deal with it as\nit happens. So it's going to be--it's like\none of the reality shows where things are going to be as they\nare and hopefully after a while we'll learn to act and behave\nnormally and not worry about its presence. Then, coming to the rest of the details of the course. By the way, there are more details on the website that I\nposted, that was given to me by the university,\nif you want to know more about what all this is about. The course organization is fairly simple. We're going to meet Monday and Wednesday in this room,\n11:30-12:45. I will give you some problems\nto do on Wednesday and I'll post them on the website. You guys should get used to going to the class' website. I'm really, really dependent on that now. I finally learned how to use it. I will use that to post\ninformation, maybe once in a while send e-mail to the whole\nclass. If you want to get those\ne-mails, you got to sign up for the course because I push a\nbutton and it goes to anybody who's signed up there. The homework will be given on Wednesday and it's due before\nclass the following Wednesday. Let me introduce you to our\nhead TA, Mara Daniel, who's recently Mara Baraban. So Mara's going to be the\nperson who will see you after class and she will take the\nproblem sets that you have submitted before class and\nshe'll give you the graded ones after class. Okay? That will be sorted up,\nit'll be up there. So you should drop the homework\nbefore you come into class, rather than furiously work on\nit during class, and the solutions will be\nposted the same afternoon. So there is not much point in\ngiving homework that's late. But once in a while,\nyou know, you will come up with a reason that I just cannot\nargue with. You got married,\nyou're getting a transplant, whatever it is. That's fine. You got a transplant,\nI want to see the old body part. You got married, I want to see your spouse. If something happened to a grandparent, I'm counting. Up to four I don't get suspicious. Go five, six, seven, eight,\nI will have to look into the family tree."}, {"content": "But, you know, any reasonable excuse will be\nentertained. Relative importance given to\nthese different things, there's 20% for your homework,\n30% for the Midterm, which will be sometime in\nOctober, and 50% for the Final. That'll be the weighted average. But I have another plan called the \"Amnesty Plan\" in which I\nalso compare just your final grade,\nwhat you did on the Final exam, and whichever is higher of the\ntwo is what I will take to determine your overall course\ngrade. This is something I used to\nannounce near the end but then some people felt that it's not\nfair not to know this from the beginning. So, I'm telling you from the beginning, but don't dream and\nthink that somehow the Final's going to be so much different\nfrom your regular day-to-day performance,\nbut to give you some reason to live after the Midterm. So, you feel there is hope. I can change everything\novernight; it does happen. I put that in for a reason because sometimes some of you\nhave not taken a physics course and you don't know how to do\nwell in physics and slowly you catch on and by the time it's\nFinal exam you crack the code; you know how to do well. As far as I'm concerned, that's just fine. If at the end of the semester you take a three-hour exam in a\nclosed environment and you answer everything,\nI don't care what you did in your homework or your Midterm. That's not relevant."}, {"content": "So that's how the grading will\nbe done. We have Mara's group of TAs. She is the head TA and she's the one you should write to\nwhenever you have a problem. Then we also have two faculty\nmembers. One is a Postdoctoral Fellow,\nMark Caprio. So he will have a discussion\nsection on Tuesdays between 1:00-2:00 in Sloane Lab. And Steve Furlanetto--I don't know if Steve is here or not. There's Steve, our new Assistant Professor. He will have his section on Tuesday night in Dunham Lab,\nin Room 220. Tuesday night is the night when\nyou people realize homework is due on Wednesday. So we know that, so he will be there to comfort\nyou and give you whatever help you need. All right. My own office hours I've not\ndetermined yet. I will have to find out when it\nis good for you. You know, I live and work out\nof Sloane Lab up on the hill and it was easy to have office hours\nbefore or after class but now you have to make a special trip. So, just give me a little bit of time to find out maybe by\nsoliciting e-mail responses from you what would be a good time\nfor my office hours. But for any procedural things,\nlike, you know, this problem set was not graded\nproperly, and so on, there's no point\ne-mailing me because I'm going to send it to Mara anyway. So directly deal with the powers that be. Okay, finally I want to give you some tips on how to do well\nin this course and what attitude you should have. First, I advise that you should come to the lectures. It's not self-serving; it's not so much for my benefit. I think there is something useful about hearing the subject\npresented once orally. Secondly, the book,\nyou can see, one of you had a book here,\nit's about 1,100 pages and when I learned physics it was,\nlike 300 pages. Now, I look around this room,\nI don't see anybody whose head is three times bigger than mine,\nso I know that you cannot digest everything the books\nhave. So I have to take out what I\nthink is the really essential part and cover them in the\nlecture. So, you come to class to find\nout what's in and what's not in. If you don't do that,\nthere's a danger you will learn something you don't have to,\nand we don't want that. Okay, so that's why you come to\nclass. Second thing,\nmost important thing for doing well in physics,\nis to do the homework. The 20% given to the homework\nis not a real measure of how important it is. Homework is when you really figure out how much you know and\ndon't know. If you watch me do the thing on\nthe blackboard, it looks very reasonable."}, {"content": "It looks like you can do it but the only way you're going to\nfind out is when you actually deal with the problem. That's the only time you're going to find out. So, I ask you to do the problems as and when they're\nposted. So if I post it on Wednesday to\ncover the material for that week, then you should attempt it\nas quickly as possible because I'm going to assume you have\ndone the problems when you come for the next few lectures. And in doing the homework, it is perfectly okay to work in\ngroups. You don't have to do it by\nyourself. That's not how physics is done. I am now writing a paper with two other people. They are my experimental colleagues who write papers with\n400 other people, maybe even 1,000 other people. When they do the big collider experiments in Geneva or\nFermilab, collaborations can run into hundreds. So, it's perfectly okay to be part of a collaboration,\nbut you've got to make sure that you're pulling your weight. You've got to make sure that if you explain to others how to do\nthis problem, then somebody else contributes\nto something else, but you know what everybody\ncontributed in the end. So the game is not just to\nsomehow or other get the solution to the problem set but\nto fully understand how it's done,\nand the TAs will be there to help you. Every day there's going to be a TA in the undergraduate lounge. I would urge you to use that. That's a beautiful new lounge\nthat the Provost's Office allowed us to build for\nphysicists and chemists, or whoever happens to be in the\nbuilding. If you go there on the third\nfloor of Sloane, you may run into other people\nlike you who are trying to work on problems. You may run into upper-class students, students who are more\nadvanced, you will run into your TA. So that's a good climate. There are coffee machines and\nthere are lounge sofas and everything else. There are computers, there are printers,\nso it's a good lounge, and I think if you go there one\nday a week to do your problem sets,\nmore often that's a good meeting place,\nI recommend that. The final piece of advice,\nthis is very important so please pay attention to this,\nwhich is, I ask you not to talk to your neighbors during\nlecture. Now, this looks like a very\ninnocuous thing, but you will find out,\nit is the only thing that really gets my back up. Most of the time I don't really care. I'm really liberal, but this disturbs me because I\nam looking at you, I'm trying to see from your\nreaction how much of my lecture you are following,\nand then it's very distracting when people are talking. So please don't do that. If you talk,\nI am going to assume you are talking about me. If you laugh, I'm going to assume you are\nlaughing at me. That's not really what I think,\nbut that's how disturbing it is when people talk,\nand very nice students who do not realize this often disrupt\nmy line of thinking. So I ask you to keep that to a\nminimum. Once in a while you'll have to\ntalk to your neighbor and say, \"Can you please pass me my\npacemaker that fell down?\" That's fine. Then you go back to your business."}, {"content": "But don't do too much of that. Finally, there is this ancient\nissue about sleeping in class. Now, my view is,\nit's just fine, okay. I know you guys need the rest and interestingly,\nthe best sleepers are in the first couple of rows. I haven't met you guys. It's not personal. I have found some people really have to come to the first and\nsecond row because they claim that if they don't hear me they\ncannot really go to sleep. Now, that was true in Sloane\nbut I think Luce has got very good acoustics so you can\nstretch out in the back. But my only criterion is if you\ntalk in your sleep, now that's not allowed because\ntalking is not allowed. Next, if you're going to sleep,\nI ask you to sit between two non-sleepers because sometimes\nwhat happens, the whole row will topple over. We don't want the domino effect. Now, it's going to be captured\non tape and that's going to be really bad for my reputation,\nso spread yourself around other people. All right. So that's it in terms of class,\nyou know, logistics and everything. I'm going to start going into the physics proper. I will try to finish every lecture on time,\nbut sometimes if I'm in the middle of a sentence or the\nmiddle of a derivation, I may have to go over by a\ncouple of minutes; there's no need to shuffle your\nfeet and move stuff around. I know what time it is. I also want to get out like you guys, but let me finish\nsomething. Other days I may finish a few\nminutes before time. That's because the ideas of\nphysics don't fall into 75-minute segments and sometimes\nthey spill over a little bit. Also, I'm used to teaching this\ncourse three times a week and now it's suddenly twice a week,\nand so things that fell into nice 50-minute units are now\nbeing snipped up different ways so it's pretty difficult. So, even for me, some of it will be new and the\ntiming may not be just right. I should tell you first of all\nthat in this class, the taping is not going to\naffect you because the camera is going to be behind your head. I mentioned to you in the website that this is not the big\nopportunity you've been looking for to be a star. Only the back of your head will be seen. In some cases, the back of the head could be\nmore expressive than the front, in which case this is your\nopportunity and I wish you luck. But otherwise,\njust don't worry about it because you will be only heard."}, {"content": "You may not even be heard. So, I've been asked that if a\nquestion is not very clear, I should repeat it so that\npeople listening to it later will know what the question was. Let me make one thing very\nclear. That is, I'm not in favor of\nyour talking to each other because you're distracting. Your stopping me at any time is just fine. I welcome that because I've seen this subject for God knows\nhow many years. The only thing that makes it\ndifferent for me is the questions that you people have. You can stop me any time and you should not feel somehow you\nare stopping the progress of the class. There is no fixed syllabus. We can move things around and\nit's far more exciting for me to answer your questions than to\nhave a monologue."}, {"content": "So, don't worry about that. So stop me anytime you don't follow something,\nand don't assume that you're not following something because\nthere's something wrong with your level of comprehension. Quite often, you guys come up with questions\nthat never cross my mind, so it's very interesting."}, {"content": "And things we've been repeating year after year after year,\nbecause they sound so reasonable,\nsuddenly sound unreasonable when some of you point out some\naspect of it that you didn't follow. So, it could be very interesting for all of us to\nhave issues to discuss in class, and quite often some questions\nare very common and your classmates will be grateful to\nyou that you brought it up. Otherwise, you know,\nTAs get ten e-mails, all with the same question. Okay."}, {"content": "So I'm going to start now. Anybody have any questions about class? The format? The Midterm? The exams? All right."}, {"content": "Yes? Student:\nYou said there's going to be two hours to be announced. How do we wait for [inaudible] Professor Ramamurti\nShankar: Oh, you mean my office hours? Student: No. I thought there was an\n[inaudible] Professor Ramamurti\nShankar: No, the discussion sections are\nTuesday afternoon from 1:00-2:00,\nand Tuesday night from 8:00-10:00, and the website has\ngot all the details on when and where. Yes? Student:\nSo the lab times will still be [inaudible]\nProfessor Ramamurti Shankar: Yeah. There are many, many lab times and you have to\ngo to the website for the lab. And, by the way,\nthat reminds me. I've got here lots of flyers\ngiven to me by the director of the laboratories which will tell\nyou which lab is the right lab for you,\nand they're offered many times a week. Yes? Student:\nAs far as knowing the material, just from your class,\nhow important is taking a lab concurrent with this class? Professor Ramamurti Shankar: I think it's a good\nidea to take the lab, particularly in this particular\nclass because I don't have any demonstrations. They're all in the other building. So, this will remind you that physics is, after all,\nan experimental science and you will be able to see where all\nthe laws of physics come from. So, if you're going to take it,\nyou should take it at the same time. Yes? Student:\nCould you please talk about when you expect [inaudible]\nProfessor Ramamurti Shankar: Ah,\nvery good. This is a calculus-based class\nand I expect everyone to know at least the rudiments of\ndifferential calculus. What's a function,\nwhat's a derivative, what's a second derivative,\nhow to take derivatives of elementary functions,\nhow to do elementary integrals. Sometime later,\nI will deal with functions of more than one variable,\nwhich I will briefly introduce to you,\nbecause that may not be a prerequisite but certainly\nsomething you will learn and you may use on and off. But there are different ways of doing physics. Mine is to demonstrate over and over how little mathematics you\nneed to get the job done. There are others who like to\nshow you how much mathematics you could somehow insinuate into\nthe process, okay. There are different ways of\nplaying the game, and some of us find great pride\nin finding the most simple way to understand something. That's certainly my trademark; that's how I do my research\nalso. So, if you feel there's not\nenough math used, I guarantee you that I\ncertainly know enough eventually to snow the whole class,\nbut that's not the point. I will use it in moderation and\nuse it to the best effect possible rather than use it\nbecause it is there. Okay. So I don't know your mathematical background,\nbut the textbook has an appendix, which is a reasonable\nmeasure of how much math you should know. You've got to know your trigonometry,\nyou've got to know what's a sine and what's a cosine. You cannot say, \"I will look it up.\"\nYour birthday and social security number is what you look\nup. Trigonometry functions you know\nall the time. Okay."}, {"content": "I will ask you, and you do."}, {"content": "All right. And of course, there's trigonometric\nidentities you know from high school. Pages and pages of them, so no one expects you to know\nall those identities, but there are a few popular\nones we will use. All right."}, {"content": "Anything else?"}, {"content": "Yes? Student: This may be a bit early,\nbut when will we be having our Midterm? Professor Ramamurti Shankar: Yeah. Midterm will be sometime around 20th of October. I have to find out exactly the right time. We have 24 lectures for this class and the first 12 roughly\nwill be part of the Midterm, but after the 12th lecture I\nmay wait a week so that you have time to do the problems and get\nthe solutions. Then I will give you the\nMidterm. Yes? Student: If wanting one of the two lab\ncourses, which one do you recommend? Professor Ramamurti Shankar: Yeah,\nthis tells you in detail. This flyer answers exactly that. Okay, there was one more question from somebody?"}, {"content": "Yes? Student:\nA few people I've talked to have recommended that we start\ntaking the lab second semester instead of first. Would that be advisable or should we take both\nconcurrently? Professor Ramamurti\nShankar: I don't have a strong view. I think you should take the lab sometime but I don't know how\nmany semesters that you have to take. But I would say the advice of your predecessors is very\nimportant. If they tell you this is what\nworks, that's better than what somebody like me can tell you. Also, you should talk to Stephen Irons,\nwho is the director of the labs. He has seen every possible situation."}, {"content": "He will give you good advice. Let's start now."}, {"content": "Okay. So we are going to be studying\nin the beginning what's called Newtonian mechanics. It's pretty remarkable that the whole edifice is set up by just\none person \u2013 Newton -- and he sent us on the road to\nunderstanding all the natural phenomena until the year\n18-hundred-and-something when Maxwell invented the laws of\nelectromagnetism and wrote down the famous Maxwell equations. Except for electromagnetism, the basics of mechanics,\nwhich is the motion of billiard balls and trucks and marbles and\nwhatnot, was set up by Newton. So that's what we are going to\nfocus on, and you will find out that the laws of physics for\nthis entire semester certainly can be written on one of those\nblackboards or even half of those blackboards. And the purpose of this course is to show you over and over and\nover again that starting with those one or two laws,\nyou can deduce everything, and I would encourage you to\nthink the same way. In fact, I would encourage you\nto think the way physicists do, even if you don't plan to be a\nphysicist, because that's the easiest way\nto do this subject, and that is to follow the\nreasoning behind everything I give you. And my purpose will be not to say something as a postulate,\nbut to show you where everything comes from,\nand it's best for you if you try to follow the logic. That way, you don't have to store too many things in your\nhead. In the early days when there\nare four or five formulas, you could memorize all of them\nand you can try each one of them until something works,\nbut after a couple of weeks you will have a hundred formulas and\nyou cannot memorize all of them. You cannot resort to trial and\nerror. So you have to know the logic. So the logical way is not just the way the physicists do it,\nit's the easier way to do it. If there is another way that it\nwill work for non-physicists, I won't hesitate to teach it to\nyou that way if that turns out to be the best way. So try to follow the logic of everything. Okay. So, Newtonian mechanics is our\nfirst topic. So, Newtonian mechanics has two\nparts. All of physics is a two-part\nprogram. The plan, every time,\nis to predict the future given the present. That's what we always do. When we do that right,\nwe are satisfied. So the question is,\n\"What do you mean by \u2018predict the future?'\"\nWhat do you mean by the future? What do you mean by the present? By \"present,\" we mean--we will pick some part of the universe\nwe want to study and we will ask,\n\"What information do I need to know for that system at the\ninitial time, like,\nright now, in order to be able to predict the future?\"\nSo, for example, if you were trying to study the\nmotion of some object, here is one example. [throws a piece of candy for someone to catch]\nProfessor Ramamurti Shankar: See,\nthat's an example of Newtonian mechanics."}, {"content": "I'll give you one more demonstration. Let's see who can catch this one. [throws another piece] Professor Ramamurti\nShankar: That's a good example. So, that was Newtonian mechanics at work,\nbecause what did I do? I released a piece of candy,\nthrew it from my hand, and the initial conditions have\nto do with where did I release it and with what velocity. That's what he sees with his eyes. Then that's all you really need to know. Then he knows it's going to go up, it's going to curve,\nfollow some kind of parabola, then his hands go there to\nreceive it. That is verification of a\nprediction. His prediction was,\nthe candy's going to land here, then he put his hand there. He also knew where the candy was going to land,\nbut he couldn't get his hand there in time. But we can always make predictions. But this is a good example of what you need to know. What is it you have to know about this object that was\nthrown, I claim, is the initial location of the\nobject and the initial velocity. The fact that it was blue or\nred is not relevant, and if I threw a gorilla at him\nit doesn't matter what the color of the gorilla is,\nwhat mood it is in. These are things we don't deal\nwith in physics. There is a tall building,\na standard physics problem. An object falls off a tall\nbuilding. Object could be a person. So we don't ask why is this guy ending it all today? We don't know, and we cannot deal with that. So we don't answer everything. We just want to know when he's\ngoing to hit the pavement, and with what speed. So we ask very limited questions, which is why we brag\nabout how accurately we can predict the future. So, we only ask limited goals and we are really successful in\nsatisfying them. So, we are basically dealing\nwith inanimate objects. So the product of Newtonian\nmechanics of predicting the future given the present,\nhas got two parts, and one is called kinematics\nand the other is called dynamics. So, kinematics is a complete description of the present. It's a list of what you have to know about a system right now. For example, if you're talking about the\nchalk--if I throw the chalk, you will have to know where it\nis and how fast it's moving. Dynamics then tells you why the\nobject goes up, why the object goes down and\nwhy is it pulled down and so on. That's dynamics. The reason it comes down is gravity is pulling it. In kinematics, you don't ask the reason behind\nanything. You simply want to describe\nthings the way they are and then dynamics tells you how they\nchanged and why they changed. So, I'm going to illustrate the\nidea of kinematics by taking the simplest possible example. That's going to be the way I'm going to do everything in this\ncourse. I'm going to start with the\nsimplest example and slowly add on bells and whistles and make\nit more and more complicated. So, some of you might say,\n\"Well, I've seen this before,\" so maybe there is nothing new\nhere."}, {"content": "That may well be. I don't know how much you've seen, but quite often the way\nyou learned physics earlier on in high school is probably\ndifferent from the way professional physicists think\nabout it. The sense of values we have,\nthe things that we get excited about are different,\nand the problems may be more difficult. But I want to start in every example, in every situation that\nI explain to you, with the simplest example,\nand slowly add on things. So, what we are going to study\nnow is a non-living object and we're going to pick it to be a\nmathematical point. So the object is a mathematical\npoint. It has no size. If you rotate it, you won't know. It's not like a potato."}, {"content": "You take a potato,\nyou turn it around, it looks different. So, it's not enough to say the potato is here. You've got to say which way the nose is pointing and so on. So, we don't want to deal with that now. That comes later when we study what we call \"rigid bodies\". Right now, we want to study an entity which has no spatial\nextent. So just a dot,\nand the dot can move around all over space. So we're going to simplify that too. We're going to take an entity that lives along the x\naxis. [draws a line with integrals]\nIt moves along a line. So you can imagine a bead with\na wire going through it and the bead can only slide back and\nforth. So, this is about the simplest\nthing. I cannot reduce the number of\ndimensions. One is the lowest dimension. I cannot make the object simpler than being just a\nmathematical point. Then, you've got to say,\n\"What do I have to know about this object at the initial time? What constitutes the present, or what constitutes maximal\ninformation about the present?\" So what we do is we pick an\norigin, call it zero, we put some markers there to\nmeasure distance, and we say this guy is sitting\nat 1,2, 3,4, 5. He is sitting at x = 5. Now, of course, we've got to have units and the\nunits for lengths are going to be meters. The unit for time will be a second, and time will be\nmeasured in seconds. Then we'll come to other units. Right now, in kinematics, this is all you need. Now, there are some tricky problems in the book. Sometimes they give you the speed in miles per hour,\nkilometers per year, pounds per square foot,\nwhatever it is. You've got to learn to\ntransform them, but I won't do them."}, {"content": "I think that's pretty elementary stuff. But sometimes I might not write the units but I've earned the\nright to do that and you guys haven't so you'll have to keep\ntrack of your units. Everything's got to be in the\nright units. If you don't have the units,\nthen if you say the answer is 19, then we don't know what it\nmeans. Okay."}, {"content": "So here's an object. At a given instant,\nit's got a location. So what we would like to do is\nto describe what the object does by drawing a graph of time\nversus space and the graph would be something like this. You've got to learn how to read this graph. I'm assuming everyone knows how to read it. [draws a graph of x versus t]\nThis doesn't mean the object is bobbing up and down. I hope you realize that. Even though the graph is going\nup and down, the object is moving from left to right. So, for example, when it does this,\nit's crossed the origin and is going to the left of the origin. Now, at the left of the origin, it turns around and starts\ncoming to the origin and going to the right. That is x versus t. So, in the language of calculus, x is a function\nof time and this is a particular function. This function doesn't have a name. There are other functions which have a name. For example, this is x = t,\nx = t^(2), you're going to have x = sin\nt and cos t and log t. So some functions have a name, some functions don't have a\nname. What a particle tries to do\ngenerally is some crazy thing which doesn't have a name,\nbut it's a function x (t). So you should know when you look at a graph like this what\nit's doing. So, the two most elementary\nideas you learn are what is the average velocity of an object,\nas then ordered by the symbol v-bar. So, the average is found by taking two instants in time,\nsay t_1 and later t_2,\nand you find out where it was at t_2 minus\nwhere it was at t_1 and divide\nby the time. So, the average velocity may\nnot tell you the whole story. For example,\nif you started here and you did all this and you came back here,\nthe average velocity would be zero, because you start and end\nat the same value of x, you get something;\n0 over time will still be 0. So you cannot tell from the\naverage everything that happened because another way to get the\nsame 0 is to just not move at all. So the average is what it is. It's an average,\nit doesn't give you enough detail. So it's useful to have the average velocity. It's useful to have the average acceleration,\nwhich you can find by taking similar differences of\nvelocities. But before you even do that,\nI want to define for you an important concept,\nwhich is the velocity at a given time, v (t). So this is the central idea of calculus, right? I am hoping that if you learned your calculus,\nyou learned about derivatives and so on by looking at x\nversus t. So, I will remind you,\nagain, this is not a course in calculus. I don't have to do it in any detail. I will draw the famous picture of some particle moving and it's\nhere at t of some value of x. A little later, which is t + \u0394t. So \u0394t is going to stand always for a small finite\nintegral of time; infinitesimal interval of time\nnot yet 0. So, during that time,\nthe particle has gone from here to there, that is x +\n\u0394x, and the average velocity in that interval is\n\u0394 x/ \u0394t. Graphically,\nthis guy is \u0394 x and this guy is \u0394t,\nand \u0394x over \u0394t is a ratio. So in calculus,\nwhat you want to do is to get the notion of the velocity right\nnow. We all have an intuitive notion\nof velocity right now. When you're driving in your\ncar, there's a needle and the needle says 60;\nthat's your velocity at this instant. It's very interesting because velocity seems to require two\ndifferent times to define it -- the initial time and the final\ntime. And yet, you want to talk about\nthe velocity right now. That is the whole triumph of\ncalculus is to know that by looking at the position now,\nthe position slightly later and taking the ratio and bringing\nlater as close as possible to right now,\nwe define a quantity that we can say is the velocity at this\ninstant. So v of t,\nv(t) is the limit, \u0394t goes to 0 of\n\u0394x over \u0394t and we use the symbol dx/dt\nfor velocity. So technically,\nif you ask what does the velocity stand for--Let me draw\na general situation. If a particle goes from here to\nhere, \u0394x over \u0394t, I don't know how\nwell you can see it in this figure here,\nis the slope of a straight line connecting these two points,\nand as the points come closer and closer,\nthe straight line would become tangent to the curve. So the velocity at any part of the curve is tangent to the\ncurve at that point. The tangent of,\nthis angle, this \u03b8, is then \u0394x over \u0394t. Okay, once you can take one derivative,\nyou can take any number of derivatives and the derivative\nof the velocity is called the acceleration,\nand we write it as the second derivative of position. So I'm hoping you guys are comfortable with the notion of\ntaking one or two or any number of derivatives. Interestingly, the first two derivatives have\na name. The first one is velocity,\nthe second one is acceleration. The third derivative,\nunfortunately, was never given a name,\nand I don't know why. I think the main reason is that\nthere are no equations that involve the third derivative\nexplicitly. F = ma. The a is this fellow here, and nothing else is given\nan independent name. Of course, you can take a\nfunction and take derivatives any number of times. So you are supposed to know, for example,\nif x(t) is t^(n), you're supposed to know\ndx/dt is nt^(n-1). Then you're supposed to know\nderivatives of simple functions like sines and cosines. So if you don't know that then, of course, you have to work\nharder than other people. If you know that,\nthat may be enough for quite some time. Okay, so what I've said so far\nis, a particle moving in time from point to point can be\nrepresented by a graph, x versus t. At any point on the graph you can take the derivative,\nwhich will be tangent to the curve at each point,\nand its numerical value will be what you can call the\ninstantaneous velocity of that point and you can take the\nderivative over the derivative and call it the acceleration. So, we are going to specialize to a very limited class of\nproblems in the rest of this class. A limited class of problems is one in which the acceleration is\njust a constant. Now, that is not the most\ngeneral thing, but I'm sure you guys have some\nidea of why we are interested in that. Does anybody know why so much time is spent on that? Yes? Student:\n[inaudible] Professor Ramamurti\nShankar: Pardon me?"}, {"content": "Student:\n[inaudible] Professor Ramamurti\nShankar: Right. The most famous example is that\nwhen things fall near the surface of the Earth,\nthey all have the same acceleration,\nand the acceleration that's constant is called g,\nand that's 9.8 meters/second^(2). So that's a very typical problem. When you're falling to the surface of the Earth,\nyou are describing a problem of constant acceleration. That's why there's a lot of emphasis on sharpening your\nteeth by doing this class of problems. So, the question we are going to ask is the following,\n\"If I tell you that a particle has a constant acceleration\na, can you tell me what the\nposition x is?\" Normally, I will give you a\nfunction and tell you to take any number of derivatives. That's very easy. This is the backwards problem. You're only given the particle has acceleration a,\nand you are asked to find out what is x? In other words, your job is to guess a function\nwhose second derivative is a,\nand this is called integration, which is the opposite of\ndifferentiation, and integration is just\nguessing. Integration is not an\nalgorithmic process like differentiation. If I give you a function, you know how to take the\nderivative. Change the independent\nvariable, find the change in the function, take the ratio and\nthat's the derivative. The opposite is being asked\nhere."}, {"content": "I tell you something about the\nsecond derivative of a function and ask you what is the\nfunction. The way we do that is we guess,\nand the guessing has been going on for 300 years,\nso we sort of know how to guess. So, let me think aloud and ask how I will guess in this\nproblem. I would say,\nokay, this guy wants me to find a function which reduces to the\nnumber a when I take two derivatives,\nand I know somewhere here, this result,\nwhich says that when I take a derivative,\nI lose a power of t. In the end, I don't want any\npowers of t. It's very clear I've got to\nstart with a function that looks like t^(2). This way when I take two derivatives, there will be no\nt left. Well, unfortunately,\nwe know this is not the right answer, because if you take the\nfirst derivative, I get 2t. If I take the second derivative I get 2, but I want to get\na and not 2. Then it's very clear the way\nyou patch it up is you multiply it by this constant and now\nwe're all set. This function will have the\nright second derivative. So, this certainly describes a\nparticle whose acceleration is a. The a is not dependent on time. But the question is, is this the most general\nanswer, or is it just one answer, and I think you all know\nthat this is not the most general answer. It is one answer. But I can add to this some\nnumber, like 96, that'll still have the property\nthat if you take two derivatives,\nyou're going to get the same acceleration. So 96 now is a typical constant, so I'm going to give\nthe name c to that constant. Everyone knows from calculus that if you're trying to find a\nfunction about which you know only the derivative,\nyou can always add a constant to one person's answer without\nchanging anything. But I think here,\nyou know you can do more, right? You can add something else to the answer without invalidating\nit, and that is anything with one power of t in it, because if you take one\nderivative it'll survive, but if you take two\nderivatives, it'll get wiped out. Now, it's not obvious but it is true that you cannot add to this\nanymore. The basic idea in solving these\nequations and integrating is you find one answer,\nso then when you take enough derivatives, the function does\nwhat it's supposed to do. But then having found one\nanswer, you can add to it anything that gets killed by the\nact of taking derivatives. If you're taking only one\nderivative you can add a constant. If you're taking two derivatives you can add a\nconstant and something linear in t.. If you knew only the third derivative of the function,\nyou can have something quadratic in t without\nchanging the outcome. So, this is the most general\nposition for a particle of constant acceleration,\na. Now, you must remember that this\ndescribes a particle going side to side. I can also describe a particle going up and down. If I do that, I would like to call the\ncoordinate y, then I will write the same\nthing. You've got to realize that in\ncalculus, the symbols that you call x and y are\ncompletely arbitrary. If you know the second\nderivative of y to be a, then the answer looks\nlike this. If you knew the second\nderivative of x, the answer looks like that. Now, we have to ask what are these numbers,\nb and c. So let me go back now to this\nexpression, x(t) = at^(2)/ 2 + c +\nbt. It is true mathematically,\nyou can add two numbers, but you've got to ask yourself,\n\"What am I doing as a physicist when I add these two numbers?\"\nWhat am I supposed to do with a and b? I mean, with the b and c?"}, {"content": "What value should I pick? The answer is that simply\nknowing the particle has an acceleration is not enough to\ntell you where the particle will be. For example, let's take the case where the\nparticle is falling under gravity. Then you guys know, you just told me,\nacceleration is -9.8, my g is -9.8. We call it \"minus\" because it's accelerating down and up was\ntaken to be the positive direction. In that case, y(t) will be\n-1/2gt^(2) + c + bt. So, the point is,\nevery object falling under gravity is given by the same\nformula, but there are many, many objects that can have many\nhistories, all falling under gravity, and what's different\nfrom one object and the other object is,\nwhen was it dropped, from what height,\nand with what initial speed. That's what these numbers are\ngoing to tell us and we can verify that as follows. If you want to know what the number c is,\nyou say, let's put time t = 0. In fact,\nlet me go back to this equation here. You'll put time t = 0, x(0) doesn't\nhave this term, doesn't have this term,\nand it is c. So I realize that the constant,\nc, is the initial location of the object,\nand it's very common to denote that by x_0. So\nthe meaning of the constant c is where was the object at the\ninitial time? It could've been anywhere. Simply knowing the acceleration is not enough to tell you where\nit was at the initial time. You get to pick where it was at\nthe initial time. Then, to find the meaning of\nb, we take one derivative of this, dx/dt,\nthat's velocity as a function of time, and if you took the\nderivative of this guy, you will find as at + b. That's the velocity of the object. Then, you can then understand that v(0) is what\nb is, which we write as v_0. Okay,\nso the final answer is that x(t) looks like\nx_0 + v_0 t + 1/2 at^(2). Okay. So what I'm saying here is we are specializing to a limited\nclass of motion where the particle has a definite\nacceleration, a. Then, in every situation where the body has an acceleration\na, the location has to have this form,\nwhere this number (x_0) is where\nit was initially, this (v_0 )\nwas the initial velocity of the object. So, when I threw that thing up and you caught it,\nwhat you are doing mentally was immediately figuring out where\nit started and at what speed. That was your initial data. Then in your mind, without realizing it,\nyou found the trajectory at all future times. Now, there is one other celebrated formula that goes\nwith this. I'm going to find that,\nthen I'll give you an example. Now, I'm fully aware that this\nis not the flashiest example in physics, but I'm not worried\nabout that right now. You'll see enough things that\nwill confound you, but right now I want to\ndemonstrate a simple paradigm of what it means to know the\npresent and what it means to say this is what the future behavior\nwill be. We want to do that in the\nsimplest context, then we can make the example\nmore and more complicated, but the phenomenon will be the\nsame."}, {"content": "So, what we have found out so\nfar, I'm purposely going from x to y because I\nwant you to know that the unknown variable can be called\nan x or can be called a y. It doesn't matter, as long as the second\nderivative is a; that's the answer. Now there's a second formula one derives from this."}, {"content": "You guys probably know that too from your days at the daycare,\nbut I want to derive the formula and put it up,\nthen we'll see how to use it. Second formula tries to relate\nthe final velocity of some time, t, to the initial\nvelocity and the distance traveled with no reference to\ntime. So the trick is to eliminate\ntime from this equation. So let's see how we can\neliminate time. You know that if you took a\nderivative of this, you will find v(t) is\nv_0 + at. What that means is,\nif you know the velocity of the given time and you know the\ninitial velocity, you know what time it is. The time, in fact, is v - v_0\nover a. If I don't show you any\nargument for v, it means v at time\nt and the subscript of 0 means t is zero. So what this says is, you can measure time by having\nyour own clock. A clock tells you what time it\nis, but you can also say what time it is by seeing how fast\nthe particle is moving because you know it started with some\nspeed. It's gaining speed at some rate\na. So, if the speed was so and so\nnow, then the time had to be this. So time can be indirectly inferred from these quantities. Then you take that formula here (t) and you put it here,\n(y(t)) to see a times t,\nyou put this expression. So what will you get? We'll get an expression in which there is no t;\nt has been banished in favor of v. So, I'm not going to waste your time by asking what happens if\nyou put it in. I will just tell you want\nhappens. What happens is,\nyou will find that v^(2) = v_o^(2) + 2a times\n(y- y_0). [Note: The Professor said x\nwhen he meant y] How many people have seen this\nthing before?"}, {"content": "Okay."}, {"content": "That's a lot. Look, I know you've seen this. At the moment, I have to go through some of\nthe more standard material before we go to the more\nnon-standard material. If this part's very easy for\nyou, there's not much I can do right now. So let me draw a box. Drawing a box to you guys means\nimportant. These are the two important\nthings."}, {"content": "Remember, I want you to\nunderstand one thing. How much of this should you\nmemorize? Suppose you've never seen this\nin high school. How much are you supposed to\nmemorize? I would say,\nkeep that to a minimum, because what the first formula\ntells you should be so intuitive that you don't have to cram\nthis. We are talking about particles\nof constant acceleration. That means, when I take two\nderivatives, I want to get a, then you should know\nenough calculus to know it has to be something like\nat^(2), and half comes from taking two\nderivatives. The other two you know are\nstuff you can add, and you know where you're\nadding those things, because the particle has a head\nstart. It's got an initial position. Even at = 0, and it has an initial velocity,\nso even without any acceleration,\nit will be moving from y^(0) to y^(0) + vt. The acceleration gives you an extra stuff, quadratic in time. Once you've got that, one derivative will give you\nthe velocity, then in a crunch you can\neliminate t and put it into this formula. But most people end up memorizing these two because you\nuse it so many times. It eventually sticks in you but\nyou shouldn't try to memorize everything. So, we are now going to do one standard problem where we will\nconvince ourselves we can apply this formulae and predict the\nfuture given the present. So the problem I want to\ndo--there are many things you could do but I just picked one,\nand this is the one with round numbers so I can do it without a\ncalculator. Here's the problem. There is this building and it's going to be 15 meters high,\nand I'm going to throw something and it's going to go\nup and come down. It's something I throw up has\nan initial speed of 10 meters per second. So we have to ask now,\nnow that my claim is, you can ask me any question you\nwant about this particle and I can answer you. You can ask me where it will be nine seconds from now,\neight seconds from now, how fast will it be moving. I can answer anything at all. But what I needed to do this\nproblem was to find these two unknowns."}, {"content": "So, you've got to get used to the notion of what will be given\nin general and what is tailor-made to the occasion. So, we know in this example the initial height should be 15\nmeters and the initial velocity should be 10,\nand for acceleration, I'm going to use -g and\nto keep life simple, I'm going to call it -10. As you know, the correct answer is 9.8,\nbut we don't want to use the calculator now so we'll call it\n-10. Consequently,\nfor this object the position y, at any time t\nis known to be 15 + 10t - 5t^(2). That is the full\nstory of this object. Of course, you've got to be a\nlittle careful when you use it. For example,\nlet's put t equal to 10,000 years. What are you going to get? When t is equal to\n10,000 years or 10000 seconds, you're going to find y\nis some huge negative number. You know, that's not right,\nwhat's wrong with that reasoning? Student: [inaudible]\nProfessor Ramamurti Shankar: So you cannot use\nthe formula once it hits the ground because once it hits the\nground, the fundamental premise that\na was a constant of -9.8 or -10 is wrong. So that's another thing to remember. Once you get a formula, you've got to always remember\nthe terms under which the formula was derived."}, {"content": "If you blindly use it beyond its validity,\nyou will get results which don't make any sense. Conversely, if you get an answer and it doesn't seem to\nmake sense, then you've got to go back and ask,\nam I violating some of the assumptions, and here you will\nfind the assumption that the particle had that acceleration\na is true as long it's freely falling under gravity but\nnot when you hit the ground. Now, if you dug a hole here\nuntil there, and of course it may work until that happens,\nokay. But you've got them every time. This is so obvious in this problem, but when you see more\ncomplicated formula, you may not know all the\nassumptions that went into the derivation and quite often you\nwill be using it when you shouldn't. All right. See, this you agree,\nis a complete solution to this miniature, tiny,\nMickey-Mouse problem. You give me the time and I'll\ntell you where it is. If you want to know how fast\nit's moving at a given time, if you want to know the\nvelocity, I just take the derivative of\nthis answer, which is 10 - 10t. So let me pick a couple of trivial questions one can ask."}, {"content": "One can ask the following question. How high does it go? How high will it rise? To what height will it rise? So, we know it's going to go up\nand turn around and come down. We're trying to see how high\nthat is. So, that is a tricky problem to\nbegin with because if you take this formula here,\nit tells you y if you know t,\nbut no, we're not saying that. We don't know the time and we\ndon't know how high it's rising so you can ask,\n\"How am I supposed to deal with this problem?\"\nThen you put something else that you know in your mind,\nwhich is that the highest point is the point when it's neither\ngoing up nor coming down. If it's going up,\nthat's not the highest point. If it's coming down,\nthat's not the highest point. So at the highest point it\ncannot go up and it cannot go down. That's the point where velocity is 0. If you do that, let's call the particular time\nt*, then 10t* - 10 = 0, or t*\nis 1 second. So we know that it'll go up for\none second then it will turn around and come back. Now, we are done because now we can ask how high does it go,\nand you go back to your, and y (1) is 15 + 10 -\n5, which is what? Twenty meters. By the way, you will find that I make quite a lot of mistakes\non the blackboard. You're going to find out,\nyou know, one of these years when you start teaching that\nwhen you get really close to a blackboard, you just cannot\nthink. There's definitely some inverse\ncorrelation between your level of thinking and the proximity to\nthe blackboard. So if you find me making a\nmistake, you've got to stop me. Why do you stop me? For two reasons. First of all,\nI'm very pleased when this happens, because I'm pretty\nconfident that I can do this under duress,\nbut I may not do it right every time. But if my students can catch me making a mistake,\nit means they are following it and they are not hesitating to\ntell me. Secondly, as we go to the more\nadvanced part of the course, we'll take a result from this\npart of the blackboard, stick it into the second part\nand keep manipulating, so if I screwed up in the\nbeginning and you guys keep quiet,\nwe'll have to do the whole thing again. I would ask you when you follow this thing to do it actively."}, {"content": "Try to be one step ahead of me. For example,\nif I'm struck by lightning, can you do anything? Can you guess what I'm going to say next? Do you have any idea where this is going?"}, {"content": "You should have a clue. If I die and you stop,\nthat's not a good sign, okay. You've got to keep going a little further because you\nshould follow the logic. So, for example,\nyou know, I'm going to calculate next when it hits the\nground. You should have some idea of\nhow I'll do it. But this is not a spectator\nsport. If you just watch me,\nyou're going to learn nothing. It's like watching the U.S. Open and thinking you're some kind of a player. You will have to shed the tears and you've got to bang your head\non the wall and go through your own private struggle. I cannot do that for you. I cannot even make it look hard\nbecause I have memorized this problem from childhood,\nso there is no way I can make this look difficult. That's your job."}, {"content": "All right. So, we know this point at one second is 20 meters,\nso let's just ask one other question and we'll stop. One other question may be, \"When does it hit the ground\nand at what speed?\" -- a typical physics question. So when does it hit the ground? Well, I think you must know now\nhow to formulate that question. \"When does it hit the ground\"\nis \"When is y = 0\"? By the way, I didn't tell you this but I think you know that I\npicked my origin to be here and measured y positively to\nbe upwards and I called that 15 meters. You can call that your origin. If you call that your origin,\nyour y_0 will be 0, but ground will be called\n-15. So, in the end,\nthe physics is the same but the numbers describing it can be\ndifferent. We have to interpret the data\ndifferently. But the standard origin for\neverybody is the foot of the building. You can pick your origin here, some crazy spot. It doesn't matter. But some origins are more equal\nthan others because there is some natural landmark there. Here, the foot of the building is what I call the origin. So, in that notation, I want to ask,\nwhen is y = 0? I ask when y = 0,\nthen I say 0 = 15 + 10t - 5t^(2). Or I'm canceling the 5 everywhere and changing the sign\nhere I get t^(2) - 2t - 3 = 0. That's when it hits the ground. So let's find out what the time\nis. So t is then 2 + or -\nor + 12 over 2, which is 2 + or - 4 over\n2, which is -1 or 3. Okay, so you get two answers\nwhen it hits the ground. So it's clear that we should\npick 3. But you can ask,\n\"Why is it giving me a second solution?\"\nAnybody have an idea why? Student:\nBecause there was an entire parabola [inaudible]\nProfessor Ramamurti Shankar: That's correct. So her answer was, if it was a full parabola,\nthen we know it would've been at the ground before I set my\nclock to 0. First of all,\nnegative time should not bother anybody;\nt = 0 is when I set the clock, I measured time forward,\nbut yesterday would be t = -1 day,\nright? So we don't have any trouble\nwith negative times. So the point is,\nthis equation, it does not know about the\nbuilding. Doesn't know the whole song and\ndance that you went to a building and you threw up a rock\nor anything. What does the mathematics know? It knows that this particle happened to have a height of 15,\na time 0, and a velocity of 10, a time 0, and it is falling\nunder gravity with an acceleration of -10. That's all it knows. If that's all it knows,\nthen in that scenario there is no building or anything else;\nit continues a trajectory both forward in time and backward in\ntime, and it says that whatever seconds,\none second before you set your clock to 0, it would've been on\nthe ground. What it means is if you'd\nrelease a rock at that location one second before with a certain\nspeed that we can calculate, it would've ended up here with\nprecisely the position and velocity it had at the beginning\nof our experiment. So sometimes the extra solution\nis very interesting and you should always listen to the\nmathematics when you get extra solutions. In fact, when a very famous physicist, Paul Dirac,\nwas looking for the energy of a particle in relativistic quantum\nmechanics, he found the energy of a\nparticle is connected to its momentum, this p is what\nwe call momentum, and its mass by this relation. It's a particle of mass m and momentum p\nhas this energy so you solve for the energy, you get two answers. Now, your temptation is to keep\nthe first answer because you know energy is not going to be\nnegative. Particle's moving,\nit's got some energy and that's it. But the mathematicians told Dirac, \"You cannot ignore the\nnegative energy solution because it tells you there's a second\nsolution and you cannot throw them out,\"\nand it turns out the second solution, with negative energy,\nwas when the theory is telling you,\nhey, there are particles and there are anti-particles,\nand the negative energy when properly interpreted will\ndescribe anti-particles. So the equations are very smart. The way the physics works is you will find some laws of\nmotion in mathematical form, you put in the initial\nconditions of whatever, you solve the equations,\nand the answer that comes, you have no choice. You have to accept the answer, but there are new answers\nbesides the one you were looking for. You've got to think about what they mean, and that's one of the\nbest things about physics because here's a person who is\nnot looking for anti-particles. He was trying to describe\nelectrons, but the theory said there are two roots in the\nquadratic equation and the second root is mathematically as\ninteresting as the first one. It has to be part of a theory,\nand then trying to adjust it so it can be incorporated,\nyou discover anti-particles. So always amazing to us how we\ngo into the problem, our eye or mind can see one\nclass of solutions, but the math will tell you\nsometimes there are new solutions and you've got to\nrespect it and understand and interpret the unwanted\nsolutions, and this is a simple example\nwhere you can follow what the meaning of the second solution\nis. It means that to the problem\nyou pose, there's more than the answers that you could imagine. Here it meant particle that was released from the ground\nearlier. There it meant something much\nmore interesting, mainly anti-particles\naccompanying particles. They are going to accompany\nparticles surely as every quadratic equation has two\nsolutions. All right, so now in this\nproblem, we can do something slightly different,\nand let's use this expression here,\nand I will do that, then I'll stop for today. If you were asking questions, like, how high does it go,\nbut you don't ask when does it go to the highest point,\nthen you don't have to go through the whole process of\nfinding the time at which it turned around. I don't know where that is, that disappeared on the\nblackboard, then putting the time equal to 1 second into this\nformula. If the question of time is not\nexplicitly brought up, then you should know that you\nhave to use this formula. So how do we get it here? Well, we say at the top of the loop, when it goes up and comes\ndown the velocity is 0. Therefore, you say 0^(2)\n= initial velocity^(2) + 2 times -g,\nthat's my acceleration, times y - y_0. If you solve for that, you find y - y_0 =\nv_0^(2) over 2g,\nand if you put in the v_0 I gave you,\nwhich was what, 10? That's 100 over 20, which is 5 meters. So y = y_0 + 5 meters, and that was the height\nto which it rises. I think we got it somewhere\nelse. We found the maximum height to\nbe 20 meters. Another thing you can do is you\ncan find the speed here. If you want to find the speed\nthere, you put the equation v^(2) = v_0^(2)\n+ 2 times -g (y - y_0). What is y - y_0? The final y is 0, the initial y is\n15. You solve for that equation and you will find the\nfinal velocity. So, if time is not involved,\nyou can do it that way. I want to derive the last\nresult in another way, then I will stop,\nand that's pretty interesting because it tells you the use and\nabuse of calculus. So I'm going to find for you\nthis result using calculus in a different way. So, from the calculus we know dv/dt = a. Now, multiply both sides by v. Now you have to know from\nelementary calculus that v times dv/dt is\nreally d by dt of v^(2) over 2. Now, I hope you guys know that much calculus,\nthat when you take a derivative of a function of a function,\nnamely v^(2) over 2 is a function of v,\nand v itself is a function of t,\nthen the rule for taking the derivative is first take the\nv derivative of this object,\nthen take the d by dt of t,\nwhich is this one. On the right-hand side,\nI'm going to write as a dx/dt. This much is standard. I'm going to do something which\nsomehow we are told never, ever to do, which is to just\ncancel the dts. You all know that when you do\ndy/dx, you're not supposed to cancel\nthat d. That's actually correct. You don't want to cancel the d in the derivative. But this happens to be completely legitimate,\nso I'm going to assume it's true and I'll maybe take a\nsecond and explain why it's legitimate. What this really means is in a given time, \u0394t,\nthe change in this quantity is a times the change in\nthis quantity. Therefore, you can multiply\nboth sides by the \u0394t, but the only thing you should\nunderstand is \u0394t, as long as it's small and\nfinite, will lead to some small infinite errors in the formula,\nbecause the formula is really the limit in which \u0394x\nand \u0394t both go to 0. So what you have to do is\nmultiply both sides by \u0394t, but remember it's\ngot to be in the end made to be vanishingly small. As long as we understand that, we can do this cancellation and\nthis says on the left-hand side the change in the quantity\nv^(2) over 2 is a times the change in the quantity\nx. So add up all the changes or what you mean by\nintegral. Same thing. Add up all the changes. The change in v^(2) over\n2 will be the final v^(2) over 2 - the initial\nv^(2) over 2 and the other side will be a\ntimes change in x; x - x^(0) and that's the\nformula I wrote for you: v^(2) is\nv_0^(2) + 2a (x - x^(0)). So,\nthe point is whenever you have derivatives with something over\ndt, do not hesitate to cancel the dts and think\nof them as \u0394v^(2) over 2 is equal to a times\n\u0394 of x. This will be actually true as long as both\nquantities are vanishingly small. They will become more and more true as \u0394x and\n\u0394v^(2) become vanishingly small,\nin the limit in which they are approaching 0,\nthe two will be, in fact, equal. If \u0394x is a finite amount, like 1 second,\nthis will not be true because in the starting equation,\n\u0394x and \u0394t and \u0394v^(2) were all assumed\nto be infinitesimal. So don't hesitate to do\nmanipulations of this type, and I will do them quite often. So you've got to understand when it's okay and when it's not\nokay. What this means is,\nin a time \u0394t, this quantity changes by some\namount, and in the same time,\n\u0394t, that quantity changes by some amount,\nthen keeping the \u0394t equal to some number we may\nequate the changes of the two quantities,\nprovided it is understood that \u0394v^(2) over 2 is a\nchange in v^(2) over 2 in the same time in which the\nparticle moved a distance, \u0394x. Adding the differences, we eliminate time and we get\nthis final result."}, {"content": "All right. So if you go to your website today, you will find I've\nassigned some problems and you should try to do them. They apply to this chapter. Then next week we'll do more\ncomplicated problems that involve motion in higher\ndimensions, how to go to two dimensions or three dimensions. "}], "Giving you guys a chance....": [{"content": "you guys know what this is It's a nose Swizzle check this [Applause] out sorry it was in the background it distracted me book review I can't clap cuz it will sound horrible at last book review will return last year I uploaded a video I bet you didn't watch it so I'm giving you a second chance I want to help you guys out it's was talking about habits how to take bad habits and replace them with good ones I know this seems like some sort of U productivity idity 2025 Sigma bigma I was trying to be go beyond that and use ideas from philosophy to incorporate these ideas and for me it really worked I picked up drawing I've been sketching every day since but that's just one of many things that I I think at least I've learned from reading reading is something that I enjoyed as a kid something I had also abandoned kind of like drawing actually something I enjoyed as a kid but then I picked it up again and realized just how much I loved it and uh it was the best thing I've ever done for myself by far reading completely changed my whole perspective in life I think it's just something incredibly valuable that I think everyone should experience and that's why I've announced book review 2025 cuz I want you guys to have the same Journey or if not Inspire to go on your own all these books that we're going to read I've already read but I will re read them with you I don't want to blame having a kid but I have not read nearly as much as I used to this past couple years and I want to get back into it as well so I can't make any excuses therefore you can't make any excuses now I haven't really figured out how I'm going to do this but I realize the best way to make anyone do anything is through shame therefore we will have have a shame list for anyone that fails book review 2025 and also everyone that do complete book review 2025 will get a sense of ah beyond the infinite wisdom also a sense of ah now let's get into the books the book list in January we're going to start off we're going to work our way this way we're going to start off super simple baby level T teing this is ancient Chinese wisdom it's only 100 pages but you could very easily finish it in a in one day but we're not supposed to do that we're going to take our time with it hey you can do whatever you want who cares it's hard to hold a book and a microphone the reason I H picked this book is because it's a really good soft start if for Rusty readers out there I think it's very simple it breaks down ancient wisdom in a nice simple way I kept seeing simple as you see I I've labored things in this because I think there are some passages that are just brilliant and that I keep coming back to that's sort of a theme throughout all these books that I've picked is it's books that really resonated with me I've learned stuff from them that I've Incorporated in my life and that I like to revisit and rethink about and remind myself and I think u t teing is just a great start of that and if you want to do a head start maybe let's say you finished this and you're like okay I want to move on obviously you can do that sorry to interrupt I actually wanted to review a book really quickly it's one that speaks highly to my heart and my Soul it's the book of the best vpn's on the planet starting n VPN only have you guys heard about this have you heard about nordvpn this book draws heavily for my own personal life the other day for example I was downloading legal Minecraft mods and oh I felt like I was being watched I don't know why so I launched nordvpn and my internet activity go po FBI agent go where'd he go and I could continue downloading my legal Minecraft mods safe and sound knowing that nor VPN has a strict no log's policy my internet business is my internet business as it should be another example from this great book that correlates with my personal life is when I was watching legal Minecraft anime online and all of a sudden not alloud in your region be nearly fainted was crying luckily I can always save the day with nordvpn Bing bam boom connect to anywhere in the world get rid of any region blocks the internet is open and free as it should be thank you nor VPN not just for being an amazing service but for being an amazing sponsor to this channel for so [Music] long this is what be does now he there's nothing to do with ad he thinks hello and by is blowing a kiss I just realized I did the same if you use my link in the description you get four bonus month and a huge discount the best offer you can get on nor VPN and if you're not convinced try it out for 30 days money back guaranteed I promise you will like it give it a shot I've been using it for how many years now like I know they're paying me but I'm actually paying to use it myself I'm happy to sponsor products that I actually use myself so thank you nordvpn check out nordvpn.com PewDiePie the link is the description let's continue with the book reviews the second book is in in the Buddhist words I've talked about this book so much because it's an incredible book we S I hate using the word Awakening for lack of better one that's all I'm going to use because it really was an Awakening experience for me to read this book I never examined myself in in such a way and it's funny the book seems almost aware of this itself where most of us throughout our lives go through our days and it maybe in our entire existence for many existences as Buddhism believes where we're drawn to Sensational Pleasures we're drawn to all these distractions without fully examining our lives and and our purpose and what we're doing and when you read it you get that understanding and you look at yourself obviously first you look at yourself but then you look at the whole world and you realize you want everyone to sort of stop and go no wait let's what are we doing here let's rethink this uh what is our purpose come on to me there's just something so tragic about living your life without examining it it taught me so much about Sensational pleasure especially I'm Mr dopamine okay I'm sure a lot of people can relate to this but there's almost this romanticized idea of of a sad man at a bar hunched over with a drink like there's something cool about it smoking a cigar these things are not cool that's sad all of that is sad and not a sad in that wow so sad kind of way just bad don't romanticize these things you know what I mean being drawn these Sensational Pleasures you can Free Yourself completely from them I'm speaking way more about this than I thought I would but here we are you just binding yourself to different things that you don't need and by uprooting these uh issues they will you'll completely be free from them I used to think about drinking alcohol every single day now it has zero control over me there's so much in Buddhism that ties into what we're going to go into later as well but moving on January February March March you can pick whatever you want I I think every third month I will let you guys decide I think the point of reading is not just to blindly follow what someone laid in front of you it's about finding your own Curiosities okay you read this huh I'm interested in maybe expanding on this or do reading something different maybe I hated it and this is not for me that's part of the your own Discovery I will announce which books I will read but I see them sort of outside of the list they might be maybe too advanced for some of you sounds so demeaning like you you dummies I'm going to read maybe I'll do uh uh meditations of first Philosophy by Renee Descartes I never read Renee there's a couple philosophers that I just never touched and I want to I I just feel like I should read them so that's what I pick for March moving on with the book list January February March April I don't know the months unless I count them in order another book I've talked about so much we're going to read epic Titus discourses and selected writings if you for some reason haven't read this with the amount of yapping I've done about this book you got to do it now I think if I had to pick one book out of all of these one book to rule the moral I would pick the inidian literally means handbook it is the handbook of stoicism it is the simplest way to ever explain stoicism people mostly associate stoicism with Marcus aurelus or maybe senica and aurelus obviously is an incredible story I think his life is more interesting and obviously he talks about stoicism which is amazing and he lived sism which is amazing but uh just take the inidian it puts it so beautifully and so simply and I think everyone can benefit from these ideas they are similar to Buddhism in the sense of it's in a way of avoiding suffering I've been very fortunate and and privileged I there hasn't been much times where I even feel like I need stoicism but reading stoicism it almost feels like I I put on this armor like I'm ready for anything whatever life is going to give me I'll be ready for it and that's how stoicism changes your perspective instead of fearing Misfortune you you sort of look at it as this gives me a chance to show show my virtue and and what I've learned I remember there was a book I read about American soldier that crashed his plane over Vietnam during the war and he had started sism and as he was shut down and falling in his parachute he he thought to himself this is my chance to practice what I've learned from stoicism because he knew how they would torture soldiers and uh they did okay I'm going to have to speed up cuz be is going to na soon next up we have hey play to The Republic oh oh if you think I've yed a lot about epic tittis I've actually realized I Y way more about play The Republic I I love I made a 40-minute video talking about this book I love it so much I think it is also really good introduction to philosophy because it covers so so many areas the whole premise of the book is uh Socrates is discussing with Glon they're trying to find the definition of justice since it's something that they're trying to discover together it makes you feel part of this philosophical discussion like you're transported into this uh the same room as as the greatest mind of all time and you get to experience and join this discussion what other medium could do that but literature it's just so incredible I feel so fortunate to even be reading this book it examines the human soul but then goes into a macro level and they try and examine okay so to answer this question we need to examine what is the ideal way of running a society yeah it goes into all these amazing and interesting ideas some are a little bit weird actually now I think about it I feel like I shouldn't say I enjoy this book too much big disclaimer I do not agree with every single idea that this author has a necessary 2019 disclosure everyone and then in the end it ties it all together in this beautiful like depiction of the afterlife and and rebirth kind of like Buddhism as well and what sort of Life they want to live and it answers that question in the end and I just think about it all the time I absolutely love it it's an an amazing book I'm just so excited for you for you guys defitely H anyway third month free I'm going to read I'm going to read content critique of pure reason I feel like I have to recount I tried a while ago I think I got a third in and uh I stopped for whatever reason it is extremely dense literature like uh I do not necessarily recommend casual readers to pick this one up I uh read a bit about Kant and I find him to be more interesting than his work he was just Mega autistic he's basically Sheldon Cooper which makes for a lot of interesting and sort of silly things about his life he had the famous philosopher walk every day at the exact same time but he refused to speak to anyone so if anyone tried to he would Resort he didn't want his lips to open cuz that would constitute us talking so he would resort to making noises with his mouth like mhm it's just I don't know it's funny to me I obviously know some ideas around him and his moral principles are quite famous I'm curious to read if his reasoning can sort of bring me over or not I don't know interjecting I done a little bit more research about the books that I picked cuz obviously I haven't read them and I think it might be a little difficult to do K in just a month so I was thinking okay maybe I'll do two much and or maybe I'll I was trying to think the best way to do it but then I thought you know what I'm just going to try my best if I fail that's okay I can I can pick it up at some other time or or keep going so I'm just saying this if you're deciding to read the same book which I don't encourage to be honest but if you are to be honest I I want you guys to pick your own interest uh but yeah just wanted to explain my reasoning right so next up guess what another book I've talked about a ton Aristotle nikan ethics that sounds so Advanced but it's really simple do not be turned turned off from this it is talking about happiness how to be happy what what does it mean to be a good person uh the Greek had this word for happiness which is a beautiful word called udonia and it sort of translates vaguely to flourishing as an individual and this is something I think about a lot and I can sort of make sense out of it I used this book a lot my previous video that I talked about last year about the ideas of habit cuz the Greeks understood habit and how it can lead to good virtues while bad habit obviously leads to bad virtues and but it's not just about becoming this imulation I almost Ed the tough word there but I I gave up amalgamation sort of this new Millennial idea of how you should be the more you achieve the more you show people that you're doing that is not the answer if anything that just leads to another attachment but Aristotle talk about the golden mean and this sort of balance instead of your life I'm looking forward to refresh my ideas on it I think it's just incredibly incredibly useful and valuable for people to read next is more for me you don't have to read this I I'll say you have to read a classic uh I think so many people don't want to read classic literature but that is just a huge mistake I can never say it right donkey shot the cter mon the crystal Moby Dick actually I don't I wasn't huge M day I read cash 22 recently too which is another classic I just think that was hilarious I love it actually but a classic literature maybe seems a bit dull but they are classic for a reason every time I read one it's just an amazing experience and my favorite I I don't know if it even counts as a classic but my favorite is The Iliad I love the ilad so much I've had such a weird experience with it because uh when I was a kid I think around 11 or 12 I was so into the Troy War history I don't know why I think I read it about it somewhere like a Comic version and I wanted to know everything there was about it how tall were the walls and I wanted to remember all the years and then you find out about things that you know may or may not have happened you know with the Achilles fighting Hector and all these things I just thought it was so cool I couldn't believe not everyone was talking about it and I thought it was the coolest thing ever it was basically my Marvel of the time you know I was like the gods are helping all in all these battles that's the coolest thing ever and then finally in my 30s I read the actual Iliad and I thought the gods are helping in the war that's the coolest thing ever I I I absolutely love it most people know the Iliad or associate The Iliad with the troyan horse everyone knows about it but surprisingly it isn't in The Iliad and the Iliad ends completely differently and to me the ending of Iliad was so beautiful it really struck me deeply I remember when I read it and I think most Classics do they really just hit you differently I don't know how to explain it yeah I just thought it was so incredible and I I love reading it and I want to reread it so uh that's why I picked it but I just encouraged maybe picking a a classic that you're interested in it will be worth it so next month it's free you can read whatever you want I will read Arthur schopenhauer I think actually you can read it as well it sort of makes sense to read before nche I will read the world as will and representation I think I've already read it but I think I definitely need a refresher chaen was the first as far as I understand the Western uh Buddhist he wanted to escape suffering and N which will read later really looked up to shophow but also critiqued him heavily and I want to sort of better understand schopenhauer and why cuz I I don't remember much I don't even have the copy here I left it in UK so I look forward to read open hour and then we have October I know like I'm the one who made the least so obviously I'm going to like all the books but I'm like this is so sick I love this all right so next up we're going to go into n thus so spoke sarra I talked about this book in the video I made last year a little bit there are these ideas of Will To Power the Uber MCH uh you you heard God is dead this is all in this book sarra n is such a interesting character he is the most misunderstood philosopher by far and even amongst people that have a better idea of n everyone seems to disagree as well but I I understand I understand n okay I got it I don't all these books that we read by the way so far not all of them but most of the philosophers n has up he hat he hated everyone he had this hit hit list of philosophers and he would attack them all the time it's kind of funny but I also saw it as a you know you criticize things that you like in a sense as much as I love sism and we will understand sism once we got to nche he did criticize stoicism and I think his criticism is actually fair you know nche is famously misunderstood as the poster boy for nihilism when in reality as you probably know now is he fought for the opposite he thought about this life his life affirming philosophy to me I think is so important I don't remember if s sistra had that much of that idea in it actually I think it's more in the gay science I know it's a hilarious title of a book I still think sister if I had to pick one each it's it's a really good one to start on well I don't know it's a really good one to pick apparently I don't know if it's true I think it is he was high on opioids when he wrote it so it is vastly different from other books I read from him but that also makes it very fun I think it's really fun to read and I can't wait for you guys to experience it as well like all of these books next up we have we're going to finish with sidara by Heron has maybe it doesn't make sense to end on this maybe it does make sense to end on this I think I'll know once I read reread it it is the the story of Buddha there are different depictions of Buddha amongst Buddhism but the more modern version as far as I understand is that he was a person that lived went through difficulties and suffering just as we did but then overcame it and became enlightened and became the Buddha and that is the story of suhara so I think it's a beautiful beautiful book that I would highly recommend to anyone it really surprised me caught me out of nowhere I had this horrible version of it from Amazon doesn't even have a proper spine uh if anyone have a better version if you want to give it to me I would love it and then finally you're free December I'm going to read phenomenology of Spirit by hego cuz I never read hego and I feel like I should he just have such a boring face I just assume he is equally boring I think any of these FL K looks boring yeah I'll say it if he has a dumb face probably his ideas are dumb too it's like I learned nothing from all this that is the 2025 book review imagine if you all you have to do is spend let's say the average of these book are 300 Pages they are probably a little bit more but probably more or less if you read 20 Pages a day for 30 days 2 minutes per page probably less maybe you know instead of going on your phone the first thing in the morning or um before bed replace that with the reading and it will have no change in your productivity or what you're doing but it will just vastly improve your life and I guarantee it rep a bad habit with a good one let's do it I'm so excited for you guys I'm so excited for me this is going to be great that's it hug come here"}], "3. Budget Constraints and Constrained Choice": [{"content": "[SQUEAKING] [RUSTLING] [CLICKING] JONATHAN GRUBER:\nToday, we're going to continue our discussion\nof consumer choice. And we're going to\ntalk now about what happens when we take that\nunconstrained choice we talked about on Monday and\nimpose budget constraints. We'll talk about what\nbudget constraints are. We'll then come to talking\nabout how consumers make constrained choices. And then we'll end with\nan example of food stamps. So let's start by talking\nabout budget constraints. And we'll start by talking\nabout their construction, the construction of\nbudget constraints. So, basically, last\ntime, we talked about the fundamental\naxiom of consumer choice that more is better. So what stops people from\njust bingeing on everything? It's their budget constraint. It's their limited resources. Now, for most of\nthis course, we're going to make a simplifying\nassumption that your budget-- that is what you spend-- equals your income. That is what you earn, OK? That is there won't be any\nsavings or borrowing, OK? Now that is a\nsimplifying assumption. And, indeed, we'll\nspend a couple lectures at the end of the semester\ntalking about what happens when people can save or borrow. That said, this is not\na terrible description of most Americans. The median American household\nhas $400 in the bank. So this is not kind of\na terrible description of the way most people live\ntheir lives in America, which is what they\nearn each week is what they spend each week. So that's what we'll do. It also might not be sort\nof a terrible description of your life. I presume, in college, you're\nnot doing a lot of savings. You maybe do a little\nborrowing, but not a lot of savings or borrowing. So what we're going\nto do is we're going to assume that's\ntrue for you as well. We're going to assume your\nparents have given you some amount of money to spend. We'll call it Y. Your income\nY is the amount of money your parents have given\nyou to spend for say the semester or the month. And, once again, let's say\nall you spend your money on is pizza and cookies, OK? That's all you want to\nspend your money on. We write the budget\nconstraint as saying that your resources,\nyour income Y, can be spent on either\npizza or cookies. And the constraint is\nthat you could spend it-- that budget has to be divided\nbetween pizza, where there's the price per slice of pizza\ntimes the number of slice of pizza, or cookies. We have the price per cookie\ntimes the number of cookies. So p sub p is the price\nper slice of pizza. p sub c is the price per cookie. P is the number of pizzas, and\nC is the number of cookies. That's your budget constraint. You can essentially\ndevote your income to some combination\nof pizza and cookies, but you have to consider\nhow much they actually cost in doing that. I find this easier\nto see graphically."}, {"content": "So let's turn to figure 3-1. Figure 3-1 shows a\nbudget constraint. So how does the budget\nconstraint look? Well, the x-axis is\nyour income divided by the price of cookies. That is, if you decide to devote\nall your income to cookies, then how many\ncookies can you have? Y over pc. If your income is $100,\nand cookies are $10-- that means you're going\nto Insomnia Cookies-- then you can only have\n10 cookies, et cetera. Likewise, the\ny-intercept is the income divided by the price of pizza. That's how many\npizzas you can have. The budget constraint\nrepresents-- the budget constraint, the\nslope of the budget constraint, is the price ratio, the\nnegative of the price ratio because it's a downward-sloping\nline, pc over pp. That is every extra\ncookie that you buy, holding your\nincome constant, lowers the amount of pizza\nyou can have by p sub p, OK? So let's consider an example. Suppose that Y is $96,\nthat the price of pizza-- it's an expensive\npizza place-- is $12, and the price of a\ncookie is $6, OK? $12 for pizza, this is like\ndowntown San Francisco or New York. $96 income, $12 for a slice\nof pizza, $6 for a cookie, OK? I'm sorry. Y is-- I wanted to\nmake Y 72, my bad. So Y is 72. Your income is $72, OK? And you can spend it\non pizza and cookies, and those are the prices. Now what that means is,\nif you wanted just pizza, you could get six pizzas. If you wanted just cookies,\nyou can get 12 cookies. And, generally,\nthe rate at which you can trade off pizza for\ncookies is minus 1/2, OK? That is every additional\ncookie would require giving up half a slice of pizza, OK? Every additional cookie requires\ngiving half a slice of pizza. That's why the slope\nwould be negative 1/2, OK? So, basically, we're going to\ncall the slope of the budget constraint-- the slope, we are going\nto call the Marginal Rate of Transformation, the MRT. Last time, we did the MRS, the\nMarginal Rate of Substitution. Now we're going to have\nMRT, the marginal rate of transformation, which is\nequal to minus pc over pp. Or the slope of the\nbudget constraint, OK? That is the marginal\nrate of transformation. Now this class is not alchemy. We are not literally\ntransforming pizza into cookies. That would be kind of cool,\nbut we're not doing that. That's somewhere\nelse at MIT, OK? But it's effectively\ndoing the same thing. What we're doing is, given that\nwe have a fixed amount of money and given that we're\ngoing to spend it all, the more you spend on pizza,\nthe less you spend on cookies. So you're effectively\ntransforming pizza into cookies and vice\nversa because you're going to spend all your money. You've got to spend\nit on something. So, the more you spend on one,\nthe less you get of another. So, through the\nbudget constraint, we are effectively transforming\none good to the other. By having more of one, we're\ngetting less of the other. So that's the sense\nin which we call it the marginal rate\nof transportation-- of transformation. So, basically, this comes\nback to the key concept we talked about in the very\nfirst lecture, opportunity cost. The opportunity cost of a\nslice of pizza is two cookies. Remember, opportunity\ncost is the value of the next best\nalternative, OK? The opportunity cost is\nthe next best alternative. Well, here you only have\ntwo alternatives, pizza and cookies. So the opportunity cost of a\nslice of pizza is two cookies. And that's the sense\nin which you're transforming pizza into cookies\nor cookies into pizza, OK? Now this seems kind of\nabstract, but let's actually think of an organization\nwhich has taken this principle to heart to develop the\nbest method of weight loss in America, which is Weight\nWatchers, OK, Weight Watchers. Now it turns out that\ndieting is super hard and basically doesn't work, OK? There's a large\nliterature, which says that people go\non diets all the time. Then they stop them, and\nthey gain the weight back. OK, dieting is incredibly hard\nand basically doesn't work, OK? But a much more\nsuccessful approach has been established\nby Weight Watchers. It's not the only\napproach, but it's been proven much\nmore successful, OK? And, essentially, what\ndoes Weight Watchers do? They set up a budget constraint\nand ask you to follow it. So, for example,\nthey essentially assign point values to every\ngood you might consume. You go on the website,\nand everything in the world you might want\nto eat has a point value. They then ask, well, what\nweight are you today? What's your age and gender? That stuff matters\nfor weight loss. And what weight do\nyou want achieve? And they say, if you\nwant to achieve a weight loss of x over y\ndays, then you've got to limit\nyourself to z points. So, essentially, your\ngoal is to lose weight. So we're going to give\nyou the budget constraint. We're not going to\ntell you what to eat. That's why it's\nbetter than dieting because, once again,\nAdam Smith was right. People like to have choices."}, {"content": "They like to let\nchoice drive things. But we are going to\ntell you a total budget. So, for example, vegetables\nare like zero points. Snickers bars are like\nsix points, et cetera. They have various\npoint systems, OK? So, for example, suppose your\nbudget is 30 points, which would be pretty typical, OK? Suppose you go to\nMcDonald's for lunch, and you get a number one. The number one at\nMcDonald's is a Big Mac, which has 14 points, fries,\nwhich have 10 points, and a Coke, which\nhas six points. That's 30 points, and\nit's only lunch, OK? You've blown your whole\nbudget for the day on lunch. Now you could just get\ndepressed and say screw it. I'll just be fat. But, clearly, looking\naround the room, you guys have not\nmade that choice. Or you could look at\nthe budget constraint and say, well, what\nelse can I get. Well, it turns out you can\nget a 10-piece nugget, which is 12 points, apple\nslices, which is one point, and a Diet Coke,\nwhich is zero points, for a total of only 13 points. Now you have 13 points and\nplenty of room for dinner. Now, to be honest,\nanyone who tells you that second lunch is as good as\nthat first lunch is a liar, OK? I'd much rather a Big Mac and\nfries and a Coke than nuggets and apple slice and Diet Coke. Give me a break."}, {"content": "But I'd also much\nrather have dinner, OK? So, basically, this lets\nyou make the trade-off by imposing a budget\nconstraint, by setting relative prices across goods. The points are like utils. They're not meaningful."}, {"content": "They're only\nmeaningful relatively. It lets you set relative\nprices across goods and then it lets\nyou, essentially, optimize across those various-- across those various goods. So budget constraints,\nessentially, by setting up this marginal\nrate of transformation, can help with a lot of\nkind of decisions in life. OK, questions about that? OK, now what happens if we\nshock the budget constraint? So we talked about\nconstructing them. What about shocking\nthe budget constraint? We're going to do a lot\nin this class of what we call comparative statics,\nwhich is, essentially, making changes in\none thing or another and seeing what it\ndoes to the system. So let's talk about shocking\nthe budget constraint. Let's start first with\na change in prices. Suppose the price of pizza\ngoes from $12 up to $18. This is a really good\nslice of pizza, OK? Well, what happens to\nthe budget constraint? Let's look at figure 3-2. Figure 3-2 shows what happens. You have your original\nbudget constraint BC1. The equation of that line is\n12P plus 6C equals 72, OK? The price of pizza and the\nnumber of slices of pizza plus the price of cookies\ntimes the number of cookies equals 72. Now the price of\npizza has gone up. What that's done is that has\npivoted inward your budget constraint to BC2. It has flattened the\nbudget constraint because the slope,\nremember, is the ratio of the price of cookies to\nthe price of pizza, right? That's a ratio."}, {"content": "Well, that ratio\nhas just fallen. It used to be a 1/2. Now it's a 1/3. Negative 1/2-- well,\nit used to be a half. Now it's a 1/3. So the slope has fallen from\nnegative 1/2 to negative 1/3. So what's happened is you can\nstill have as many cookies as you had before. The y-intercept has\nnot changed, but you can have fewer slices of pizza. That's why it's a pivot\nbecause one price has not changed, only the other price. So it's a pivot inward. The other thing\nhere, you'll notice we have all these funny\ndots and stuff, OK? That represents\nwhat has happened to what we call your opportunity\nset, your opportunity set, which is an\nimportant concept, OK? Your opportunity set is the\nset of choices available to you given your income\nand market prices, the set of choices available\nto you given your income and market prices. So your opportunity\nset initially was the black dots\nplus the red dots. Now your opportunity\nset has shrunk. Your opportunity set is\nnow just the black dots. Given your income,\nyou can now get less stuff, same amount of\ncookies, but less pizza. And you are worse off. Your opportunity set has shrunk. Your opportunity set-- even\nthough your parents are still sending you the same check, you\nare worse off because you can now buy less pizza with it, OK? So that's what happens\nto the opportunity set when a price changes. And, likewise, you\nshould show to yourself the same thing will happen when\nthe price of cookies change. In that case, you'll\nget an increase in the steepness of the\nbudget constraint, OK? But your opportunity\nset will still-- your opportunity set\nwill still shrink, OK? Now what about-- yeah? AUDIENCE: Don't we not\ncare about all the dots below the line, though,\nbecause we're assuming we're spending all the money? JONATHAN GRUBER: Well,\nthat's a good point, and we're going to\ncome back to that. We haven't-- we assume they're\nspending all their money, but it's just a way\nof representing. You could think of the line\nbeing lower as the same thing. We care about-- we just\ncare about the area because it represents the\nset, but you're right. You could just focus\non the line and say the line is everywhere lower. So they're worse off. That's another\nway to look at it. But we like to think\nabout as a set. It comes in handy later\nfor various reasons, OK? But that's a good question."}, {"content": "Now let's ask about\na second thing. What if your income goes up? What if prices are\nback to 12 and 6, but your parents decide\nto send you more money? Suppose your parents--\nor send you less money. It turns out you haven't\nbeen paying enough attention in 14.01. You're parents are mad. They're monitoring you. That's why we have\nthe camera here. This goes directly to\nall your parents, OK?"}, {"content": "I'm sort of joking. And so let's say parents cut\nyour allowance to $60, OK? Well, what does that do? That's in figure 3-3. OK, in figure 3-3, the\nold budget constraint was that you get\npizzas and cookies at a price of $6 and $12,\nand you could get them until you spend $72. Now you can only get\nthem until you spend $60. Now what we see is not a pivot\nin the budget constraint, but an inward shift in\nthe budget constraint, because the relative\nprice of pizza and cookies has not changed. Therefore, the slope\nhasn't changed. OK, the slope is\ndictated solely-- you don't do anything\nto control the slope. The market controls\nthe slope, OK? But you and your family\ncontrol the level, and the level has shrunk. So you're pivoting inwards, OK? And, once again,\nnow, instead of being able to buy say 12\ncookies and six pizzas, now you can only buy say\n10 cookies and five pizzas. That's the most you can get, OK? So, once again, your opportunity\nset has been restricted, but in a different kind of way\nthrough this pivot inward, OK? So that's how we\nsort of manipulate these budget constraints. And we're going to come\nback to that next lecture. That'll be important."}, {"content": "Yeah? AUDIENCE: So, in looking\nat the differences, can like an increase\nin the price of pizza or like a decrease\nin your budget-- is it more showing that\nlike the change in slopes doesn't really\naffect you if you're like say buying more\ncookies than pizza? But like, in terms of if\nyour budget as a whole decreases, then it\naffects you overall. JONATHAN GRUBER: That's\na great question, and we're going to actually\nanswer that question next lecture very explicitly. So hold on to that\nquestion, and we'll talk about we're going\nto compare explicitly why income changes\ndiffer from price changes and what are the\nunderlying mechanisms. Yeah? AUDIENCE: How do you\ndetermine your marginal rate of transformation? How do determine your--\nlike say it wasn't just pizza and cookies. Like say it was more products. How would you\ndetermine that value? JONATHAN GRUBER:\nGreat, great question."}, {"content": "So, as I said, we\nalways are going to start with simplifying\nassumptions to make life easy. There's no reason\nthat this couldn't be written in three dimensions. And you'd have\nrelative marginal rates of transformation, rates at\nwhich you're willing to trade off various things. So you could just extend\nthe math in all dimensions. It wouldn't add any\nrichness, and it'd just make your head spin. But the basic-- so\nall the basic ideas can come across with\ntwo goods, but it'd be the same mechanics\nwith more goods, OK? You essentially, when we get to\nthe constrained optimization, you'll essentially have\nmore first-order conditions in your constrained\noptimization. That's the way to\nthink about it."}, {"content": "OK, so let's-- actually,\nthat's a great segue. Let's turn to the\nsecond part, which is how we use budget\nconstraints and the utility function we learned about\nlast time to actually describe how consumers make choices. So we're going to take utility. Remember, I said\nlast time consumers are going to maximize their\nutility subject to a budget constraint. Well, now we've taught\nyou about utility. We've taught you about\nbudget constraints. Let's put them together, OK? How to consume-- how do\nconsumers put them together? Well, graphically, the\nrepresentation of preferences was our indifference curves. That represented\npeople's indifference with further out\nindifference curves made people happy, right? That was last time. So, essentially, what we're\ngoing to ask graphically is what is the\nhighest indifference curve you can achieve\ngiven your budget, right? We know you want to be that\nhighest indifference curve possible by more is better. So we're simply\ngoing to ask what is the highest\nindifference curve you can reach given your budget, OK? So let's consider the same\nutility from last time. Utility is square\nroot of P times C, OK? And let's consider the same\nbudget we wrote down up here-- $72 income, $12 price of\npizza, $6 price of cookies. And now let's ask where\ncan you go with that."}, {"content": "So let's turn to figure\n3-4 and do it graphically."}, {"content": "We'll do it mathematically\nin a minute, OK? So, in figure 3-4, you\nhave our budget constraint, which runs from 6\npizzas to 12 cookies. That's the original\nbudget constraint. And you have a series\nof indifference curves. And these indifference\ncurves, I1, I2, I3, I4, they all come directly\nfrom this utility function. So, simply, I've solved\nthis utility function. I'll talk about the\nmath in a little bit, and you'll do more math\nin section on Friday, OK? But, essentially,\nyou can solve-- we'll show you--\nyou'll drive on Friday how you take this\nutility function and literally can draw the\nindifference curves from it, OK? But, for now, take my word\nthat these indifference curves represent this utility function. And what we see is that\npoint D is the furthest out indifference curve you\ncan achieve while still meeting your budget, while still\nmeeting your budget constraint. And, therefore, we say that\nthe optimum, graphically, is the tangency between\nyour indifference curve and your budget constraint is\nthe optimal constrained bundle. You see how we brought-- last time, we talked about\nfurther out indifference curves make you happier. Today, we talked about\nthe fact that you're limited by your budget. So we have the furthest\nindifference curve you can get to is going\nto be, definitionally, at the tangent of the\nindifference curve and the budget constraint. And, once again,\nthat gives you-- we realize we don't want\nto measure utils, but, just for mathematical, for\nmathematical purpose, that gives utility at the tangency\nof square root of 18, OK? At that point, you are choosing\nsix cookies and three pizzas. That is the choice\nyou are making. That is the best off you\ncan get given your budget. And, to see this, let's\ntalk about some other points and why they're not better, OK?"}, {"content": "Let's talk about point A. Why isn't point A better? Why isn't it better\nto have two-- maybe you just-- maybe you\nlike cookies a lot and don't like--\nor like pizza a lot and don't like\ncookies that much. How can we say that point\nD is better than point A? Yeah? AUDIENCE: Because point D is\non a higher indifference curve. JONATHAN GRUBER: It's on a\nhigher indifference curve. So point D dominates\npoint A because it's a higher indifference curve. Well, fine. Same person, by that logic,\nwhy not choose point E? AUDIENCE: It's above the budget."}, {"content": "JONATHAN GRUBER: Yeah,\nyou can't afford it. So the bottom line is\nyou can see graphically why the tangency is\nthe best you're going-- is the best you're going to do. OK, likewise, point C\nyou wouldn't choose. Point C has the same slope. It has the same\nslope as point D. In other words, the slope\nis minus 1/2 at point C. You've drew a line tangent\nto point C. The slope will be minus 1/2, just\nlike it is at point D, but you wouldn't be\nspending all your money. So you wouldn't choose\nthat point either. Yeah? AUDIENCE: What if you have\njust three indifference curves so there is none\nthat hit the tangent? Do you just go for one that's\nlike the most tangent I guess? JONATHAN GRUBER: We're going\nto come to-- we're going to-- well, first of all,\nwe're not going to have discrete indifference. We could have lines, and\nthe lines could end up-- you could end up lying along. You could end up lying along a\nbudget constraint for example. Or you could have-- you could even have\nutility functions, which just touch a\nbudget constraint at one extreme or another. And we'll talk\nabout those cases. Yeah? AUDIENCE: So [INAUDIBLE]\nutility function go through lines and the\nbudget constraint, right? JONATHAN GRUBER: Yeah. AUDIENCE: Isn't this just\nLagrange [INAUDIBLE]?? JONATHAN GRUBER: Well,\nlet's come to the math then. OK, let's come to the\nmathematical derivation. So that's the graphic. So let's come to the math, OK?"}, {"content": "Now, always a bit\nof a tightrope act when I'm doing math up here on\nthe board, so bear with me, OK? But the key thing is the math\nof constraint optimization is all about the\nmarginal decision. Remember, it's hard to say\nhow many cookies you want. It's easier to say should\nI have the next cookie, OK? It's about constraint\noptimization. And what we want to ask is we\nessentially want to compare how do you feel about trading\noff pizzas versus cookies versus what will the market let\nyou do in sort of trading off pizzas versus cookies. That is the optimum\nis going to occur when we set your marginal\nrate of substitution, which, remember, we defined\nas minus MUc over MUp, equal-- I'm going to get rid of this-- equal to your marginal\nrate of transformation, which we defined as\nminus pc over pp. And this is the fundamental\nequation of consumer choice. If you understand\nthis equation, you can solve virtually\nevery consumer choice problem I'll give you, OK? That basically, at the optimum,\nthe ratio of marginal utilities equals the ratio prices. That is the rate at which\nyou want to trade off pizza for cookies is the rate\nat which the market will allow you to trade off\npizza for cookies, OK? Basically, it's saying\nthe ratio of the benefits. Think of this as the benefits\nand this as the costs. Think of the MRS\nas the benefits. It's what you want. MRT is the costs. It's where you're constrained. You want to set the\nratio of the benefits equal to the ratio\nof the costs, OK? Now I find it actually easier\nto think of it this way. If you just rearrange terms,\nyou can write it as MUc over pc equals MUp over p sub p. I like this way of writing\nit because I call this the bang for the buck equation. What this is saying, your\nmarginal happiness per dollar should be equal. This is sort of the happiness\nper dollar spent on cookies. This is the happiness per\ndollar spent on pizza. And you want those to be equal. You want the bang\nfor the-- you want to put your next\ndollar where it's going to make you happiest, OK? And so, basically, think of\nthat as your bang for your buck. So, for example, suppose\nyou were in a position where the MRS was\ngreater than the MRT. You're in a position where the\nmarginal utility of cookies-- and I'm getting\nrid the negatives. There's negative on both sides. So I'm just going to get\nrid of the negatives, OK? The marginal utility of cookies\nover the marginal utility of pizza was greater\nthan the price of cookies over the price of pizza, OK? That is the slope of\nthe indifference curve was greater than the slope\nof the budget constraint. This is the slope of\nthe indifference curve. OK, this is slope of\nthe indifference curve. This is the slope of\nthe budget constraint. In absolute value, the slope\nof the indifference curve is greater in absolute value\nthan the slope of the budget constraint, OK? That would be true at points\nlike point A, point A where you intersect-- where you basically intersect\nfrom above the budget constraint by the\nindifference curve. So a point like point\nA has a steeper slope of the indifference curve than\ndoes the budget constraint. What that says is\nintuitively-- and, once again, I want you to understand\nthe intuition-- the rate at which you\nare willing to give up, the rate at which you\nare willing to give up cookies for pizzas-- I'm sorry. Let me say it-- let me say it a better way. The marginal benefit to\nyou of another cookie relative to another\npizza is higher than what the market will charge\nyou to turn pizza into cookies. Let me say it again. The marginal benefit to you of\nanother cookie, which is this-- this is how much more\nyou want the next cookie relative to how much more\nyou want the next pizza-- is greater than\nwhat the market is going to charge you to trade\nin your pizza for cookies. Therefore, you should trade\nin your pizza for cookies, OK? So let's say this\nmathematically. At a point like A,\npoint A, OK, you have your marginal\nutility for pizza is the derivative of the\nutility function with respect to the number of\nslices of pizza. It's the marginal utility. It's derivative of\nthe utility function. So it's dU dp, which is equal\nto 0.5 times C over square root of P times C, OK? And, at point A,\nat point A, we had two cookies and five pizzas. At point A, P was five. C was two. OK, that's true of point A. So we can evaluate the\nmarginal utility dU dp, which equals 0.5 times C\nover square root of P times C. So that's 1 over the\nsquare root of 10. That's the marginal utility\nof the next slice of pizza. The next slice of\npizza makes you 1 over square root of 10 happy. Once again, that\nnumber is meaningless. So we only care\nabout it in ratios. So we need the ratio. So let's do the marginal\nutility of cookies. That's dU dC, which\nis 0.5 times P over square root of P\ntimes C, which is 2.5 over the square root of 10, OK? So the marginal utility of pizza\nis 1 over square root of 10. Marginal utility of cookies is\n2.5 over the square root of 10. Therefore, your marginal rate\nof substitution is minus 2.5. Remember, marginal rate of\nsubstitution is MUc over MUp. So your marginal rate of\nsubstitution is minus 2.5. What does that mean? Can anyone tell me\nwhat that means? Your marginal rate of\nsubstitution is 2.5. What does that mean?"}, {"content": "That is a meaningful concept. Utils are not, but that is. Yeah, say it loudly\nso we can hear. AUDIENCE: You're\nwilling to trade-- you're willing to trade\ntwo pizzas for one cookie. JONATHAN GRUBER: You're\nwilling to trade. Exactly, you're willing to\ngive up 2.5 slices of pizza for one cookie. That's what that number means. And that is a meaningful number. That's not an ordinal. That's cardinal."}, {"content": "We can use that. You are willing to give\nup 2.5 slices of pizza to get one cookie. What is the market\nasking you to give up? How much pizza do you have\nto give up to get one cookie? Half a slice. You are happy to give up\n2 and 1/2 slices of pizza to get a cookie,\nbut the market is saying we'll let you\nhave a cookie for half a slice of pizza. So what should you do? AUDIENCE: Trade. JONATHAN GRUBER: Eat less pizza. Eat more cookies. That will unambiguously\nmake you happier. And that's why you should move\nfrom point A towards point D. OK, that's the intuition, OK? You basically want to\ntrade pizza for cookies until these things are equal. Indeed, I'd like you to go home\nand do the same math starting at point B. If you do the\nsame math starting at point B, you'll find the MRS\nis much below 1/2. That is, at that point,\nyou are happy to give up tons of cookies to get pizza\nbecause, jeez, you've got 10 cookies and one slice of pizza. You'd give up tons of\ncookies to get pizza. But the market says you\nonly have to give up two cookies to get pizza. So you'll happily do it, and\nyou move back towards point D. And that's sort of in a bundle\nsort of the intuition and math and graphics of how we do\nconstrained optimization. OK, that is hard\nand very important."}, {"content": "Questions about that? Don't hesitate to ask."}, {"content": "OK, that is hard\nand very important. If you understand\nthis, you're sort of done with consumer theory, OK? This is sort of the core of what\nconsumer theory is all about. It's all about\nthis balancing act. The whole course\nis fundamentally all about one equation,\nwhich is marginal benefits equals marginal costs, OK? Everything we do is going\nto be about weighing the marginal benefit\nof an activity against its marginal costs. If we take the next\nstep, what's the benefit? And what's the cost? Well, here the marginal\nbenefit is the MRS. The marginal cost is the MRT. We want to set them equal."}, {"content": "And this sort of example\nI hope explained why, OK? So that is how we think\nabout constrained choice. Now I want apply it. I want to apply it by looking at\nthe example of food stamps, OK? Now food stamps are not actually\ncalled food stamps anymore. When I was a kid, they\nwere called food stamps. It's basically a program\nthe government has that provides money\nfor individuals to buy food if\nthey're low income. Essentially, we have in the US\nwhat's called the poverty line. And I'll talk a lot more about\nthis at the end of the class, but the poverty\nline is essentially a measure of what's a\nminimum level of resources you need to live in America. The poverty line for an\nindividual is about $14,000. OK, for a family of\nfour, it's about $28,000. How you feel about\nthat number obviously is going depend on\nwhere you're from. If you're from Boston,\nyou'll say that's insane. If you're from some rural\npart of the country, you think, yeah, that's\npoor, but manageable. OK, we'll talk later\nabout the poverty line, what's good and bad about it. But, in any case, if you're\nbelow the poverty line in America, roughly speaking,\nyou get help with buying food. And that comes through a\nprogram we now call SNAP. It used to be\ncalled food stamps. I've got to update my notes. Supplemental Nutrition--\nI don't know. I know the N is for nutrition. OK, so, basically, what\nthe SNAP program does is it gives you a debit card. If you qualify on income\ngrounds, you get a debit card, and that debit card can be used\nto buy food and food only, OK? So you essentially get a\ndebit card from the government that you can use to buy\nfood if you're poor enough. And they give you sort of\na fixed amount every month, and that amount can be\nused to purchase food. So here's the question. Why go through this rigmarole? Why not just give people cash? This fancy thing, if we want\nto give poor people money, why don't you just\ngive them money? And we're going to-- I don't want the answer yet, OK? What I want to do is\nshow you graphically how we think about\nthe trade-off, and then we'll\ncome to the answer. So hold your thoughts. So let's actually graph how\nwe think about food stamps. Let's go to figure 3-5A. And let's start with\na cash transfer. So here's the setup. Imagine people start\nwith an income of $5,000. That's super poor, OK? $5,000 is their whole family\nincome for the year, OK? And let's say all they can\nspend it on is food or shelter. Remember, as this gentleman\npointed out, in life, there's more than two goods,\nbut it makes it a lot easier to have two goods. So imagine this case. Your two goods are\nfood and shelter. And, actually, quite\nfrankly, if you're that poor, that probably is\nthe only two goods you have to-- you can worry\nabout at that level of income. OK, it's food and shelter. So you $5,000 to devote\nto food and shelter. So you have some\noriginal budget line, which is labeled\nthere original budget line, that runs from 5,000\nin food to 5,000 in shelter. And then you can have some of\nin between, some along the way, OK? Now let's say we give\nsomeone $500 in cash. Obviously, this graph\nis not to scale, OK? It looks like you're doubling\nhis income, but it's only $500. This just sort of makes it\neasier, a not to scale graph. Let's say we give someone-- we\nsay to them, look, you're poor. We're going to give\nyou $500 in cash. Well, now all we've done\nis shift out your budget constraint from 5,000 to 5,500. OK, we've shifted out\nyour budget constraint from 5,000 to 5,500. What does that do\nto your choices?"}, {"content": "Well, consider two\ndifferent types of people. Person y, OK, they used to\nbe on indifference curve I0. They used to spend almost\nall their income on food and not a lot on shelter."}, {"content": "They were probably homeless, OK? So they spent all\ntheir money on food and were basically homeless. Now what do they do? Well, they spend a little\nmore on food and a lot more on shelter. Maybe now they get--\nyou know, $400 still doesn't buy you much shelter. They spend a little more, OK? Maybe, a night a week,\nthey can get shelter, OK? So, basically,\nthat's what they do. That's their constrained\noptimization. We're not saying\nit's right or wrong. This is not normative economics. It's positive. The positive thing is, given\ntheir utility function, they move from point y1 to y2. Now imagine someone\nlike individual x."}, {"content": "They're different. Their tastes are such that\nthey don't need to eat. They just want to have shelter. So they're up at\npoint x1 initially. And you give them\nthat $500, and they spend just a little bit more of\nit on food and even more of it on shelter. They just love\ntheir shelter, OK? And they're just super-- they're super Weight Watchers. They don't eat, OK? So, basically, they\nmove from x1 to x2. Once again, not\nnormative right or wrong, it's just these are\nfeasible choices people could make given the opportunity\nset with which they're faced. And that's what happens when\nyou give them the $500 in cash. Questions about what I did\nhere on this graph alone? Yeah? AUDIENCE: Like, even\nif like you gave them money specifically for\nfood, couldn't they then just reallocate\ntheir other money? JONATHAN GRUBER: OK,\nthat's a good point."}, {"content": "We'll come back to that. That's time out if\nyou're not a sports fan. OK, so we will\ncome back to that. And, in fact-- OK, but do people\nunderstand what the cash transfer is, how it works? OK, now let's go to SNAP. And let's say, with SNAP,\ninstead of giving them $500, we'll give them the debit card. Instead of handing\nthem a $500 check, we give them a debit\ncard with $500 on it that can only be used on food. How does this affect\ntheir budget constraint? Now we see where budget\nconstraints start to get interesting and fun\nand the kind of challenges you're going to face in this\ncourse in drawing budget constraints. The original budget\nconstraint continues to be the original budget line\nrunning from 5,000 to 5,000. The new budget constraint\nis this kinked line that runs from 5,000 on\nthe y-axis to the point x2 at 5,000 on the y-axis. So it starts at 5,000 on\nthe y-axis, 0 on the x-axis. There's a flat line that goes\nto 5,000 on the y-axis, 500 on the x-axis. And then it slopes down\nparallel to the original budget constraint to 5,500. Can someone explain to me\nwhy that's the new budget constraint? Yeah? AUDIENCE: You can't\nspend a negative amount. So you can't spend\nlike negative amounts of your non-food-stamp\nmoney on food. JONATHAN GRUBER:\nExactly, you have-- we are forcing you to\nspend at least $500. Compared to cash, where you can\ndo whatever the hell you want, we are forcing you to spend\n$500 of your money on food. Coming to the\nquestion back there, it doesn't have to be a\nspecifically labeled 500. It can be any 500. But we're forcing you to\nspend at least $500 on food. Well, what does that\ndo to your choices? Well, for person y,\nit makes no difference whether they get cash or\nwhether they get food stamps. Now the person, light blue\nshirt, turquoise shirt, asked that question. Why does it make no difference? Yeah? Why does it--\nwhatever, greenish, I don't know, yeah, you. Why does it make no\ndifference for person y if I give him food\nstamps or cash? AUDIENCE: He's already spending\na lot of his money on food. So any money he gets he can\njust reallocate differently so he can spend\nsome of the money he would have used\non food on shelter. JONATHAN GRUBER: Exactly, he can\njust reallocate his money, OK? That's exactly right. So, for person y,\nthere's no difference. Look, they're already\nspending, what, $4,900 on food. You give him a thing\nlabeled $500 for food. It's not going to\naffect their life. They'll just take 500. They'll just spend-- they'll\njust treat it as $500 more in cash. They're indifferent. So nothing affects them. But what about person x? Well, person x, remember,\nthe dashed portion of this budget constraint is\nfrom the old cash example. And the dotted\nindifference curve is what they would\nhave chosen with cash. Remember, person\nx with cash would have chosen to still spend\nless than $500 on food. Even when you gave\nthem $500, they still only spent $300 on food. So we are forcing them to not\nbe on their preferred budget constraint. Rather, we're forcing\nthem down to point x2, which is they'll spend the\nminimum they can on food, but the minimum is $500, OK? We are forcing them\ndown to point x2. Now why do I say forcing them? Why do I know for sure they\nare being forced, that they're less happy at x2 than they would\nhave been when they gave them the cash? How do I know that for sure?"}, {"content": "Yeah? AUDIENCE: They're at a\nlower indifference curve. JONATHAN GRUBER: Exactly. Think of it this way. The fundamental-- one\nof the important things is people always get\nto the point that makes them happiest, OK? We call it the robustness\nof economic equilibria. People get to the point\nthat makes them happiest. They want-- they\nalways before had the choice of spending $500 on\nfood, and they chose not to. Therefore, if you force\nthem to spend $500 on food, they must be less happy, OK? Think of it that way. They always could have\nspent $500 on food. They didn't. Therefore, in\nforcing them, you're making them less happy, OK? So they are worse off, OK? They are forced to spend. They'd rather spend\nsome of that money and find a nicer place to live,\nbut we're not letting them. We're making them buy food, OK? Do people-- I don't want-- I just want to know if people\nunderstand the graphics here and the conclusions I drew. OK, now why?"}, {"content": "Why are we doing this? Why would you-- they're\nbetter off with cash. Why would we force\nthem to have food? Yeah? AUDIENCE: Say\nbecause what makes-- what puts people on the\nhighest indifference is just what makes them\nhappiest, but not necessarily what makes them like\nlive the longest or like have the best\nhealth So, perhaps, like if you never spend money\non food, and then you die, that would be really bad. JONATHAN GRUBER: OK, but,\nbasically, what you're saying is you know better than the guy. Let me-- I'm not accusing you."}, {"content": "I'm just saying, look,\nif people knew best, maybe they'd like to just like\nhave a nice house and die, OK? If people knew\nbest, then there'd be no reason to do this."}, {"content": "The reason to do this is because\nwe think they don't know best. So, for example, let's change\nthe label on the y-axis, just a small change. Let's cross out shelter\nand write cocaine."}, {"content": "[LAUGHTER] OK? Well, in that case, maybe\nwe don't feel so bad about forcing the guy to buy\nfood instead of cocaine, OK? In other words, this a\nprogram which might make sense if we are paternalistic. Now we're getting into normative\neconomics, paternalistic. If we think that people\nwon't necessarily make the right decisions\nfor themselves, then it may be worth\nactually making them worse off because\nthey're not worse off. Their perceived\nbenefits are worse, but they don't know\nwhat they're doing, OK? Now you can see why-- I hope you can\nsort of immediately see why this concept makes\neconomists a little nervous because why do we know what they\nwant better than they do, OK? So it makes people a\nlittle bit nervous, economists a little\nbit nervous, and a lot of people a little bit nervous\nto say, gee, maybe they're just happier doing cocaine. And how do we know that\nthat's the wrong way for them to spend their resources?"}, {"content": "Yeah? AUDIENCE: Well,\nlike can't you look at it from the perspective of\nlike this is taxpayer money, right? So then aren't you\nalso just factoring in how the taxpayer wants to\nspend their money and then their indifference curve\nand all their information? JONATHAN GRUBER: That's\na very good point. Now but there's sort\nof two points there. First of all, if the taxpayers'\ngoal is to help poor people, then why shouldn't you make them\nas happy as possible, right? If tax-- why am I giving\nmoney to this poor guy? Because I'm sad his poor. But, what you're saying, I'm\nnot actually that sad he's poor. I'm sad he's not eating. If you're really\njust sad he's poor, then you should give him money. If what you're\nsad about is, gee, I don't like how he's living-- I don't like his-- I'm sad he can't have better\nfood to eat, sad at the place he lives. Then you're starting to\nimpose your preferences, but let's be important."}, {"content": "That's imposing\nyour preferences."}, {"content": "Yeah? AUDIENCE: I feel like the\nindifference curve only goes for happiness or\nlike contentedness, but, really, the point\nof SNAP isn't really with contentedness or\nhappiness, but rather like what would be to a\nmore sustainable life. JONATHAN GRUBER: Well, that's a\nrelated point of the taxpayer. If the taxpayer\ncares about, look, we want a healthy\npopulace that's going to live a long time and\nbe productive and pay taxes, then that would be\na reason to do this. But, once again, I\nwant to emphasize, OK, this is paternalism. If you really just care\nwhat makes people happiest, you should give them cash, OK? So that raises\ntwo questions, OK?"}, {"content": "First of all, first\nquestion-- yeah? AUDIENCE: So how about\nlike negative [INAUDIBLE].. Because, for example, if\nwe pump a lot of money-- if we allow people to\nspend a lot on shelter, that's not really\ngoing to help people. It would just make the real\nestate developers rich. And say the amount\nof shelter is kind of fixed, but like the amount of\nfood that eaten [INAUDIBLE].. So, if we let people\nspend more money on food-- JONATHAN GRUBER: Yeah,\nyeah, so, basically, that's a great question. And, in general,\nwe're going to-- I'm going to answer a\nlot of those questions with the same cheat\nthis semester, which is we're going to assume\nthe markets are perfectly functioning. So there's no-- you're imposing\nsort of a market failure. If there's no market-- once\nthere's market failures, all bets are off. But, with no market\nfailure and no paternalism, you'd want to give them cash. So this raises an\nimportant question. Do food stamps actually\nincrease food purchases? First of all, there's two\nreasons why they might not."}, {"content": "Reason one is everybody\ncould be like y."}, {"content": "x is sort of a\nsilly case, right? You're going to die if\nyou eat that little. And food stamps\naren't that much. They're maybe like\n$3,000 a year. Everybody is going\nspend $3,000 on food. So the first issue is the first\nreason why food stamps may not matter is that, in\nfact, everybody is spending at least that amount. Everybody is like y,\nand nobody is like x. What's another reason\nwhy it might not matter? What's a way people could\nget around food stamps? Yeah? AUDIENCE: Buy food with\nfood stamps and sell it. JONATHAN GRUBER: Yeah,\nthey could set up a black market where they,\nessentially, say, look, I only want $2,000 of food. The government is\nmaking it worth $3,000. I'll buy my extra\n$1,000 of food, and I'll sell it to\npeople who do want it. And I'll end up still\neating $2,000 worth of food. So we actually want to know do\nfood stamps actually increase food consumption in practice. Are they making a difference? Well, actually, we've run\nan experiment on this, OK? We're going to talk\nin this class a lot about empirical\nresults in economics. This class is mostly going\nto be a theoretical class. That is we'll talk\nabout models and ideas. But we're also--\nsince, basically, I'm an empirical\neconomist, we're going to talk about empirical\neconomics, which is results and testing the\ntheories we develop. Empirical economics,\nhere's a great example of empirical economics is we\nset up a theoretical model. You always want to\nstart with the theory, but the theory sometimes\nhas predictions, which are uncertain. Here we have an uncertain\nprediction from theory about whether food stamps will\naffect food purchases or not. So let's test it. And the way we test\nit is we actually have run food stamps cash out\nexperiments where we literally take guys on food stamps\nand give them cash instead and watch what happens to their\nconsumption before and after. It's a real randomized trial. We literally flip a coin. Heads, you keep\nyour food stamps. Tails, we replace\nthose food stamps with an equal amount of cash. Then we watch what happens. What happens is that people\nspend about 15% less on food when you give them cash\ninstead of food stamps. That is food stamps is forcing\npeople to spend about 15% more on food than\nthey would like to unconstrained by the cash. Yeah?"}, {"content": "AUDIENCE: Yeah, this gets\nyou into the behavior of [INAUDIBLE]. I remember reading an\nexperiment like, if you have the price of gas go down,\nthe actual like amount of money spent on gas is constant. And this might\ntranslate to food stamps because like food stamps\nare like explicitly on food. JONATHAN GRUBER: Yeah, you\nknow, that's a great question. And that's you're asking about\nricher theory, richer theory. And I'm telling you that\nI'm going to give you the empirical evidence. So, whatever the theory\nis, the empirical evidence tells you what happens. And there's different\nexplanations for why. So the empirical evidence is\nthat, basically, the price of our paternalism is 15%, OK? We are making people,\neffectively, 15% worse off. We're making them spend 15%\nmore food than they want to. So is it worth it? Well, actually, the\nevidence is starting to pour in that it might not\nbe worth it because there's starting to be a lot of\nexperiments where we're giving people just cash,\nespecially in developing countries. In developing\ncountries, the answer seems to be just\ngiving people cash makes them better\noff, that actually, especially in\ndeveloping countries, people use the cash\nin productive ways. So, for example, they have a\nseries of evaluation programs where they've given people cash,\nmostly in developing countries, in Africa in particular,\nsome in the US. And they find that people\nspend relatively little of that on drugs and\nalcohol, but they actually tend to spend it productively. And, in fact, they found,\nin developing countries, this often provides valuable\nresources for individuals to start businesses. So they ran experiment Uganda\nwhere a nonprofit company randomly offered\na group of women $150, which is huge\nrelative to their income. That's 50% to 100% of annual\nincome in Uganda, $150. And what they found was, after\ntwo months-- after 18 months, these women had used that\nmoney to start businesses. And that actually\nraised their earnings. That actually effectively\ndoubled their earnings. From that one\ninjection of cash, it led them to actually double\ntheir annual earnings, OK? So that leads one to\nthink that maybe we should stop being paternalistic\nand just give cash. Unfortunately, if you're a\nreader of policy websites like I am, the best one\nof which is vox.com-- it's a great website-- they had an article just\nthe other day pointing out how they actually followed\nthese women up nine years later. And, nine years later, the\neffect had totally gone away. So the story isn't quite\nnecessarily positive, but it's not negative. They're not worse\noff, but it looks like, at least what\nin the short run made them better off, well,\nthat effect fades over time. But the bottom line\nis, at this point, I think the evidence\nis sort of probably in favor of being\nless paternalistic and just giving\npeople cash, but that runs into a lot of difficulties\nin terms of our concerns about how people will spend it. So let me stop there. We will come back\non Monday, and we'll talk about how we actually go\nfrom this stuff to the demand curves we started\nthe class with."}], "Stanford CS229 I Machine Learning I Building Large Language Models (LLMs)": [{"content": "so let's get started uh so I'll be talking about building llms today um so I think a lot of you have heard of llms before uh but just as a quick recap uh llms standing for large language models are basically all the chat Bots uh that you've been hearing about recently so uh Chad GPT from open ey Claud from entropic Gemini and and lman other type of models like this and today we'll be talking about how do they actually work so it's going to be an overview because it's only one lecture and it's hard to compress everything but hopefully I'll touch a little bit about all the components that are needed to train uh some of these llms uh also if you have questions please interrupt me and ask uh if you have a question most likely other people in the room or on Zoom have other have the same question so please ask um great so what matters when training llms um so there a few key components that matter uh one is the architecture so as you probably all know LMS are newal networks and when you think about new networks you have to think about what architecture you're using and another component which is really important uh is the training loss and the training algorithm um so how you actually train these models then it's data so uh what do you train these models on um the evaluation which is how do you know whether you're actually making progress towards the goal of of uh llms and then the system component so that is like how do you actually make these models run on uh Modern Hardware which is really important because these models are really large um so now more than ever system is actually really an important topic um for llms so those five components um You probably all know that llms and if you don't know LMS are all based on Transformers or at least some version of Transformers uh I'm actually not going to talk about the AR lecture today uh one because I gave a SE lecture on um Transformers a few weeks ago and two because you can find so much information online on uh Transformers but I think you can it's there's much less information about the other four topics so I really want to talk about those um another thing to say is that most of Academia actually focuses on architecture and training algorithm and losses um as academics and I've done that for a lot big part of my career is simply we like thinking that this is uh like we make new architectures new models and it it seems like it's very important but in reality honestly what matters in practice is mostly the three other topics so data evaluation and systems uh which is what of most of Industry actually focuses on um so that's also one of the reason why I don't want to talk too much about the architecture uh because really the rest is super important um great so overview of the lecture I'll be talking about pre-training so pre-training uh you probably heard that word this is the general word this is kind of the classical language modeling uh Paradigm uh where you basically train your language model to essentially model all of internet and then there's a post training which is a more recent Paradigm which is taking these large language models and making them essentially AI assistants um so this is more of a recent Trend since Chad GPT uh so if you ever heard of gpt3 or gpt2 that's really pre-training land uh if you heard of chat GPT which you probably have this is really posttraining land uh so I'll be talking about both but I'll start with pre-training and uh specifically I'll talk about what is the task of pre-training llms and what is the laws that people actually use so language modeling this is a quick recap uh language models at a high level are simply models of probability distribution over sequences of tokens or of words so it's basically some uh model of P of X1 to XL where X1 is basically word one and Excel is the last one in the sequence or in the sentence um so very concretely if you have a sentence like the mouse ate the cheese what the language model gives you is simply a probability of this sentence being uttered by a human or being found on on online uh so if you have another sentence like the the mouse at cheese uh here there's grammatical mistakes so the model should know that this uh should have some syntactic knowledge so it should know that this has less likelihood of appearing online uh if you have another sentence like the cheese ate the mouse uh then the model should hopefully know about the fact that usually cheese don't eat Mouse um so there's some semantic knowledge and this is less likely than the first sentence so this is basically at a high level what language models are um one word that you probably have been hearing a lot in the news are generative models uh so this is just something that can generate models that can generate sentences or can generate some data uh the reason why we say language models are generative models is that once you have a model of a distribution you can simply sample from this model and now we can generate data uh so you can generate sentences uh using a language model so the type of models that uh people are all currently using are what we call Auto regressive language models and the key idea of autor regressive language models is that you take this distribution over words and you basically decompose it into the into the distribution of the first word multiply the by the distribution of or the likelihood of the distribution of the second word given the first word uh multiply by P of the third word given the first two words um so there's no approximation here this is just the chain rule of probability which you hopefully all know about uh really no approximation this is just one way of modeling a distribution uh so slightly more concisely you can write it as a product of U of PS of the next word given everything which happened in the past so of the context and uh so this this is what we call Auto regressive language models again this is really not the only way of modeling distribution this is just one way uh it has some benefits and some downsides one downside of autoaggressive language models is that when you actually sample from this autoaggressive language model you basically have a for Loop which generates the next word then conditions on that next word and then regenerate an other word so basically if you have a longer sentence that you want to generate you it takes more time to generate it uh so there are some downsides of this current Paradigm but that's what we currently have so I'm going to talk about this one uh great so Auto regressive language models at a high level um what the task of autoregressive language model is is simply predicting the next word as I just said so if you have a sentence like she likely prefers uh one potential next word might be dogs and the the way we do it is that we first tokenize so you take these words or subwords you tokenize them um and then you give an IDE for each token so here you have 1 2 three uh then you pass it through this black box as I already said we're not going to talk about the architecture you just pass it pass it through a model and you then get a distribution a probability distribution over the next word over the next token and then you sample uh from this distribution you get a new token and then you DET tokenize so you get a new ID you then DET toonize and that's how you basically sample from a language model uh one thing which is important to not is that the last two TS uh two steps are actually only need needed during inference uh when you do training you just need to predict uh the most likely token and you can just compare to the real token which happen in practice and then you basically change the weights of your model to increase the probability of generating that token um great so autoaggressive neural language models so to be slightly more specific still without talking about the architecture uh the first thing we do is that we have all of these oh sorry yes on the previous slide when you're predicting the probability of the next tokens does this mean that your final like output VOR has to be the same dimensionality as the number of tokens that you have yes how do you deal with like if you have more to like if you're adding more tokens to your cor something yeah so we're going to talk about tokenization actually later uh so you will get some sense of this you basically can deal with adding new tokens I am I'm kind of exaggerating there are methods for doing it but essentially people don't do it um so it's really important to think about how you tokenize your text and that's why we'll talk about that later but it's a very good point to notice that you basically the vocabulary size so the number of tokens that you have is essentially the output of your uh language model so it's actually pretty pretty large okay so autoaggressive new language models first thing you do is that you take every word or every token you embed them so you get a um some Vector representation for each of these tokens um you pass them through some ual Network as we said it's a Transformer then you get a representation for all the word in all the words in the context so it's basically representation of the entire sentence uh you pass it through a linear layer as you just said to basically map it to the number so that the output the number of outputs is the number of tokens uh you then pass it through some soft Max and you basically get uh probity distribution over the next words given every word in the context and the law that you use is basically it's essentially a task of classifying the next token so it's a very simple kind of machine learning task so you use the cross entry P loss where you basically you look at the actual Target that happened which is a target distribution which is a one hot encoding which here in this in this case says I saw uh the real word that happened is cat so that's a one hot um distribution over cat and here this is the actual uh do you see my mouse oh yeah this is the distribtion that you generated and basically you do cross entropy which really just increases the probability of generating cat and decreases all the the probility of generating all the other tokens one thing to notice is that as you all know again uh this is just equivalent to maximizing the text log like the text log likelihood because you can just rewrite the the max over the probability of um this autoregressive language moding task as just being this minimum over I just added the log here and minus which is just the minimum of the loss which is the cross enty loss so basically minimizing the loss is the same thing as maximizing the likelihood of your text any question questions okay tokenizer um so this is one thing that people usually don't talk that much about tokenizers are extremely important uh so it's really important that you kind of understand at least uh what they do at a high level so why do we need token in the first place uh first it's more General than words so one simple thing that you might think is oh we're just going to take every word that we will have you just say every word is a new is a token in its own um but then what happens is if there's a typo in your word then you might not have any token associated with this this word with a typo and then you don't know how to actually pass this word with a typo into a large language model so what do you do next and also even if you think about words words is a very like words are fine with like Latin based languages uh but if you think about a language like taii you won't have a simple way of tokenizing by spaces because there are no spaces between words um so really uh tokens are much more General Than Words first thing second thing that you might think is that you might tokenize every sentence character by character you might say a is one token b is another token uh that would actually work and probably very well the issue is that then your sequence becomes super long and as you probably remember from the lecture on on Transformers uh the complexity uh grows quadratically with the length of sequences so you really don't want to have a super long sequence um so tokenizers basically try to deal with those two problems and give common subsequences a certain token and usually how you should be think about is around uh an average every token is around three four letters um and there are many algorithm for tokenization I'll just talk about one of them to give you a high level which is what we call bite P en coding which is actually pretty common one of the two most common tokenizers and the way that you train a tokenizer is that first you start with a very large Corpus of text and here I'm really not talking about training a large language model yet this is purely for the tokenization step uh so this is my large Corpus of text with these five words um then you associate every character in this Corpus of text a different token uh so here I just split up every character with a different token uh and I just color coded all of those tokens and then what you do is that you go through your text and every time you see pairs of tokens that are very common the most common pair of token you just merge them so here you see three times the the the tokens T and O next to each other so you're just going to say this is a new token and then you continue you repeat that so now you have to talk which happens three times to with an E that happens sorry two times and an token which happens twice and then ex which also happen twice so this is that if you were to train a tokenizer on this Corpus of text which is very small that's how you would uh finish with a token with a pre like a trained tokenizer uh in reality you do it on on much larger corpuses of text um and this is the real tokenizer of uh actually I think this is gpt3 or chat GPT uh and here you see how it would actually separate these words so basically you see the same thing as what we gave in the previous example token becomes its own token so tokenizer is actually split up into two tokens token and iser um so yeah that's all about tokenizers any questions on that yeah how do you deal with spes and how do you deal with yeah so actually there's a a step before tokenizers which is what we call pre- tokenizers which is exactly what you just said uh so this is mostly in theory there's no reason to deal with spaces and punctuation separately you could just say every space gets its own token every um uh punctuation get its own token and you can just do all the merging the problem is that so there's an efficiency question actually training these tokenizes takes a long time uh so you better off because you have to consider every pair of token so what you end up doing is saying if there's a space this is very like pre- tokenizes are very English specific you say if there's a space we're not going to start looking at the the token that came before and the token that came afterwards so you're not merging in between spaces but this is just like a optimiz like a computation optimization you could theoretically just deal with it um the same way as you deal with any other character and yeah when you merge tokens do you delete the tokens that you merged away or do you keep the the smaller tokens that merge um you actually keep the smaller tokens I mean in reality it doesn't matter much because um usually on large Corpus of text you will have actually everything uh but you usually keep the small ones and the reason why you want to do that is because if in case there's as we said before you have some um some grammatical mistakes so some typos you still want to be able to represent these words by character um so yeah yes are the tokens unique so I mean say in this case T Ken is there only one occurrence or could do you need to leave multiple occurr so they could have take on different meanings or something oh oh I see what you say no no it's every token has its own uh unique ID um so a usual this is a great question for example if you think about a bank which could be bank for like money or bank like water um it will have the same token but the model will learn the Transformer will learn that based on the words that are around it it should associate that I'm saying I'm being very high wavy here but associate that with the with a with a representation that is either more like the bank money side or the Bank water side um but that's a Transformer that does that it's not a tokenizer yes yeah so you mentioned during tokenization keep the smaller tokens you started with right like if you start with a t you keep the T and then you build your tokenizer to the that you can now in token so let's say maybe you didn't train on token but like in your data you are trying to encode token so how does the tokenizer know to encode it with token or a great question you basically when you so when you tokenize so that's after training of the tokenizer when you actually apply the tokenizer you basically always choose the largest uh token that you can apply uh so if you can do token you will never do T you will always do token um but there's actually so people don't usually talk that much about tokenizers but uh there's a lot of of computational benefits uh or computational tricks that you can do for making these things faster uh so I really don't think we and honestly I think a lot of people think that we should just get away from tokenizers um and just kind of tokenize character by character or bites by bites uh but as I said right now there's this issue of like length uh but maybe one day like in five or 10 years we will have different architectures that don't scale quadratically with the length of the sequence and uh maybe we'll um yeah move away from tokenizes so can you share with us the drawback why do people want to move away from the tokenizer oh um yeah so think one good example is uh math if you think about math actually numbers right now are not tokenized so for example 327 might have its own token which means that models when they see numbers they don't see them the same way as we do and this is very annoying because what I mean the reason why we can kind of generalize with math is because we can deal with every every letter separately and we can then do composition where you know that basically if you add stuff it's just the same thing as adding every one separately plus like whatever the unit that you add so they can do that um so then you have to do like special tokenization and like one of the big changes that GPT 4 did uh is changing the way that they tokenize uh code so for example uh if you have code you know you have like often in Python these four spaces at the beginning those were dealt with uh kind of strangely before um and as a result like the model couldn't really understand uh how to deal with code uh so so toiz actually a lot um okay so I'll move on right now but we can come back later on token Isis great so we talked about the task the L the tokenizer let's talk a little bit about evaluation uh so the way that LMS are usually evaluated is what we call is using what we call perplexity um at a high level it's basically just your validation loss uh the slight difference with perplexity is that we use something that is slightly more interpretable which is that we use the average per token loss and then you expon entiate it and the reason why you exponentiate it is because you want I mean the loss has a log inside and you like one humans are actually pretty bad at thinking in log space but two logs depend on the base of the log uh while when you exponentiate you basically have everything in the uh kind of the vocabulary size uh unit um and the average proten is just so that your your complexity is independent of the length of your sequence um so perplexity is just two to the power uh average of the loss of the sequence um so perplexity is between one and the length of the vocabulary of your tokenizer uh one it's simply well if you predict perfectly the thing which uh every word then every word will have basically product of ones uh so the best perplexity you can have is one if you really have no idea you basically predict with one divided by uh size of vocabulary um and then you do simple math and you basically get perplexity of size of vocabulary uh so the intuition of perplexity is that basically the number of tokens that your model is kind of hesitating between uh so if you if your model is perfect it doesn't hesitate it know exactly the word if it really has no idea then it hesitates between uh all of the vocabulary uh so perplexity really improved that's perplexity on a standard data set between 2017 and 2023 it it went from kind of 70 tokens to less than 10 tokens over these five six years so that means that the models were previously as dating between 70 words every time it was generating a word and now it's as dating between like less than 10 words so that's much better perplexity is actually not used anymore in academic benchmarking mostly because it depends on the tokenizers that you use uh it depends on the actual data that people are evaluating on but it's still very important for development of llms so when you when you actually train your own llm people will still really look at the perplexity uh one common other way and now more common in Academia of evaluating these llms is just by taking all the classical NLP benchmarks and I'll give you a few examples later and just kind of aggregating everything um so collect as many automatically evaluatable benchmarks and just evaluate across all of them um so one such if uh or actually two such uh benchmarks of what we call uh Helm which is from Stanford and another one is the hugging face open LM leader board which are the probably two two most common ones right now um so just to give you an idea in Helm there are all of these type of tasks which are mostly things that can be easily evaluated uh like question answering so think about many different question answering uh tasks um and the benefit with question answering is that you usually know what is the real answer um so you can the way that you evaluate these models and I'll give you a concrete example in one second um is that you can just look at How likely the language model is to generate the real answer compared to some other answers and that's essentially at a high level how you evaluate these models um so to give you a specific example mlu is probably the most common um academic Benchmark for llms uh and this is just a collection of many question and answers in all of those domains for example College medicine College physics astronomy and these type of topics and the questions are things like so this in astronomy what is true for type 1 a supernova then you give uh four different potential answers and you just ask the model which one is more likely so there are many different ways of doing it either you can look at the likelihood of generating all these answers uh or you can ask the model which one is the most likely uh so there are different ways that you can promp the model but at a high level you know which one is correct and there are three other mistakes um yes kind creating is like unconstrained text as the output yeah how do you evaluate a model if it give something that's you know semantically completely identical but is not the exact token list that expect yeah so that's a great question I'll talk more about that later here in this case we don't do unconstrained so the way you would evaluate MML is basically either you you ask the first question and then you look at the likelihood of the model generating a the likelihood of the model generating b c and d and you look at which one is the most likely or you can as the model out of ABC d which one is the most likely and you look at whe the to the most likely next token is A B C or D so uh you can strain the model to say it can only answer these four things you say you constraint the model you mean you constraint The Prompt or do you mean of its whole probability distribution outputs you only comparing the outputs like you're only comparing the a so uh in the second case I gave you you would do exactly the I actually you would do both you would prompt the model saying ABC or D plus you would constrain to only uh look at these two these four tokens in the first case you don't even need to generate anything so in the first case you literally just look given that it's a language model it can give a distribution over sentences you just look at what is the likelihood of generating all of these words what is the likelihood of generating the second choice and you just look at whether the most likely sentence is actually the real answer so you don't actually sample from it you really just use P of x one to excel does that make sense uh that being said evaluation of open-ended questions is something we're going to talk about later and is actually really important and really challenging yes earlier you mentioned that um like um metrics like flexity are not are not like usually used because it depends on like how you do your terization some design choices I was wondering if you could speak more to that oh um yeah so think about perplexity I told you perplexity is between one and vocabulary size so now imagine that Chad GPT uses a tokenizer that has like 10,000 tokens but Gemini from Google uses a tokenizer that had 100,000 uh potential tokens then actually the Gemini one will will have like the upper bound of the the perplexity that you can get is actually worse for Gemini than for Chad GPT does that make sense so that's just an idea it's actually a little bit more complicated than that but that's just like one uh first or the bit of you can see that the tokenizer actually matters um great okay so evaluation challenges there are many I'll just talk about two really briefly uh one as I told you there are two ways of doing evaluation for these mlu actually there are many more than two but I give you two examples um and it happens that for a long time even though that was a very classical Benchmark that everyone used uh actually different uh different companies and different um different uh uh different organization were actually using different ways of evaluating mlu and as a result you could you get completely different results for example Lama 65b uh which was the first model of meta in the Lama series uh had on Helm 63.7 accuracy but on this other um Benchmark had like 48.8 um so really the way that you evaluate and this is not even talking about prompting this is really just kind of the the way that you evaluate the uh the models prompting is another issue so really there are a lot of inconsistencies it's not as easy as it looks uh first thing yeah sorry how can we make sure that all these models AR trained on The Benchmark okay second thing this is a great question uh chain test contamination uh this is something which I would say is really important in Academia in uh given that the talk is mostly about training large language models uh for companies it's maybe not that important CU they know what they trained on uh for us we have no idea so for us it's a real problem uh so there are many different ways of trying to test whether uh the test set sorry whether the test set was actually in the training Set uh one kind of cute trick um that people uh in in the lab on T lab have found is that what you can do is that given that most of the data set online are not randomized you can just look at and in that language models what they do is just predict the next word um you can just look at the entire test Set uh what if you generate all the examples in order versus all the examples in a different order and if it's more likely to generate a thing in order given that there's no real order there then it means that probably was in a training set does that make sense um so there are many that's like one of them there are many other ways of doing it train test contamination again not that important for development really important for academic benchmarking great so there are many other challenges but uh I'll move on for now great data um so data is another really big topic um at a high level people just say oh you basically train large language models on all of Internet what does that even mean um so or people sometimes say all of clean internet which is even less defined um so internet is very dirty and really not representative of what we want in practice if I download a random website right now you would be shocked at what is in there it's definitely not your Wikipedia um so I'll go really briefly on like what people do um I can answer some questions but I mean data is on its own is a huge topic uh basically first what you do is download all of Internet what that means is that you use uh web crowlers that will go on every web page on Internet or every web page that is um on Google uh and that is around 250 billion pages right now um and that's around one petabyte of of data so this is actually a common common C is one web crowler so people will usually write their own web crowlers what they do is that they use standard web crowlers and we common crawl is one of them uh that basically every month adds all the new websites that were added on uh internet that are found by by Google and they put it in a big uh basically a big data set um so that's on common call you have around 250 billion pages right now so 1 E6 gigabytes of data once you have this uh so this is a random web page like literally random uh from this common craw and what you see is that one it really doesn't look at type of things that you would usually see but actually so this is an HTML page uh it's hard to see but if you look through you will see some content for example here here uh tesing world is your ultimate source for the system X high performance server and then you have three dots so you don't even the sentence is not even finished that's how a random internet looks like uh so of course it's not that useful if you just train a like large language model to generate things like this so what are some of the steps that are needed first one you extract the text from the HTML so that's what I just try to do by looking at uh basically the correct text uh there are a lot of challenges by through this for example extracting math is actually very complicated but pretty important for training large language models um or for example boiler plates a lot of your forums will have the same type of headers the same type of Footers uh you don't want to repeat all of this in your data um then you will filter undesirable content uh so not safe for work harmful content pii uh so usually every company has basically a a black list of websites that they don't want to train the models on that Black List is very long and you basically say if it comes from there we don't train on this there are other ways of doing these things is that you can train a small model for classifying what is pii removing these things um it's hard every Point here that I'm going to show you is like a hard amount of work uh but I'm going to go go quickly through it so filter undesirable content second or fourth is the dup D duplication as I said um you might have things like headers and Footers in forums that are always the same you want to remove that another thing that you might have is a lot of URLs that are different but actually show the same website um and you might also have a lot of like U um paragraphs that come from like common books that are basically duplicated a thousand times or 10,000 times on internet so you have to duplicate also very challenging uh because you have to do that at scale once you do duplication you will do some heuristic filtering you will try to remove low quality documents uh the way you do that are things like rules-based um filtering for example if you see that there are some outlier tokens if the distribution of tokens in the website is very different than the usual distribution of tokens then it's probably some outlier if you see that the length of the words in this website is super long there's something strange going on on that website if you see that the the website has only three words maybe is it worth training on it maybe not if it has like 10 million words maybe there's something also wrong going on that page um so a lot of rules like this yes why we filter out undesirable content from our dat set instead of kind of putting it in is like a supervised loss right like can we not just say like you know here's this like hate speech website let's actively try to Let's actively penalize the for generating we'll do exactly that but not at this step that's where the posttraining will come from uh pre-training um the idea is just to say I want to model kind of how humans speak essentially um and I want to remove all these like headers photos and and menus and things like this but it's a very good uh like idea that you just had and that's exactly what we'll do later Next Step modelbased filtering so once you filtered a lot of data what you will do uh that's actually a very cute trick uh you will take all of Wikipedia and you will look at all the links that are linked through Wikipedia p because probably if something is referenced by Wikipedia it's probably some high quality website and you will train a classifier to predict whether something comes from whether a document comes from one of these references uh from Wikipedia or whether it's from the random web and you will try to basically say I want more of the things that come from Wikipedia references does that make sense so yeah so you will train a a machine learning uh model usually also very simp simple models because you need to do that really at scale I mean just think about the 250 billion Pages uh next one you will try to classify your data into different different um domains you will say okay this is entertainment this is books this is code this is like these type of domains and then you will try to either um up or down weight some of the domains uh for example you might say uh you might see that actually if you train more on code then actually your model becomes bettered on reasoning so that's something that people usually say in a very handwavy way if you train your model more code actually it helps reasoning so you want to upweight the coding uh distribution because that helps for General language modeling skills uh books is usually also another one that people usually um upweight entertainment they usually downweight uh so things like this of course you want to do it so people used to do it maybe uh kind of theistically now there's entire pipelines that we'll talk about of how to do these things uh slightly more um automatically and then at the end of training uh usually train um after training on all of this data that we saw usually train on very high quality data at the end of of training your large language model where you decrease your learning rate uh and that basically means that you're kind of overfitting your model on a very high quality data so usually what you do there is like Wikipedia you basically overfit on Wikipedia yeah and you overfit on like human uh data that was collected um the other things like continual pre-training for getting longer context I'm I'm going to skip over all of these things uh but I just to give you a sense of how hard it is when people just say oh I'm going to train on internet that's a lot of work um and really we haven't figured it out yet so collecting World data is a huge part of practical large language model uh some might say it's actually the key yes about data so basic question so usually when you start with like the terabyte of data after I go through all that steps the typical amount of data you have in and then like how how large a team does it typically think to go through all the steps you talk about so how is the question how large is the data after you filter yeah after you filter and then to go through all the step how large a team do you need to go through like the the other fation sttion uh how slow is it or how like how how many people would you need to be able to do this uh okay that's a great question I'm going to somewhat answer about the data uh how large is the data set uh at the end of this slide uh for number of people that work on it um that's a good question I'm actually not quite sure but I would say yeah I actually don't quite no but I would say it's probably even bigger than the number of people that work on kind of the two tuning of the pre-training of the model uh so the data is bigger than kind of the modeling aspect um yeah I I don't think I have a good sense I would say probably in Lama's team which have like 70 years people I would say maybe 15 work on data uh I yeah all these things you don't need that many people you need a lot of computer so because for data you need a lot of CPUs um so yeah and I'll answer the second question at the end of this slide so as I just kind of alluded to really we haven't solved data at all for pre-training so there's a lot of research that that has to be done first how do you process these things super efficiently uh second how do you balance kind of like all of these different domains uh can you do synthetic data generation that's actually a big one right now uh and because we don't have uh we'll talk about that later we don't have enough data on the internet um can you use multimodal data instead of just text data and how does that improve even your text performance um there's a lot of seccy because really this is the key of most of the pre-train pre-trained large language models so for competitive Dynamics uh usually these these um these companies don't talk about how they do the data collection and also there's a copyright liability issue they definitely don't want to tell you that they've trained on books even though they did um because if not you can uh sue them uh common academic benchmarks uh so that will kind of answer what you asked um it started so those are the smaller ones it's the names are not that important but it started from around 150 billion tokens which around uh 800 GB of data now it's around 15 trillion of to 15 trillion tokens which is also uh the size of the models that are right now the best models are probably trained on that amount of data so 15 trillion tokens uh which is probably I guess two order of manage bigger than that so 80 uh E3 gab so that would be around 100 to thousand times uh filtering of the common crawl if I'm not mistaken um so yeah one very one very uh famous one is the pile so this is academic Benchmark of the pile and we can just look at what distribution of data they have it's things like um archive PBM Central uh which is all the the biology stuff uh here it's Wikipedia you see stack exchange um some GitHub and some books and things like this um again this is on the smaller side so this is if we look at here this is on 280b so in reality it's like 100 times bigger so you cannot have that much of GitHub and and of Wikipedia um in terms of close Source models just to give you an idea uh Lama 2 um it was trained on 20 two trillion tokens lamb 3 15 trillion tokens which is currently the best model that we know on how much it was trained on which is the same thing as this the the the best academic or the biggest academic Benchmark which is 15 trillion tokens GPD 4 we don't really know but it's probably in the same water of magnitude or it's probably around that actually it's probably around 13 um from leaks if the leaks are true um great so scaling laws um any other questions on Data before you go to scaling laws sorry I know I'm giving you a lot of information but uh there's a lot into training at large language models great scaling laws so so the idea is that what people saw um around 2020 or at least from a long time but they've been able to kind of theoretically show it or impurely show it since 2020 is that the more data you train your models on and the larger the models the better the performance this is actually pretty different than what you've seen in this class in this class we teach you about overfitting overfitting doesn't happen with large language models uh larger models better performance um it's something that really took a long time for the community who took this type of class to realize um but for the exam overfitting exists so okay the idea of scaling laws is that if given that you know that more data and larger models will always give you better performance can we predict how much better your performance will be if you increase the amount of data and the size of your model and surprisingly it works uh so here you see three plots from a very famous paper called scaling loss from openi um here you see on the x-axis compute so how much did you train like how much compute did you did you spend for training and here you see test loss so this is essentially I mean it's not perplexity but it's your validation loss um so it's a log of the perplexity and if you put these two on uh log scale uh then you see that uh the the performance or like the this the sorry the the scaling law is linear uh that means that if you increase your compute by a certain amount you can you can say by how much your test loss will actually decrease same thing with data and same thing for parameters if you increase the data set size your loss will will decrease by an amount that is somewhat predictable if you increase the number of parameters it will decre the loss will decrease by amount which is somewhat predictable this is really amazing um very surprising I mean it looks in nocuous when you look at these type of plots but that's crazy because it means that you can predict uh how well we're going to perform in 2 3 years depending on how much compute we will add assuming that these things will hold there's nothing theoretical about it um yes two things one what is the loss that they're using here is this perplexity or so it's it's you know I said perplexity was like two to the power of the LW so this is the the the power of the perplexity and then the second thing is when you like increase the number of parameters or you increase the total data set size going dat times doesn't that just inherently increase your compute like do all this work to just specific no this is a great question so the compute here is actually a factor of two things the data and the parameter what I'm showing here is that you can um well actually we're going to talk about that in details but basically if you increase the number of parameters you should increase the number of data that you have um so you actually don't go multiple times through the same data set no one does EPO in a lar at least not yet uh because we have still kind of enough data um so yeah this is all the same Trend which is increase compute decrease loss yes have we seen the numbers for the last two years or is it still holding it is still holding I I don't have like good numbers to show you uh but it is still holding surprisingly yes is there no evidence like empirical evidence that you plateau expected PL no empirical evidence of plateauing anytime soon um why we don't know um will it happen probably I mean it doesn't need to because it's actually in log scale so it's not like as if it had to go it had to Plateau like mathematically it could continue decreasing like this I mean most people think that it will probably Plateau at some point we don't know when um okay so that's I'll talk more about scaling laws now so why are scaling laws really cool imagine that I give you um you're very fortunate I gave you 10,000 gpus for this month what model will you train how do you even go about answering that question and I mean this is a a hypothetical but that's exactly what these companies are faced with uh the old pipeline um which was basically you tune High parameters on the big models so let's say I have 30 days I will train 30 models for one day each I will pick the best one uh and that will be the final model that I will use in production um that means that the model that I actually used was only trained for one day the new pipeline is that you first find a scaling recipe so you find something that tells you for example oh like one common thing is that if you increase the size of your model you should decrease your learning rate so you find a scaling recipe such that you know if I increase the the the the size of my model here's what I should do with some high parameters then you tune your high parameter on smaller models of different sizes let's say I will say for 3 Days of my 30 days I will train many different models and I would do highper parameter tuning on these small models each of different sizes then I will fit a scaling law and try to extrapolate from these smaller models which one will be the best if I if I train it for much longer or sorry if I train it for a larger model and then I will train the final huge model for 27 days instead of just one day um so the new pipeline is not train things or do high prity tuning on the real scale of the model that you're going to use in practice but do things on smaller ones at different scales try to predict how well they will perform once you make them bigger I will give I will give you a very concrete example right now uh let's say Transformers versus lstms let's say you you have these 10,000 gpus you will not sure which one you should be using should I be using Transformer based model or LCM based model what I will do is I will train Transformers at different skills so here you see different parameters on the x-axis Y axis is my test loss I will then train different different lstms at different scales once I have these points I will see oh it kind of fits a scaling law I will fit my scaling law and then I will be able to predict oh if I had 10 times more compute here's how well I would perform for the LM it's actually slightly less linear for the lstm but like you could probably try to predict where you would end up and clearly from this plot you would see that Transformers are better um one thing to notice when you read these type of scaling laws is that are two things that are important uh one is really your scaling rate uh which is kind of the uh the slope of the the slope of the scaling law the other thing is your um your intercept like you could start worse but actually become better over time it just happens that lstms are worse for both uh but I could show you another one where things you can predict that actually after a certain scale you're better off using that type of model than others uh so that's why scaling laws are actually really useful any questions on that yeah so these are all kind of very how how sensitive are these to like small differences in the architecture like one one like Transformer architecture versus another Transformer architecture you basically have to like fit your own curve and make basically say like oh scaling law has tell me there should be some like logarithmic function let me extrapolate that for my own yeah so uh usually for example if you're an academic and you want to now at least that's like pretty recent and you want to propose a new like activation uh that's exactly what you will do you will fit a scaling law show another scaling law with the standard like I don't know G and you will say that it's better in reality once you start thinking about it in scaling loss terms you really realize that actually all the architecture differences that we can make like the small minor ones all they do is maybe change a little bit the The Intercept but really that doesn't matter uh cuz just train it for 10 hours longer or like wait for the next uh for the next Compu gpus and these things are really secondary which is exactly why I was telling you originally people spend too much time on the architecture and losses um in reality these things don't matter as much data though if you use good data you will have much better scaling loss than if use bad data so that really matters uh another really cool thing you can do with scaling laws is that you can ask yourself uh how to optimally allocate training resources should I train larger models because we saw that it's better when you train larger models but we saw that it's also better when you use more data so which one should I do should I just train on more data a smaller model or should I train a larger model on less data um so chinchilla is a very famous paper that first showed this uh the way they did it I want to give you a little bit of a sense of what these plots are uh here you see training loss again on the x-axis you see parameter parameter differences uh sorry parameter size uh number of parameters so the size of the model and here all these curves are what we call isof flops which is that all the models on this curve H have been trained with the same amount of compute um the way that you do that is that you train you change sorry you vary the number of tokens that we trained on and the size of the models but you vary in such a way that the total compute is constant okay so all these curves that you see with different colors have different amount of computers that were trained on then you take the best one for each of those curves once you have the best one for each of those curves um you can ask you can plot um how much flops it was and which curve were you on and how much parameters did you actually use for training that specific point you put that on the on the log log uh scale again and now you fit a scaling law again so now I have something which tells me if I want to train a model of 10^ 23 flops here's exactly the number of parameters that I should be using 100 100b and you can do the same thing with flops and tokens so now you can predict if if I tell you exactly I have one month of compute what size of model should I be training F your scaling law and I tell you um of course that all looks beautiful in reality like there's like there's a lot of like small things of like should you be counting like embedding parameters like there's there's a lot of complexities but if you do things well these things actually do hold um so the optimal number of parameters that that chinchilla Pap have found is to use 20 tokens for every parameter that you train uh so if you add one more parameter you should add you should train your thing on your model on 20 more tokens so one caveat here is that this is optimal training resources so that is telling me if you have 10^ 23 FL or if you have like 100 I don't know how much that is100 million or 10 no that's much less actually let's say I have $5 million to to train my best model that gets the lowest loss how how what would I train on in reality these companies need to think about inference also if you have a smaller model they will spend less over time um so actually if you consider the inference cost you have other papers that Tred to show that um it's around 150 uh parameters per sorry tokens per parameters because you prefer having a smaller model cuz over time you're going to you're going to actually um spend less money on inference of these models so 150 to one that's around what the best models are trained on right now at least the ones that are that are used um in practice for in production great any question on chin great oh sorry in practice how expensive is inference for these models rela to train actually very expensive uh I will not talk about inference because that would be another entire lecture but just think about Chad GPT where they have I don't know how much it is now like 600 million people that used it um like that's a lot um yeah so it's actually very expensive there's a lot of optimization you can do for in though um and that's an entire other lecture so I'm going to skip that uh this time but it's very interesting okay tuning um as I said there are many things that you can uh answer with scaling laws I just try to give you two examples uh but really there are many things what data do you use what mixture what data mixing waiting you use data mixtures that's what we talked about before uh what architecture you use whether you should make your models uh wider or deeper um should you be paying for more gpus or actually collecting more data um all these things are things you can try to answer with scaling laws one thing I want to say is the bit lesson if you ever heard of Richard sudden a very famous blog post in 2019 um what he realized uh which I think not enough people realize I didn't definitely did not realize at that time um is that once you see these type of scaling laws you know that the more compute you have the better models you will get so with skill you will get better model and you also know by Mo law or these type of variant of Mo law that you will always have better compute then the only thing that matters is just to have architectures that can leverage computation so what matters is basically systems data and less so the architecture like the small architecture differences like your your your activation and things like this uh so I think that's like one of the reasons why most of research focuses on um some things that for industry matters less and I was one of those researchers for a large part of my my career um so don't spend time over complicating do the simple things do it well seal them that's really what openi taught us with um with chat gpg and with all the gpts before okay I want to give you some backup the envelope computation so I might be off by a few factors here but I just want to give you a sense of how costly it is to train some of these models I'll give as an example Lama 3 400b which is currently the best open source model that you can get uh it was trained on 15.6 tokens it has 45 billion parameters so just now that you know what is like this uh optimal tokens per parameter that's around 40 so that's a little bit more than chinchilla but less than this like inference uh optimal um model so they went for training optimality uh flops for this model so one simple uh way to compute flops is six uh times the number of parameters times the number of data you train on uh so if you do the simple calculation here it's 3.8 e25 flops the reason why this is important is that if you follow the little bit the news there's an executive order from Biden that basically says that once you have uh 1 e26 parameters uh sorry flops uh then you have special scrutiny on your models so they went 2x less than that so they really went right below this to not have special scrutiny so 38 uh I might be off by a little bit but it's definitely under the 1 26 oh um so paramet p is parameters n is data number of tokens this is a uh this is just an approximation we yeah okay uh compute and we know that they trained on 16,000 h100s um and we know the throughput but they they said it too uh so if you do the computation it takes around 70 days um or 26 million GPU hours at least that's with my uh back of the envelope computation they actually said that they use 30 million instead of 26 million GPU hours um so maybe they had like some uh some challenges I don't really know but if you follow the simple computation it's around 70 days um cost uh I mean this it's hard to to approximate but I'm just going to say it's kind of the rent like what if I were to rent h100s that many h100s for that many days how much will I pay uh h100 a lower bound on the on the renting uh cost of h100 is around 2 hours uh $2 per hour so if you multiply this by 26 million uh hours uh you get 52 million uh dollars so they probably pay less than that but not actually much less because all these um all these services that actually rent gpus they don't make that much money so it's it's probably slightly less but not that much less um now salary I said 50 employees 500k per year say yeah it's probably the right ballpark 25 million uh so if you put all together around 75 million um dollars for training uh this Slammer model I'm probably off by like 10 million but but that's kind of right uh bpk carbon emitted um a lot of people might ask like also the cost is not the only thing that is important so I did the computation um it's around 4 uh 4,000 um tons of CO2 equivalent that is actually only 2,000 return tickets from JFK to uh London so right now uh carbon emitted is actually not uh I mean it's huge but it's not like um meaningful yeah yet I think in maybe GPT 6 gpt7 once you multiply this by 100 that might become a real issue right now it's still not uh I think um an issue in the grand scheme of things next model the way you should be thinking about these models is that every new generation the number of flops essentially uh multiplies 10x or at least that's what they try uh if they have enough energy and if they can buy enough gpus uh great any question on these back of the envelope math no okay so now we talked about pre-training I wanted to also chat about systems because now we know computer is really important so there's a question of how do you optimize the how do you optimize your computer I will leave that for the end because I'm not sure how much time we will have I think it's important but hopefully I I'll be able to to talk about it later it's slightly different than what we've been talking about right now so I'll move on to post training for now so the task of post training ER the reason why we need to do Post training is as I told you before um it's to make AI assistants so language modeling is not uh really the thing that you want when you have an AI assistant uh for example if you ask to gbd3 which is a purely language Model A pure language model not a um not an aligned one if you ask a question like explain the moon landing to a six-year-old the completion that you would get is something like explain the theory of gravity to a six-year-old because what it learned is that on on on internet if you have one question you usually have maybe another bullet point of other similar questions you don't usually have question and then answer later uh this is not what you want from an AI assistant so how do we uh do this alignment which is this post training and making these models assistance um so the goal of this alignment is to basically get LMS follow the instructions that are given um by users and and maybe some designers kind of desires um so think about moderation you don't want the model like open ey definitely doesn't want the model to say stuff that is very toxic um so here you see on the left hand side uh that when you ask a question it actually provides a a real answer so it's not like uh before the llm and on the right hand side you see that it would if you ask to write a tweet describing how a certain part of the population are evil it will say that it cannot do that um so that's kind of this alignment uh the background here is that uh basically the data that you want for training some of these models um is like we know what we want which is just asking humans this is a question this is the answer that you want uh but the thing is that it's very expensive to collect that data and it's hard to find it online uh in contrast pre-training data is not what you want but there's a lot of it um so what what we will do a the main idea is simply take a pre-train large language model pre-train all of internet and then you just fine tune so you just change a little bit of weights on the type of data that you actually want and hopefully given it you already pre-train it on all of Internet it basically learns or knows how to speak in English and and knows a standard um language syntax uh then you can really find tune in with very little data okay sft so supervis fine tuning is really exactly what I just said which is the idea of fine-tuning the large language model on uh basically the desired answers that are collected from humans um so why is it called supervis fine tuning because you basically want to do language modeling on the real ansers so language modeling is this like next word prediction and and that's the fine-tuning part and then you want to do it on desired answers given by humans so that's why we call it supervis so how do we collect this data well we I just said it you just ask humans uh to to tell you this is the this is a question this is the answer that you uh you would want from some of these models so this is an example um sorry I can't read very well on my computer but uh my kid uh needs to do a science um no let's read this one can you write a short introduction about the relevance of the term monopsony and then it says monopsony refers to a market structure blah blah blah and that's a human that wrote that um so actually this is open Assistant which was a a way to collect um uh data online by humans so this type of supervised fine tuning or alignment is really the key of Chad GPT this is what made uh the big jump from gpt3 which was mostly something that was known by AI researchers to Chad GPT which became known by basically everyone um so the problem with uh human data is that it's uh very slow to collect and very expensive um so one possible simple idea is to use llms to scale data collection uh so that's exactly what we did with alpaca uh one year ago what we did is that we asked uh humans or we use a data set of human uh question answers so there were 175 uh question answers here and we asked the best mod at the time so text3 to basically generate many more of these question and answers so all we did is like this is what humans would write now write similar answers and similar questions and we collected 52,000 LM generated question answers and then what we did is simply we took Lama 7B which was the best pre-train model at the time and we just fine- tuned this with supervised fine tuning as I told you and that's how we got um the Alpac s7b model uh and this is the type of data that we collected so things like what does algorithm mean an algorithm is a step by a stepbystep uh set of instruction used to solve a problem or achieve a goal blah blah blah blah so the data is not actually it's actually pretty good given it was LM generated by LMS from essentially two generations ago um so that really started at least for us kind of as an academic replication of chat GPT uh now it really there's a big field of like synthetic data generation of how to use llms to basically make development of llms faster um and by basically by decreasing the amount of of human hours that you need quantity of data so we talked about what type of data and how we collect it um one thing which is surprising with sft is that you don't need that much data uh so what this paper showed this is called Lima is that if you have if you scale the amount of data that use from uh supervised fine training from 2,000 to 32,000 it really doesn't help much so here scaling laws definitely don't help um so the the intuition here is that all you learn um is is you learn how to format your desired answers another way of saying it is that your pre-trained models they essentially model the distribution of every user on internet one that might write bullet points another one that might answer qu answer question with an answer so all you tell your model is like wait you should actually be optimizing more for this type of user than another one so you're not actually teaching it and you're not teaching anything through this um sft uh so supervis fine tuning all you do is you tell the model to kind of optimize for one type of user that it saw already in a pre-train data set so the knowledge is already in the pre-train llm uh and you basically just specialize to one type of user great any question on sft yes so I know it's a big issue with synthetic data where uh if you keep generating data from the same distribution eventually you're not learning a new distribution you're essentially playing with it it just bootstrapping that yeah surely you can't scale that forever right you can't keep going on and generating from the same distribution you hope to learn something new yeah uh so are there it's an active area of research but any thoughts that you have around how people are maybe thinking around this and uh better ways to bootstrap or to give up on this idea and and realize that the chart shows you don't need that many so just get humans to generate 2,000 really good uh yeah so that's a very good question uh so for the data stuff so I'm saying it's not that important for sft but there will be another thing we'll talk about right after where actually data does matter my intuition based on not that much empirical results is that you can still get um even though you use your LMS if you use purely LM generated text and you do that for like three four generations of llms I agree with you that probably you won't improve much but for me what is important is how do you use like human in the loop with llms not purely LMS not purely uh humans but maybe what you can do is just have the model generate some new text and just uh humans write a few Edits edits are much faster than writing the entire text and I think that if you have that type of collaboration then from like kind of an information theoretical point of view you still get additional information but you still much faster than if you use humans and I think that as a field we'll probably move towards these type of things uh which is um really just finding the examples that are important and and asking humans it's kind of active learning just asking humans exactly when uh you need to to get inputs yes do we train with like the same loss function the same like General training algorithm for the supervis tuning bit as we do for the for the pre-training right because like the examples you showed I think the the important thing of the good examples is they're like supera accurate there's these more complex still just like chain same so that's why here I yeah I didn't maybe didn't emphasize enough this is just language modeling fine tun the LM with language model on the desired answers so this is literally the same loss um it will be different in two seconds but the first step of sft is literally the same loss where you just say Okay I want to actually specialize on that type of data so there's even a question of like what is pre-training what is post-training because in reality it's just like a different data that you use the reason why we usually call it post training is that the way we collect that data is very different great great questions uh yes maybe it's the same question but why would these 2,000 examples have such an overweighted influence you tun so that's why we uh also that's another reason why we call it post training is that we use different type of hyper parameters so you know I told you basically at the end of pre training you essentially end up with a learning rate of zero and here you're going to increase your learning rate so like 1 eus 5 one E Yeah and and so um the weight that you give to them is actually different um okay uh Second Step or second part of this post training um is what we call reinforcement learning from Human feedback or rhf uh some of you might have heard of that um the idea is that sft has a problem namely that uh you do behavioral cloning which means that you just try to clone what the humans would say and that had that has many issues one of them is that you're bound by human abilities so if um like humans actually humans won't generate the things that they think is actually the best thing to generate so if you ask me to write a book I mean I can definitely enjoy a book I can probably say one book is better than another but I'm definitely not going to be as good as writing the book that I want to read uh so you're going to be bound by the human ability to generate things even though the humans might be better at distinguishing between things that's one issue issue number two uh I find that actually pretty interesting is that it might if you ever heard of the word hallucination so this is llms generating F like false information hallucination might these people have um hypothesized that that can come from the supervised fine tuning even if you do supervised fine tuning on data that is correct and the reason why that is is that if uh given I told you that basically sftt is with very little data and it's with data that doesn't the model doesn't learn anything new so what if the human gives an answer that the model didn't know was true from the model perspective you the human basically is telling the the model uh generate this thing that seems plausible but actually have no idea if it's true or not um so just to give you a very concrete example if we go back to this uh monopsony example can you write blah blah blah about monopsony uh imagine that a human uh wrote a reference on this type of book um and that book might exist that might be a correct reference but what if the llm never saw this reference during pre-training then it doesn't know that it's a correct reference so really what you tell the model is to generate or make up some plausibly sounding reference um rather than actually tell the real reference that it saw during pre-training uh so hallucination might be um uh a re like might be caused by this sft that's problem number two does that all make sense great problem number three price generating the ideal answers is very pricey and that comes back to your question um of like humans writing answer is actually pretty expensive um so that's where rhf comes in the idea is that instead of cloning the behaviors of humans we're going to maximize human preference um and the way we're going to do that so the pipeline is that for a certain for every instruction you're going to ask a model to generate two answers um and usually use a pretty good model so you usually don't use an LM here you use a sft uh fine tune you use a fine tuned llm already to give like pretty good answers and then you ask labelers which of these two answers was better so select the preferred one and then with different type of algorithms we're going to talk about the algorithms um you just fine-tune the model to generate more of the green thing than the red thing so more of the good stuff uh so now the question is how and we're going to talk about that right now so there are two ways that we're going to talk about and two that are mainly used in the community um the first one is simply the idea of of using reinforcement learning so hopefully you all know what reinforcement learning is now um so when you think about using reinforcement learning one important question is like what is the reward that we're optimizing uh so in this case there are really two options that I could think about the first one you could just say I'm going to compare the output generated by some baseline the output generated by my model U and I'm just going to ask the human to say which one is better and I'm going to use this as a reward so if I'm better than the Baseline this is a plus one if not it's a minus one one uh so now it's binary reward the problem with binary reward is that it's very sparse and you don't get much information out of it uh like maybe your answer was slightly better maybe it was like way better and you don't really know from this um how much better it was so option two is that you can train what we call a reward model which is simply a classifier uh so you use machine learning to to classify how much better uh two outputs are from the preference from the perspective of the human um so this is a little bit meta but what you basically do is that you train uh you take um a reward model R which is a uh just a large also a large um a large classifier and you basically ask this reward model you give it the input and the actual output that you have one of the two outputs uh and you just um exponentiate that so that's the soft Max law that you all know about and now you divide by um the the exponential reward uh on the first example sorry on the first output and this is on the second output and you basically train so the reason why you do that is that you train your your model you train this reward model to be able to classify um how much better one output is to another one so another uh slightly less convoluted way of saying it is that your reward model will output some reward that will be used as the logits of your soft Max so now if you have high logic in your softmax it means that you highly likely this um output is better uh so that's what we call Bradley ter model yes is this reward model going over the entire output or is it going um so this takes the entire uh yeah this takes the entire output at once so it takes all the input and all the output and it gives one number yes would human be sorry with the reward model where would a human be like oh I see okay sorry maybe I wasn't clear um you train this reward model to fit this green and and red preference from humans so basically you train a classifier to say whether the humans prefer red or green uh but instead of using the binary reward which is what the human would tell you you basically use the logits of the soft Max and the thing with the logits is that that logits are continuous so now you know that if your reward model said it has high logits then in some ways the human highly prefer this answer to some other answer great um so as I just said continuous information so it's better so that's what people uh use in practice or at least used to use in practice I'll tell you about uh the other algorithm later uh so what you do at the end is that you basically try to just use reinforcement learning that you know about now we know we have reward what you sample through is the generation from your large language model um and then you just use some regularization term so the reason why you do this regularization term is for avoiding what we call over optimization so this reward model might not be really represent like might not perfectly model human preferences so you don't want to maximize this thing to essentially Infinity um and you do it using uh po which is a common uh reinforcement learning algorithm um one thing to note here because it will be important for later is that when we use maximum likelihood um sorry now the large language models are actually a policy for your reinforcement learning it's not maximizing maximum likelihood anymore which means that you're not modeling any distribution anymore and the reason why this is important is that models that went through this type of Po actually don't give you likelihoods of text that are meaningful cuz what you optimize them to do is B basically just optimized for generating the most likely thing not optimize for modeling like all the answers that humans might say another way of saying that is that there's nothing that incentivizes here the model to not give a like a um a single possible generation nothing here says it's good if you have some distribution with some entropy um okay if you haven't followed it's not that important but just good to knowe great so PO is exact what chat GPT did originally so here's the on the blog post or what they have is step one do supervise fine training which now you all know about step two train a reward model on human preferences step three do po multiple steps which is where you see this this blue arrow so you continue you train the model once with po you collect new data you continue uh and that's why and that's exactly what Chad GPT did uh that was a big breakthrough between gpt3 and Chad GPT one thing to note is that uh P has many challenges reinforcement learning is something that's super nice theoretically in practice anyone who ever worked with reinforcement learning knows it's such a mess uh there's a lot of things like roll outs out of Loops clipping so many complications um so it's messy this is the idealized PO used for LM settings so that's already much more complicated than this expectation we saw before and in practice it's actually much more complicated so we have one implementation of it that we had to do and I'm not going to go through it but basically you have like so much stuff that you have to think about when you implement that type of of uh po algorithm so you have clipping everywhere you have a lot of complexities and things are not well documented all this to say um that we're going to there was a new method that was proposed uh also from Sanford one year ago called DPO which is essentially a simplification of Po um and the way uh what they did or the idea that they have is that instead of using reinforcement learning you can just maximize the probability of generating the stuff that you like and minimizing the probability of the stuff that you don't like uh so if you think about the human preference the red and green maximize uh green minimize red um so the loss is actually this one uh where what you see this is simply um some log of the model so this is the likelihood of a model generating the things that the human preferred given the the inputs um and what you try to do is basically maximize uh the likelihood of generating the things that you like minimize the likelihood of the things that you don't like um all the rest of the terms here it's not too important it's actually really not that complicated to understand but at a high level it's really just maximizing the things you like minimizing the the rest um and one thing to note uh which I was going to say just here is that actually all the rest is chosen such that um the global Minima of of Po and a global Minima of like this DPO under some assumptions are essentially equivalent so this is the right thing to do mathematically I'm not going to go through the derivations but that's the right thing to do uh it's pretty different with Po in the sense that now and with P what you had to do is collect the human preferences then train a uh reward model with maximum likelihood then use reinforcement learning now all you do is basically maximum likelihood much simpler yes I mean yeah so it seems like this is a much simpler and B like what you just intuitively do if this why did they start with this reward model like what what led them doing that I think it's a great question uh I don't really know what I can tell you is that at open ey the people who did the um uh who did basically this PP uh sorry who did Chad GPT initially are the ones who actually wrote Po and I think they were just like there are a lot of reinforcement learning people and I think that for them it was very intuitive um so there's also some additional like potential benefits for example I don't want to yeah for example if you use the reward model uh the cool thing here with reinforcement learning is that you can use unlabeled data with the reward model so here you can only use the label data for doing DPO um for PP for po you first train your reward model and then you can use unlabeled data uh where the reward model will basically label this unlabeled data so there there's additional kind of potential uh there could be potential improvements in practice it happens at down and on and I think just that a lot of people in this team were reinforcement learning experts including uh the main author of Po John hman um so much simpler in poo and is basically performs as well uh so now this is the standard uh thing that people use at least in the open source Community I believe it's actually the standard also in in Industry so that's called DPO gains um so those are all the papers on the left here this is on a summarization task you see all I want to show you is that basically the pre-train models uh were okay and they improve with scale if you do supervised fine tuning you improve them a little bit more if you do po or something with all HF with human feedback you get performance that are as often times depending on a benchmark even better than uh humans so this is the human uh reference summaries same thing this is on a uh on a paper that we have Alpaca Farm where we see uh the evaluation here is not too important but basically you see pre-train model you jump to sft and then you jump to PPO and popo have the exact same performance so basically all HF helps that's kind of the conclusion and DPO is simple uh data uh the way that you collect that type of data um first idea is just use humans as we already talked about uh guidelines are very complicated for what humans should be labeling and and it's really not that easy and actually if you ever do some of the labeling you will see that it's extremely complicated like if I zoom in to this uh here I have a question tell tell me about self-driving cars and you read both self-driving cars are vehicles that are capable of detecting their surroundings blah blah blah self-driving cars are cars that are equipped with sensors blah blah blah to navigate without the need for a driver I mean both seem okay like which one is better it's actually hard to say at a glance um and as a result uh the problem with humans is that you will start optimizing a lot of like high level features for example the second one is longer I can guarantee you that most humans will choose second one even though I mean maybe the first one is better I don't know I haven't read it carefully so challenges with humans first slow and expensive uh second as I just mentioned it's hard to focus on things that matter like correctness and people uh usually look at things that don't matter as much like the form like length uh and as a result so what I show here is that uh when you do lhf the more you do of lhf the longer the output of the of the models become so if you've ever been annoyed at chat GPT answering you super long sentences this is because of all rhf um annotator distribution shift uh like the distribution of annotators that you use matters a lot and you have to think like what is what is even the humans that we want to represent in these models uh now the question is like crowdsourcing ethics uh like usually these basically a lot of the the labeling that is done um like the people who do them are not paid well and they have to go through a lot of toxic data uh because you basically want the model to avoid saying the toxic data um so crowdsourcing ethics too so many challenges with human data um so what we did also last year is again the same thing as alpaca just the idea of like oh well they're challenges with humans maybe we can just replace them with llms uh so what we did is simply replace um oh I see that I'm just realizing that the slides are not sented anyways uh you replace a human preference with LM preferences uh so here on this uh figure you see on the xaxis the price that we paid uh for collecting human data it's around $300 for 1,000 examples and this is on mechanical turkers which are usually like cheaper than than maybe some of the other um companies that you could go through and on the Y AIS it's basically the agreement with uh other humans with the mode of other humans and what you see is that actually as I told you before labeling is really complicated humans agree with themselves only around 66% of the time on a binary Tas and it's not that the humans are not good here because uh we were five main authors on this paper we tried to label this data ourselves and we only had like say 67 or 68% accuracy even though we talk like we talk for like 3 hours of how we should be doing labeling really it's complicated it's not an easy task um and here I just showed many different models and um basically you see that models are much cheaper and they can actually get higher agreement with the mode of humans than human humans themselves and the reason why is because humans have a lot of varant models have no varant so they might be a little bit more biased but have less virence uh so it works surprisingly well and now it's kind of the standard in open uh Source Community I think even in Industry a lot of people use both humans and llms for improving uh the colle collection of allf data um and this is like this is the paper from last year but honestly now it's more like that llms would be around this agreement and this cost so around I would say 50x cheaper than humans and better agreement with human than humans themselves okay so that gets us to evaluation of post training um that goes back to your initial question at the beginning of the lecture how do you evaluate something like chpt uh the answers that chpt could give are basically unbounded and it's not that there one right answer there are many answers that are just as good um so there are many challenges one you can't use validation loss because one method might use po the other one might use DPO validation loss is not comparable second you can't use Cal uh sorry perplexity that's the thing I told you before these models uh are not calibrated they don't give distributions they they just optimize for one thing so you can't use perplexity for actually evaluating uh these type of models once they're aligned sorry one Z lined third uh there's a large diversity of questions that human might ask to these models generation open QA like some question answering some summarization and all of these things so there's so many things you have to cover um then the tasks are really open-ended so it's very hard to automate so that's what you were alluding to before so the idea uh is that instead of trying to come up with really easily automated uh benchmarks uh it's just we're going to ask questions that that users actually ask to these models in practice and we're just going to ask annotators to say between these two models which one is better like what's the what's the better output so basically do exact same thing as um basically the data from rhf but you use it now for evaluation yes I'm not sure I understand what you mean by like can't use perplexity and not calibrated right like LM is still doing like next token prediction so I can't so think about um the optim solution after doing PO is basically one model that gives you uh essentially a Delta um like basically says that there's only one sentence that is that could be generated for that question so now if you use it on something that is slightly semantically differently different it would actually give a likelihood of zero for that answer so in reality it's not that extreme because as you say it's still a distribution but I just shows you that there's a there's a fundamental issue with perplexity once these models are not llms anymore they were not trained at least with P they were not trained to to do maximum likelihood anymore they were trained to be policies okay um so probably the most common or like the most um yeah the most common Benchmark or the most trusted one is what we call Chad uh sorry chatbot Arena uh which is basically go on internet have random users on the internet blindly talk with two chat Bots just ask many questions see the two answers and rate which one is better and and you do that over hundred of thousands of users and then you get uh the actual preferences and you get rankings of models uh so you can go right now on chatbot Arena and actually interact with these models um one potential issue just to highlight is that while people who want to do these type of things are usually more like Tech driven um or like techsavvy uh so a lot of the questions that you will ask are more like Tech stuff discussing software errors inquiries about AI tools and all these things um so another issue is cost and speed if you really want to use something like this for development process um it will be too costly because you would need to basically pay a lot of humans to do that so one simple idea is again as we said many times just use LM instead of humans uh you probably know the drill at this point uh steps for every instruction generate outputs by some baseline and the model that you want to evaluate um so here you imagine that I I'm comparing an answer from Chad GPT and from I'm just asking a model uh another model uh which one is better and I just basically average that out uh yeah I asked gp4 which one is better I average that out over my entire distribution over my entire Benchmark or data set and that gives me a RN rate so RN probability for one model compared to another one and now you can rank models uh and this is the Alpa eval uh leaderboard so the benefits of this is that actually we show we get 98% correlation with Chad B Arena so very high correlation with humans um so this is yeah comparison with correlation with other benchmarks and it takes less than three minutes and less than $10 to run so it's pretty cheap um there are downsides though uh one of them is purus correlation um so as we already saw before LMS prefer this is one SP correlation not many I'll just talk about one LMS prefer longer outputs actually humans also prefer longer outputs but the problem or the issue once you use llms is that once there bias you will continue optimizing that humans at some point I can guarantee you if I ask a simple question and you give me five pages of answers I'll be like no I don't like that answer but LMS if they have this bius and they were trained for that they will continue preferring longer outputs so uh here we see um the the preference just showing that like humans and models prefer longer outputs um and here is another view of the initial apaka eval data uh Benchmark where when we asked um when we we rank gp4 when we look at the Run rate of gp4 versus actually uh gp4 itself if we com if we use the standard GPT 4 it gets 50% kind of by definition because we're comparing GPT 4 versus gp4 but if we ask a gbd4 to be slightly more verose so we just say in the prompt be Vos in your answers then it gets a r rate of 64.4% so really there's a huge variance and if we ask it to be concise it gets 20% so there's a huge variance depending on um whether you ask it to be concise of that's very annoying um so one possible solution which is what we did is uh just use some regression analysis I'm not going to go into details but basically use Cal inference tools to control for length and right now uh actually length matters much less so if you ask it to be veros we still get some gains but much less great so that's all about post training and now for the next eight minutes I might talk about systems or just answer questions yes can you um go back to your post training in terms of post training how did we tune those parameters using the small body of fine-tuning data and have such big effect on the model you mentioned earlier that there's a different set of hyperparameters are we changing just some of the weights the later weights or all the weights what's actually happening yeah uh yeah I I kind of skimmed through all of this you change all the weights actually um industry would change all the weights in open source land you might have heard of Laura which is going to change basically only some of the weights or it actually to be more specific it's going to add some differences to the output of every of every layer but but in Industry you're going to just fine tune all the weights um and also to say something else about the data actually the SL St all HF you usually going to collect uh a lot more data than with sft so if fft is like 5,000 10,000 maybe 50,000 with rhf I think you're going to be more around like the 1 million uh order of magnitude it's still much less than pre-training though yeah because pre-training is 15 trillion tokens I mean this is like that's not even a drop and yet you influence the weight a lot so because you do it I mean you have to think that how you do it is you use um I mean as I said the learning rate that you're going to use is going to be different but also you only do that so just imagine if I train even if I train on one sentence but over and over again all at some point my model will only that sentence even if uh it was just one sentence instead of the 15 trillion tokens so if you use a large enough learning rate and for enough time you will basically overfit that sentence so the the the key thing to to remember is that um the data is not I it's not as if you mix some posttraining data and some pre-training data you do pre-training and then you just start fine-tuning only on the post trining so another way maybe another perspective is that the post the pre-training is just the initialization of your model and once you view it that way that this is just initialization of Weights then there's nothing special like you don't need to remember that you train a lot of data before the only thing that matters is that you had an initialization and now I actually train a model so maybe think about it that way like there's a there's a mark of property in some way just like you had your weights this is my initialization now I'm training that one does that kind of answer your question kind of but you said something just now about it's almost the equivalence of just rerunning the find tuning data many times is it actually is that what actually happens in order to give so much more preference um you might I actually don't know right now how they do it in Industry when we did alpaca we had to do three box so you did run it three times to it um but I mean even the number of times that you run it through it's actually not important the only thing like the only thing is the is kind of the effective learning rate that what matters um so yeah great so I think I have five minutes [Music] right okay I might try to give a high level Overview at least from one of the systems trick systems as we said uh for everyone Bott neck is a sorry compute is the huge bottleneck uh one question you might ask is why not buy more gpus uh gpus are expensive but also are scarce even if you have $10 million right now you cannot buy the best gpus um there's oh yeah there's also some physical limitations when you have when you have multiple gpus you have to communicate between them that takes time um so just buying more gpus is not that easy um so it's really important to think about how do you allocate resources and how do you optimize your pipeline so system 101 on gpus I'm sorry I'm going slightly faster I hope for that some of you at least can follow uh gpus are basically optimized for throughput CPUs are optimized uh for latency so gpus the way you have to think about it is that there's one Comm there's one command that is run on many many Calles at the same time on different type of data um so this is how you see a GPU you see there are many different CES we call them streaming multiprocessors which is very different than the usual CPU architecture so just think High throughput paralyzation for gpus uh gpus are optimized for fast matrix multiplication so every time you will do uh you will do something on GPU if you can do it with a a matrix multiplication it's going to be 10 times faster than with anything else uh that is a little bit annoying because it means that we're kind of uh bottlenecked to doing anything with Matrix multiplications um another thing to note with gpus is that compute has been improving faster than memory and communication so right now gpus usually are hard to keep uh like the data that you send that send to gpus is actually hard to keep up with the processess so most of your gpus are actually going to be idle if you just run normal code if you don't optimize your code so communication and this will continue over time another thing to know about gpus is that there's a memory hierarchy this is the same thing actually with CPUs but basically the closer you are to your cuse the less memory there is but the faster things run if you're further more memory slower um okay I'm going to skip that okay actually I'm going to say it I told you about this uh the fact of communication uh the metric that people usually look at is model flop utilization so what is the theoretical maximum that GPU could run at no more flops that you could use per second divide sorry the number of OB observed through put divided by this theoretical um maximum and in general if you reach 50% you're very happy like Facebook I looked at Lama was at 45 or something like this so that that means that data doesn't come fast enough even for these big companies so one simple trick and that might be the only one I'm going to tell you about is low Precision one simple idea is that well if I'm going to put my floats in lower Precision then there's going to be fewer bits that I have to send to my gpus if there's fewer bits it's faster communication lower memory consumption things are going to go faster uh and for deep learning it just happens that de decimal is not that important uh so so when you do matrix multiplication when you do like for example SGD there's already so much noise that if you update something by 0.01 or 0.015 who cares uh so basically instead of using uh 32 bits per float which is um what people used to use or 64 for example which is what you would use in other domains you use 16 bits uh for matrix multiplication so for every float you use 16 bits um and for training you have this type of like uh what we call aut atic mix Precision which is that uh some of the things are in 32 bits others are in 60 bit in 16 bits um generally the way you should be thinking about it is that your weights are stored of your model are stored in 32 bits um but just before the computation you put everything in 16 16 bits like this you do computation super fast and at the end you update your weights in 32 Bits And the reason why you do all the updates in 32 bits it's just think that if your learning rate for example is very small you still want to be able to like make a difference in your weights uh so all the computation is done in 16 bits but the weights are actually stored in 32 bits so that's like the standard way that people are doing it um okay I'll actually talk just about this and then I'll skip all the rest operator Fusion because I think this is actually pretty cool as I just said communication is very slow and actually every time you use a pie torch line it basically moves variable to Global memory of your GPU so when you have something like this x do cosine uh equal X1 and then you do X1 do cosine what is happening behind the scenes is that you take the X which is data you ship it to your um to your actual processes of your gpus you apply the coign you ship it back to the main memory of your GPU and then you see the next sign you ship it back to the computer to the GPU processor you apply another cosign and you ship it back again um so another way to see that is that you go from your Dam which is your Global memory in your GPU and you ship it to compute you ship it back for every line This is a naive way of doing it this seems very wasteful um so the idea simple idea of operative Fusion is just communicate do all the computation ship it back once and this is exactly what fuse kernels are um so if you ever want to make your comp your computations in pytorch much faster just apply torch. compile on your model this is going to make your model around two times faster and what it does is simply that it rewrites your code uh your P like your py torch code basically in C++ in Cuda uh to to do the communication only once then do all the operations then uh ship it back okay I'm not going to have time to talk about tiling tiling is important paration paration is important um and mixture of experts mixture of experts is important Outlook there are many things we haven't T talked about we haven't talked about architectures we definitely haven't talked about inference um there are many other things that are important with LMS what is the UI that you use I mean arguably chat jpt the big novelty was just have a simple UI to use it multimodality what are all the misuses you could have uh the fact that there might not be enough data on the internet to train all these models legality of data collection so many other things if you are interested in all these topics uh I would suggest three classes cs224n is probably the one that touches the least on uh LMS uh but it gives some background and historical context um of all the LMS and gives kind of some adjacent material CS 324 I think it's called Uh I think it's just called large language models uh more in-depth reading and lectures on everything I talked about CS 336 which is large language model from scratch you actually build your own llm uh it's an amazing class also given by my two supervisors very heavy workload so be careful and um great"}], "15. Input Markets I\u2014Labor Market": [{"content": "[SQUEAKING]\n[RUSTLING] [CLICKING] JONATHAN GRUBER:\nAll right, let's get started today with our\nlecture on factor markets. So when we talked\nabout producer theory, we talked about input\nprices, that firms had prices for their\nwages and their capital. And we just sort of\nposed those as given. I just sort of gave\nyou values for the wage and the renter rate of capital. But we never really talked about\nwhere those prices come from. Given that they may be\nthe most important prices in our whole economy,\nit's probably worth spending a little time\non talking about where do w and r actually come from. And that's we'll do for\nthe next three lectures, is talk about factor markets,\ntalk about the markets that give us the price\nof labor and capital. We're going to start\nby talking about factor demand, the general demand\nfor labor and capital. And then we'll move on to\ntalk about factor supply, where does supply come from. We'll then develop\nthe equilibrium, and that will tell us where\nwages and the interest rate come from. So that's sort of the\nmap of where we're going, is we're basically\ngoing to develop the markets that give us the\nwage rate and the interest rate. So let's start with factor\ndemand, factor demand. And let's start, and\nwe're going to start with the cleanest case. We're going to assume that\nfactor markets are perfectly competitive. So unless I say\notherwise, we're assuming the market for\nworkers, or the market for machines, or capital,\nis perfectly competitive. OK, we'll come back and bend\nthat a little bit later. So what that means is that\nthere's basically many sellers and buyers, OK? So any worker is\nbasically competing with lots of workers for jobs. Any firm is competing\nwith lots of firms to hire the workers, OK? And we're also going-- we're going to assume a\nperfectly competitive input market, that is lots\nof firms and workers competing to match\nwith each other. We're also going to assume a\nperfectly competitive output market, that is, we're going\nto examine this for the case not of a monopoly firm but of\na perfectly competitive firm. So just think of this, you have\na perfectly competitive firm competing with lots of other\nfirms to hire workers, OK? So let's start by talking\nabout short run labor demand in this context. Let's talk about short\nrun labor demand. Now, in the short\nrun, capital is fixed. So our decision is just, do\nwe add another worker or not, or another hour of labor or not. Like I said, the units\ndon't really matter here, but let's take in\nterms of workers. Do we add another worker or not? Well, as with everything\nelse in this course, we want to consider the marginal\nbenefits and the marginal costs of that decision. The marginal benefit\nof an extra worker is that one extra unit of\nlabor raises productivity by the marginal\nproduct of labor, OK? One more unit of labor\nraises our output by the marginal\nproduct of labor, OK? But that's not the only\npart of the benefit, because we don't actually\ncare as a firm about units of output. We care about revenues. So the benefit of a worker is\nnot just the how many units it produces, but the\nvalue of those units. And what is the value of\nthe next unit produced? It's the marginal revenue. So the value of the\nnext unit of labor is what we call the marginal\nrevenue product, MRP sub L. The marginal\nrevenue product is the marginal product of\nlabor times marginal revenue. That's the benefit of\nanother unit of labor. It's not just what they\nmake, but what it's worth. It's not just what they make,\nbut what it's worth, OK? So that's the marginal benefit. The value of another\nunit of labor is it makes marginal revenue\nproduct amount more stuff, and you sell that at\nthe marginal revenue. That's the marginal benefit. What's the marginal cost\nof another unit of labor? So this is the marginal benefit\nof another unit of labor. What's the marginal cost? Well, the marginal cost\nof labor is just the wage. So we simply set this\nequal to the wage. We set the marginal\nrevenue product of labor equal to the wage, and that\ngives us our optimization condition for the\noptimal amount of labor the firms want to demand-- is to set the marginal\nrevenue product of labor equal to the wage. Marginal benefits of hiring\nanother unit of labor equals the marginal cost of\nhiring of the unit of labor. Now to go further,\nremember, I said this is a perfectly\ncompetitive output market. So what is the marginal revenue\nin a perfectly competitive output market? What's the marginal revenue\nof a firm producing-- yeah. Price. So I can write this\nmore to say that I want to set the marginal product\nof labor times the price equal to the wage, OK? So basically, what\nwe're saying here-- think about it-- is hire workers\nuntil the cost of the next unit of labor is the same as\nwhat that unit will actually produce for you, OK? The next unit of\nlabor costs you w. It produces for you MPL times p. So you want to hire workers\nuntil that condition is met, OK? So think about that, and figure\n15-1 sort of shows this, OK? We have a supply of labor. In 15-1, that's\nhorizontal, because we're assuming competitive\nmarket for workers, OK? We're assuming a\ncompetitive market for workers, that is a\nperfectly competitive market. So if I try to pay workers one\npenny more than other firms, every worker in the world\nwill want to work for me. If I pay workers one penny\nless than other firms, no workers will\nwant to work for me. That's what a perfectly\ncompetitive labor market means, that literally, I am\na price taker in the input market. I don't get to set the wage, OK? I don't get to set the wage. The wage is given to\nme by the labor market. So just like a perfectly\ncompetitive firm doesn't get to set the\nprice of their product-- it's given to them by\nthe competitive market. A perfectly competitive\nfirm in the input market doesn't get to set\nthe wage they pay. It's given them through\nthe kind of process that delivered us our prices\non the output side, OK? So we get a horizontal\nlabor supply curve. And then we have this downward\nsloping labor demand curve. Why is it downward sloping? Someone raise their\nhand and tell me. Why is the labor demand\ncurve downward sloping? Yeah. AUDIENCE: Marginal product\nof labor is diminishing. JONATHAN GRUBER: Exactly. The diminishing marginal\nproduct of labor means you have a\ndownward sloping marginal benefit of labor. Each additional-- remember,\nholding capital fixed is only one shovel. So each additional\nworker add less and less to digging that hole, OK? So marginal product\nis diminishing. Since p is a constant,\nthat doesn't really affect the slope. I mean, it affects the slope. It doesn't really\naffect the sign. Doesn't affect the sign. It's diminishing because the\nmarginal product of labor is diminishing. So the equilibrium is\nwhere they intersect. So the bottom line-- this\nis complicated and new-- the bottom line intuition\nis to think about, as I decide whether to hire\none more hour of work-- you've got a firm. You've got to decide,\ndo I want the worker to work one more hour? You do the tradeoff\nof, what am I going to pay them for an\nhour versus what are they going to get me for an hour. What they're going to get\nme is their marginal product times the price, OK? Now, that-- So in other words, the wage is\nnot just the marginal product. It's imagining if two workers\nwere equally productive. With one more hour of work,\nthey each make three more units. But let's say, in one case, a\nunit is a computer chip, OK? In another case, a\nunit is a potato chip. We clearly would not want to\npay the same wage to someone who produces three more computer\nchips to someone who produces three more potato chips. We'd want to pay a\nlot more to the person to do more computer chips. Why? Not because computers\nare inherently valuable. In fact, potato chips\nare much more delicious than computer chips. Because they sell\nfor a higher price. So therefore, you'd\nwant to pay more to the worker who produces more\nunits of a more valuable good. So let's think about\na sports example, OK?"}, {"content": "And I realize we're all\nabout baseball today, as we should be. Go, Red Sox. But let's focus on\nbasketball for a minute, OK? Now, imagine you're a owner of\na team in the NBA, the National Basketball\nAssociation, and you're trying to decide how much\nyou pay one of your players. So basically, in that\ncase, your goal is to-- your goal is wins. That's the goal. That's the profit you're trying\nto maximize, is your wins. Let's say you're probably\ntrying to maximize your revenues from\nads and stuff, but assume that's\nproportional to wins. OK, assume that\nbasically, the more you win, the more money you make. So let's say the thing you're\ntrying to maximize is wins, OK? So your labor demand,\nthe marginal product you care about, is the\ncontribution of the next player to your win total. That's what you care about. The marginal product of labor is\nhow much does that next player add to my win total, OK? So for example, LeBron James,\nthe best player in basketball, arguably the best\nplayer in history-- we could have that-- we could\nhave the LeBron versus Michael debate some other time, OK? LeBron James makes $31\nmillion, and that's because his marginal\nproduct is enormous. He adds a huge amount\nof wins to any team, OK? We'll see with the-- we'll run the\nexperiment to watch how the Cleveland Cavaliers\ntank this year once LeBron has left, OK? Now, other players\ndon't make as much. Let's compare LeBron\nJames to Nate Robinson. You guys might not\nknow Nate Robinson is. He's one of the shortest players\nin the history of the NBA at a paltry 5'9\", which sounds\npretty tall to you and I, but it's tiny for the NBA. He was a very exciting player. It's kind of fun to\nwatch this little guy run among these giants. But he was just OK. He wasn't a great player. He was a fine player. He made about $2 million a\nyear by the end of his career. So basically, you have\nLeBron making 31 million and Nate Robinson\nmaking two million, and that's sort of related\nto their marginal product. So LeBron adds a lot\nmore to your wins. Now, what happened\nis Nate Robinson quit basketball in\nthe US, and went to play basketball in Israel. In Israel, they love basketball. They have a league. And he went to Israel,\nand he was dominant. He was the best player in\nIsrael, because they don't-- it's not as good as the US, OK? So his marginal\nproduct went way up. Nate Robinson went\nfrom being someone that had a small marginal\nproduct to maybe the highest marginal product in the\nleague, and his wage went down from two million to 500,000. So this is a situation where\nsomeone's marginal product went way up and their wage went down. Why?"}, {"content": "Yeah. AUDIENCE: Because people\naren't paying as much to watch basketball. JONATHAN GRUBER: Right, because\nthe marginal product went up, but the price went way down, OK? And what we care\nabout is the wage equals to marginal\nproduct times the price. So you have a situation where a\nplayer got better but got paid less because they got better. He moved from making computer\nchips to making potato chips, OK? He moved from a\nmarket where he was earning a valuable commodity\nto one where he was earning one that was much less. So basically, it's a\nsituation-- that example shows why you have\nto care about both the quantity of the additional\nworker and the value of what they're producing, OK? Any questions about that?"}, {"content": "Yeah. AUDIENCE: When we talk about\nperfectly competitive input market, are we saying that\nlike all of the workers-- like a single hour of work\nregardless of who you get it from is equal, right? JONATHAN GRUBER: No, no. A single hour of\nwork is paid equally. It's not equal. Marginal product varies. We're talking about the market."}, {"content": "Let's think about a\nperfectly competitive-- I probably went\ntoo fast with this. Let's say a perfectly\ncompetitive output market is where the firms sell\nthe goods into a market where people have\nperfect information and can shop across\nall firms easily. A perfectly competitive\ninput market is where firms hire workers\nin a situation workers have perfect information\nand compare across all firms equally. So basically, the point\nis, think about a perfectly competitive output market. People are in a market where\nlots of people are shopping, and all the options\nare in front of them. A perfectly competitive labor\nmarket where you as a worker have lots of firms\nyou can work for, and they're all clearly\nin front of you, and they all offer a\nwage, and you can see it. AUDIENCE: OK, but\nwe're not saying that the firms have perfect\ninformation across all the laborers, and [INAUDIBLE]. Are we saying if we have the-- JONATHAN GRUBER:\nWhat we're saying is-- we're not saying the\nfirms have perfect information about the laborers. The firms essentially-- let\nme think of the best way describe this. So once again, the firms are--\nfrom the firm's perspective, they do have\nperfect information. No, the wages\naren't-- yes, right, the workers aren't the same. They have different\nmarginal products. The firms know you're better\nthan you or vice versa. But from the firm's\nperspective-- from the workers'\nperspective, is just like, think of the\nworkers as the consumers in a perfect competitive\noutput market. For a perfectly\ncompetitive output market, the consumers can easily\nshop across all the firms they might buy from. In a perfectly\ncompetitive input market, workers can easily\nshop among all firms they might work for, OK? That's a good question."}, {"content": "Other questions? OK, now let's think\nabout the long run. This is the short run. Let's think for a minute\nabout long run labor demand. Think for a second about\nlong run labor demand. Well, what's different? The only thing that's\ndifferent is in the long run, capital can adjust as well. The only thing\ndifferent about the long run-- all the intuition,\neverything's the same. It's just that capital\ncan adjust as well. And what this means\nis that long run labor demand is more elastic than\nshort run labor demand, OK? So we could see this\nin figure 15-2, OK? So the figure shows two\ndifferent short run labor demand curves at two\ndifferent levels of capital. So the short run labor\ndemand when k bar equals 32 is that lower one. The short run labor demand\nwhen k bar equals 108 is the higher one. And what this says\nis, in the short run, you've got these two\nlabor demand curves. In the long run, you\ncould optimize capital. You can pick a point\non either curve, depending on which level\nof capital you choose. And by definition,\nthat allows you be more elastic at choosing your labor. You're more flexible\nbecause you can optimize not just over workers,\nbut over machines as well. It's the same\nintuition we developed before talking about short\nrun and long run costs, that the long run cost\ncurve was a lower envelope than the short run cost curve. Same thing here. This applies that\nthe long run labor demand is more elastic, because\nI basically am more flexible. I not only can choose\na longer curve, I can choose which curve I use. And by definition, that\nmeans that the long run is more elastic, OK? Just a small sort\nof side point there. Now, the last thing I\nwant to talk about here is capital demand. We talked about short run\nand long run labor demand. Let's talk about capital demand. It basically is the same thing. Capital demand is the\nexact same intuition. You want to get machines\nuntil the marginal product of capital, marginal\nproduct of the next machine, times the price you get for your\ngood equals the interest rate. It's the same condition. So we want to hire workers\nso the marginal product of the labor times the price of\nour good equals the wage rate. We want to invest\nin more machines until the margin\nproduct of capital of the next machine times\nthe price for our goods is equal to the interest rate. So it's exact same logic. Here's the marginal cost. The next unit of\ncapital-- remember, we talked about the intuition. You're always renting things. So thinking about\nrenting a machine, the next machine\ncosts are to rent. Do you want to rent it?"}, {"content": "Well, it depends."}, {"content": "What will it produce, and what\ncan you sell that stuff for? So you rent the next machine\nif the marginal product of capital, if the\ngoods it produces, times what you sell\nthose goods for, you want to do that until that\nequals the interest rate, OK? Questions about that?"}, {"content": "Yeah. AUDIENCE: [INAUDIBLE]\nmachine that you buy and own? JONATHAN GRUBER: Yes. We're going to talk about that\na lot starting next lecture."}, {"content": "Right now, I think I'll\njust put this down here. We'll come back to\nit, but I'm going to focus on labor\nfor this lecture, OK? So let's focus on labor, and\nlet's-- so I just put that down, and we'll back to\ncapital, but focus on labor for a minute, and make sure to\nunderstand where labor demand comes from. Now let's talk about where\ndoes labor supply come from. We talked about,\nat the firm level, labor supply is\nperfectly elastic. So go back to figure 15-1. That was a firm level curve, OK? That was a firm level curve. That's a perfectly elastic\nlabor supply to a firm, but that doesn't\nmean labor supply to the market's\nperfectly elastic. So now we want to derive\nmarket labor supply. So I'll call this\nderiving market labor supply, deriving market\nlabor supply, OK? Now, this is basically\nthe question of, how do we model how hard\npeople want to work? This is, once\nagain, getting where the economics is exciting, OK? You sort of knew that economics\nwas involved in how much Ford charged for a car,\nbut you might not have thought so much\nabout that economics was involved in deciding how\nhard you work, but it is. And we're going to use the\nsame tools of consumer choice. Indeed, I used to teach this\nas an application of consumer choice, and now I teach it here,\nbecause it's the same tools of consumer choice. But now, consumers, instead of\nchoosing good A versus good B, are going to choose how hard\nthey're going to work, OK? So basically, like any\nchoice, there's a tradeoff. There's a tradeoff. On the one hand, if you work\nharder, you get more stuff. So you bring home more income. You can buy more\npizzas and cookies, OK? Remember, we talked about\nincome as a fixed thing your parents gave you, but\nin reality, sorry, kids, you're going to have to\nmake your own money someday. In reality, you're going\nto make a Y. It's not going to be given to you. And so if you want to buy\nmore pizza and cookies, you're going to have to\nraise your Y. It's not going to be given, OK? So the reason you\nwant to work harder is to buy more\npizza and cookies. The reason you don't\nwant to work harder is because you're not\nan MIT student, OK? That is, normal people actually\ndon't like work, newsflash."}, {"content": "OK? Normal people\nactually like leisure. There's a thing called\nleisure, it turns out, and normal people like it, OK? So the tradeoff for\nregular people-- so it's a hard\nthing teach at MIT-- is that basically, the\ntradeoff is if you work harder, you get more stuff,\nbut you spend more time doing something you\ndon't want to do. Now, this is weird. When we talked about\ntradeoffs before, we talked about the tradeoff\nbetween goods, pizza and cookies. Now we're talking\nabout the tradeoff between a good and a bad. The good is more stuff to eat. The bad is working harder,\nand we don't really know how to model that. So the trick we're\ngoing to use here is we're going to flip\nthe bad into a good. Instead of modeling labor,\nwe're going to model leisure. So to get labor supply, we're\ngoing to model leisure supply, and then just flip it around\nto get labor supply, OK? So that is, we're going to say,\nyour ultimate labor supply, the amount of hours you\nwork, the amount you work, the amount of hours\nyou work, call them H, is equal to 24 minus leisure. Let's call it leisure, because\nleisure's called little l. Leisure's little l. The amount of hours you work is\n24 minus the hours of leisure you take. What that means is I don't\nhave to model the bad. I can model the good and just\nuse this simple reflection equation to get the bad, OK? So this is the\ntrick in economics. It's a good modeling trick. We don't model bad\nso we don't have to do the tradeoff between\nthe bad and the good. We don't have to do the\ntradeoff between two goods. So turn the bad into a good. Don't model work, model leisure. Don't model your hours\nyou work, model how many hours of leisure, OK? This is a general\nmodeling trick. So what we want to\nask is, now, not how do you derive the\nsupply of labor, how do you derive the\ndemand for leisure? How do we derive how\nmuch leisure people want? Well, once I say it that\nway, you know what to do, which is what I just said. There are two goods,\nconsumption and leisure. I wonder how much of\none good you choose-- of each good you choose. Well, that's a consumer\nchoice problem. You know how to do that, OK? So basically, take\nfigure 15-3, OK? In figure 15-3, now, instead\nof doing pizza versus cookies, now our decision\nis all consumption. So we're thinking about\nconsumption as a bundle, OK, versus leisure. So on the y-axis is\nthe goods you choose. On the x-axis is how much\nleisure you take, OK? It says N but actually it\nshould be little l, OK?"}, {"content": "Should be little l."}, {"content": "So let's call that little l, OK? So basically, as you go\nmore positive on the x-axis, that's more leisure. But because this\nequation, that implies as you go to the left on the\naxis, that's more work, OK? Yeah. H is hours of work. H is hours of work. So as you go to the\nleft, you work more. As you go to the right,\nyou take more leisure. But we're modeling the\ngood, which is leisure. And then we just go\nto our standard-- we go to our standard\nconsumer choice equation. We have a budget\nconstraint and preferences. The indifference curve comes\nfrom your utility function. It comes from your indifference\nbetween how much you consume and how much leisure you take. And the indifference curve comes\nfrom like any consumer choice decision. But instead of choosing\nbetween pizza and cookies, now it's how much stuff you\nwant versus how much leisure you want to take. So it's the same sort\nof indifference curve. The budget constraint comes\nfrom what the market tells you is the cost of leisure. What is the price of leisure? What is the price of leisure? Someone else? Someone else got it? Yeah, AUDIENCE: Your wage. JONATHAN GRUBER: Your wage. Why is that the\nprice of leisure? AUDIENCE: Because\nevery hour you don't work is another hour\nof wage you don't get. JONATHAN GRUBER:\nWhich we call what? AUDIENCE: Opportunity cost. JONATHAN GRUBER:\nOpportunity cost. Remember, prices\nand opportunity cost are the same thing in economics. Here's once again where it gets\ninteresting to apply what we've learned, which is\nthat basically, this is why, once again, they call\neconomics the dismal science. Instead of having\nfun sitting around, we're telling you,\nyou know, by the way, you could be working\nand making a wage. So you're actually spending\nmoney by taking leisure. By taking leisure, you\nare spending money. What are you spending? You're spending the money\nyou could be earning. So the opportunity--\nso leisure has a price, and the price of\nleisure is the wage. It's what you could be\nearning if you were working. So the budget constraint\nhas the slope of minus w. So if you look at the\nbudget constraint, you could take 24\nhours of leisure and have zero consumption, OK? That's the x-axis intercept. Or you take no leisure and have\n24w worth of consumption, OK? So basically, that is\nthe tradeoff you face."}, {"content": "One other modeling\ntrick-- couple of them-- so a couple of\nmodeling tricks here. Modeling trick one is modeling\nthe good, not the bad, OK? Modeling trick two is, I\nwrote on the x-axis goods, but we don't think\nin quantities, we think in dollars. So to make life\neasier, I just said, let's assume the price of\nthe average good is $1. That way you can-- that's called-- that's\njust a normalization, OK, which allows you to think\nin terms of dollars of goods rather than quantity of goods. That's another modeling\ntrick we'll do. We call it making a\nnumerator good, OK? You don't have to\nremember that term, but the point is\na trick we'll do is we want to model\ndollars, not quantities. We just make the\nquantities cost $1, and then we can model\nquantities basically as dollars. So that's the trick we're doing. So the y-axis is dollars,\nbut it's also quantities, because we made the price\nof everything be $1, OK? It's just another trick\nthat makes life easier. OK, so two modeling tricks\nhere, the numerator trick, which is making the price $1\nso quantities become dollars, and the bad is good trick,\nwhich is model the good, and then reverse\nthat to get the bad. Having done that,\nwe know what to do. We get an optimum,\nwhich is the tendency between the indifference curve\nand the budget constraint, and we're done. And so what do you do?"}, {"content": "You choose-- we're going to call\nthis L."}, {"content": "We'll call it little l. You choose little l\nstar hours of leisure, which means you choose 24 minus\nlittle l star hours of work, OK? So basically, you sat down. You made the\ndecision, how much do I want to eat versus how\nmuch do I want to watch TV. You make that tradeoff, and that\ndetermines how hard you work, OK? Now-- yeah. AUDIENCE: Aren't there things\nthat are kind of necessary? Like for example, if\nyou wanted to-- like if your preference was\ncompletely to work, then wouldn't we be like\nan inefficient worker if we didn't sleep? Doesn't-- JONATHAN GRUBER: Well,\nand in some sense, that would be in your\nutility function, or it would be in\nyour utility function and/or your budget constraint. That would be true, absolutely. But that would be a feature. That wouldn't change this\nmaximization problem. It'd just change\ngeneral structure of the equations that go into\nthe maximization problem, OK? So basically, now, what's really\ninteresting about this is now we finally understand why\nwe learned all that shit about income and\nsubstitution effects. Remember, let's think\nof substitution effects. And you're probably saying\nlike, \"Why do I care? Price goes up. Quantity goes down. Why do I care?\" Here's why you care, because now\nit gets really interesting, OK? Because when we're doing\nsubstitution effects for a good, they work together. As long as the good was\nnormal, they work together. When the price went up, you\nsubstituted away from the good and you are poor. So it gets substituted\ndown for two reasons. Now, a normal leisure effect\nis an inferior labor effect. What I mean by that is that\nwhen your wage goes up, you work more through the\nsubstitution effect, but now you're richer. And when you're richer,\nyou buy more of everything, including leisure. So if you take more\nleisure, you do less labor. So the income effect naturally\ngoes against the substitution effect. I'll go through this\na couple of times. Don't worry. The income effect naturally goes\nagainst the substitution effect here. For consumption goods,\nthe income effect naturally work together, OK? We almost never saw sort\nof a Giffen good type phenomenon, where the\neffect could sort of switch the overall effect. For labor, that's\nmuch more likely, and it's much more likely not\nbecause of any inferior good. It's because leisure\nis a normal good, and labor is the\nopposite of leisure. So once again, let\nme say it again. The wage goes up. The substitution effect--\nthink of leisure as a good. When the wage goes up, that's\nthe price of leisure going up. When the price of\na good goes up, the substitution effects\nsays you want less of it, OK? So when the wage goes up,\nthe substitution effect says that leisure\ngoes down, right? Because you want to\nsubstitute-- wait, leisure just got more expensive. You now feel worse sitting\naround watching TV, because you could be out\nthere making more money. Yeah. AUDIENCE: Wouldn't\nincome-- [COUGHS] JONATHAN GRUBER: I haven't\ngot to income effect. Let me finish, then\nyou can ask it. AUDIENCE: Wouldn't\nincome effect be-- JONATHAN GRUBER: I haven't\ngotten to the income effects. Let me ask finish, then\nyou can ask it, OK? So the substitution effect says\nthat leisure goes down, OK? The income effect says\nthat you are richer, right? Your wage went up. You're richer. When you're richer, you want\nmore of all normal goods. Leisure for non-MIT\nstudents is a normal good. So you want more of it. So here, with consumption\ngoods, when they were normal, the income and substitution\neffects work together. With labor and leisure,\nthey work opposite. So what this is, the\nsubstitution effect says take more leisure,\nwhich means work-- take less leisure means work\nharder, work more hours. But the income effect\nsays take more leisure, which means work less hours. So you don't know what\nthe net effect is. So that's why we do income\nand substitution effects, because in a case like this,\nthey get much more interesting. Yes, now your question. AUDIENCE: Is this income effect\nin terms of income over time? JONATHAN GRUBER: No, this is\nyour income, your actual cash income. You are now richer,\nand when you're richer, you spend more on everything. So think of it this way."}, {"content": "Once again, imagine\nyou're not an MIT student. You're a normal guy. OK, if we won the lottery,\nif you guys won the lottery, you would use that\nto do a startup. If a normal person\nwon the lottery, they'd use it to not work, OK? That's the income effect. OK, when normal\npeople win lotteries, they don't go work harder. They don't work, OK? So that's the point. You are now richer\nbecause your wage went up. So you work less,\nand that offsets it. So let's show this in a graph. Let's go back to our income\nand substitution effect graph that we did before,\nfigure 15-4, OK? Now we're back to-- once again, this is just\napplied consumer theory, OK? Let's go back to the income\nand substitution effects. We start with budget\nconstraint one at wage one, and we have our initial tangency\nat A, OK, with leisure of N1 or little l1. Now our wage goes up. Our wage goes up. Therefore, the budget\nconstraint pivots up. Think of what that means. You can still only have\n24 hours of leisure. That's a fixed point. But as you take less\nleisure, you make more money. So the budget trade\nnow pivots up. Well, that has two effects. The first is the\nsubstitution effect."}, {"content": "Remember how we get that. We draw an imaginary\nbudget constraint at the new price ratio. The price ratio is\njust W because I assume the price of goods is 1. The new price ratio, tangent\nto the old indifference curve, that is point B. So\nthe substitution effect says, take less leisure, OK? The price of leisure has gone\nup, so holding utility costs, you want to take less leisure. The income effect,\nhowever, says, you are now richer\nso take more leisure. So the income effect\ngoes the opposite way of the substitution\neffect naturally. You don't need a weird\nthing for that to happen, like with pizza and cookies. It comes naturally. So for normal goods, the income\neffect goes the opposite way. Now, in this case, we end up\nwith leisure still going down. We end up with, the wage\ngoes up, leisure goes down, and therefore labor\nsupply goes up. So we end up with our\nstandard intuition, which is, I tell you, if I'm\ngoing to pay you more, you're going to work\nharder or less hard? The standard intuition\nis I work more hard, OK? But as figure 15-5\nshows, it would not be super odd to get a\nGiffen good effect here, which is, the wage goes up. The substitution effect\nshifts you to the left, but the income effect shifts\nyou even more to the right, and you actually end\nup with more leisure. So once again, my intuition, if\nI say to you the price of pizza went up, what happens to\nyour demand for pizza? You think of a standard--\nyou say, \"Well, I'm going to demand less pizza.\" If I say to you\nthe wage went up, what happened to\nhow hard you work? It's not clear."}, {"content": "Think of a simple example. Think of yourself\nactually back before you were an MIT student,\nwhen you were a kid saving for something. You were saving to buy a\nbike, and the bike was $150. OK, bike was $200, and you're\nearning $10 an hour, OK? So you had to work 20\nhours to get the bike. Now I gave you a\nraise to 15 hours-- to $15 an hour or $20 an hour. Would you work\nharder or less hard? Well, if all you want is the\nbike, you'd work less hard. You don't have to work 20 hours. You only have to work 10 hours. So in fact, a higher wage\ncaused you to work less hard. That's not that\nbizarre a case, right? That makes sense. The point is, it's\nactually quite sensible that you couldn't end up with\nthe labor supply being a Giffen good, with a higher wage\ncausing you to work less. It's not a crazy outcome. Giffen goods and\nconsumer goods are crazy. It's not at all crazy\nto think that in cases like having a target,\na purchase target, a higher wage would cause\npeople to work less. Yeah."}, {"content": "AUDIENCE: So does the law\nof nonsatiation not apply? JONATHAN GRUBER:\nAbsolute applies. Absolutely applies. There's no violation. We haven't violated\nany of the laws. All we've done is just\nsaid income effects-- it didn't apply with\nGiffen goods too. It's all just saying income\neffects dominate substitution effects, which we\nthought was sort of going to be pretty bizarre\nin the consumption good context, but it's not at all bizarre\nin the labor supply context. So this is pretty wild. What this says is\nthat basically, you've got a situation where\neven in the normal world, you can get that\npaying workers more makes them work less, which\nis kind of bizarre, OK? Questions about that, about\nthat intuition, or the math, or the graphs?"}, {"content": "Well, the math we haven't\ndone, but the graphs? We'll do the math on Friday. The graphs or anything?"}, {"content": "OK. Let's then say, well, does\nthat happen in reality? What does the evidence say? Let's go to the evidence."}, {"content": "What does the evidence say? And there may be sort\nof no question more worked on in economics than\nthe elasticity of labor supply or the shape of the\nlabor supply curve. There is thousands of articles\nwritten on this question, OK?"}, {"content": "And what I want to do here\nto make the intuition easy, I want to go back to\nthe literature circa probably 40 years\nago, when it was sort of the initial burst\nof interest in this, in like the 1970s."}, {"content": "In 1970s, there was a\nburst of interest in this. And what the literature did\nwas it looked separately at men and married women,\nbecause most of women were married, and back then we\ndidn't care about single women, OK? OK, it was a dark time, OK? So the literature\nlooked at men and women, and married women,\nand asked what was their elasticity\nof labor supply. Well, let's think for a\nsecond about what we'd expect, and to do that, let's think\nabout the substitution effect and the income effect. Let's start with men, the\nmale substitution effect. Let's go substitution effect. Men versus married women,\nwho has a bigger substitution effect and why? That is, when the wage goes up,\nwho has a bigger substitution response to that and why? Men or married women? Think about the world-- think about the Mad\nMen world or the world, you know, circa 40 years ago. You guys seen\nenough TV and stuff to know how life was\na little bit, OK? So who's going to respond? Who's the bigger-- yeah. AUDIENCE: Are you assuming\nmen were primary providers? JONATHAN GRUBER: Well, they\ncertainly were in the 1970s. AUDIENCE: Oh, OK. In that case, the men. JONATHAN GRUBER: Men have a\nbigger substitution effect? AUDIENCE: Yeah, they'll\nwork more, probably. JONATHAN GRUBER: OK,\nthat's one option, yeah. AUDIENCE: It'll be married\nwomen, because they're only working if they have to. JONATHAN GRUBER: Right. So it's actually married\nwomen, because men were already working 40 hours. They can't-- there's no-- So think about a\nmarried man in 1975. OK, men didn't raise their kids. Men quite frankly didn't\ngive much of a shit about their kids, OK? Men just worked. That's what men did in 1975, OK? They worked, and they\nworked their 40 hours, and then went home. OK, maybe they worked less\nor more than 40 hours, but certainly, the\nnotion of saying, \"Well, the wage went up. Maybe I'll take more\nleisure,\" never really crossed a man's mind in 1975. Because what were\nthey going to do? They have no one\nto play golf with. They didn't want to spend\ntime with their kids. What were they going to do? Whereas women had a real\nsubstitution possibility, OK? This was an era women were\nentering the labor force. There were real\nopportunities for work, but it was also fine\nto hang out at home. You had-- a lot of your friends\nwere hanging out at home. You could take care of kids. There were a lot\nof things to do. So women had a much larger\nsubstitution effect than men, OK? Because men-- remember, what's\nthe substitution effect? It's about the next\nbest alternative. For men, there was no\nnext best alternative. It was just work. Basically, between 9:00\nto 5:00 on a weekday, there was nothing\nelse to do, OK? For women, there was\nother things to do, which is, you can hang out with\nfriends who weren't working, or you could take\ncare of the kids. Yeah."}, {"content": "AUDIENCE: But what about\nlike working overtime? JONATHAN GRUBER: OK, well,\nlet's-- but once again, if I'm a man, you might\nthink that I could then-- but then once again, if I work-- the substitution effect could\nwork that way for overtime. But let's talk about\njust the decision to work at all, in some\nsense, or the decision to work sort of\nyour first 40 hours. Overtime is hard, because then\nyou get paid more, et cetera. OK, now let's go\nto the other side."}, {"content": "Let's go to the income effect. So let's not say this is zero. Let's say it's small, because\nthis is big and this is small. Because you can\nwork a little bit overtime or something\nlike that, and some men did care about the kids. I'm obviously being facetious. So it could be, some men\nwere willing to spend time with their kids, et cetera. OK, now let's go to\nthe income effect. For whom is the\nincome effect going to be bigger, men or women? For whom is the income\neffect going to be bigger? Yeah."}, {"content": "AUDIENCE: Maybe men. JONATHAN GRUBER: Because? AUDIENCE: Because they\nhave a goal of like, they need x amount of\nmoney to just provide for their families. So if they get this\nhuge raise in wage, then they become wealthier,\nand they could start doing more leisure in the week. JONATHAN GRUBER: Exactly. There's actually two\nreasons it's men. One, you're more likely to\nhave your target income. Two is, you can't have an\nincome effect if you don't work. The income effect is\nproportional to how hard you are working. If you weren't\nworking, then there's no income effect, right? Income effect is essentially--\nthe income effect for labor is essentially the\nhours times dH dy. What Manny said\nwas the reason why dH dy might be bigger\nfor men than women, because they have these targets. More relevantly, if\nwomen weren't working, they didn't have\ndH, so this is zero. So the income effect is zero. So for men, this was big, and\nfor women, this was small, OK? Put this together,\nand what does it suggest about the relative\nshapes of labor supply for men and women? Someone raise their\nhand and tell me. What does it suggests\nwhat the labor supply curve would look like for\nmen and women in this era? OK, given the\nintuition we talked about here, what does it\nsuggest the female and male-- the married women labor supply\nand the male labor supply curve should look like? You guys can get this, come on."}, {"content": "Well, let's talk--\nwhat did we talk about?"}, {"content": "We talked about the\nsubstitution effect. If the wage goes up, it leads\nto more leisure, which means it leads to more labor supply. By the income effect,\nif the wage goes up, it leads to less labor supply. So for men, with-- for women, with a big\nsubstitution effect and a small income effect,\nthis suggests a standard steep upward-- standard upward-sloping\nsupply curve. Think of the income\neffect being zero. Then we get the standard\nsubstitution effect. We know the sign of that. So for women, this suggests an\nupward-sloping supply curve, just like a substitution\neffect suggests a downward-sloping demand curve. For men, it's not clear. You could very much get\na Giffen effect here, because basically, there's not\nmuch option for substitution, but they might work a lot\nless if they get rich, OK? So that is sort of this-- what I like with this\nexample-- it's hard, but I like that this\nexample sort of illustrates how substitution and income\neffects can come together to get a bottom line answer. What do we know? What we know is that actually,\nevidence is that female labor supply was very elastic,\nthat circa this era, female labor supply\nwas in the elasticity of between 0.5 and 1. That if you raised women's wage\nby 10%, there was a 5% to 10% increase in their\nlabor supply, which is pretty not elastic-elastic,\nbut reasonably elastic, OK? Whereas for men it\nwas pretty much zero."}, {"content": "It wasn't negative. It wasn't positive. It was basically zero. Basically, men just worked 40\nhours and then went home, OK? So basically, in an era where\nfor women, the labor supply was very elastic and of\nthe standard direction, higher wages lead\nyou to work harder, an upward-sloping supply curve. But for men, it was pretty\nmuch a vertical supply curve, maybe even a\nbit backward bending, maybe even a wrong\nsign supply curve. But pretty much, you could\nthink of it as zero, OK? Now, what do we think has\nhappened in the 40 years since these two numbers? So elasticity of woman\nof between 0.5 and 1, and men of zero,\nwhat do we think has happened to these two\nnumbers in the 40 years since these studies, and why? What do you think has happened\nto these elasticity estimates and why? Yeah."}, {"content": "AUDIENCE: Are we talking\nabout these together? JONATHAN GRUBER: Let's\ntalk about women. What do you think has happened\nto the female estimate? AUDIENCE: Probably\ngotten less elastic. JONATHAN GRUBER: Because? AUDIENCE: More of them are\nworking in a primary role. JONATHAN GRUBER: Right. Well, first of\nall, this is going to come down, because in fact,\nit's now more standard just to work, right? In fact, now, for a woman\ntoday, in many communities, it's like being a\nman in 70s, which is if you don't go\nto work, there's no one to hang out with, OK? So basically, this is\ngoing to get smaller. And they're more of a\nprimary winner in the family. This is going to get bigger. So in fact, female labor\nsupply has fallen more to like about an\nelasticity about 0.2. It's actually fallen over time."}, {"content": "Now, for men, the question is,\ndo you get the opposite effect? Actually, men sort of care\nmore about their kids now, and there's more sort of\nactivities going on during the day, but in fact it hasn't. In fact, male labor supply\nstill is pretty inelastic. What's happened is kids\nare now in childcare. So basically, we've gone from a\nworld where, as wages went up, women went-- men worked. Women either worked or didn't\nwork, depending on the wage, and if they worked, the\nkids went in childcare. Now men work and women work,\nand kids are in childcare. And that's basically the change,\nthe evolution of the labor-- roughly speaking, obviously. Still, female labor\nforce participation is only about 70%, OK? Many women still do stay\nhome and raise their kids, and are in and out of\nthe labor force, OK? But by and large,\nwe moved to a world with just overall less\nelastic labor supply. Yeah. AUDIENCE: Between the average\ntwo-income household is richer now, or-- JONATHAN GRUBER: No. The average-- well,\nOK, we're going to get into this when we talk\nabout income distribution. What this has done is allowed\nthe average two-family household to tread water. So it's, the average\ntwo-family household today has the same income\nas they did in the 1970s. Why? Because workers earn a ton less\nin real terms than they did, and that's facts\nabout inequality we'll come to, that basically,\nthe average family in America, despite having-- going from the wife not\nworking to the wife working is no better off they\nwere 40 years ago. And that has lots implications\nwe'll talk about, OK?"}, {"content": "So any other\nquestions about that? So let me end with one final\nexample, an application, OK? Which is to the problem we have\nin the world of child labor."}, {"content": "It's a huge problem\naround the world, is kids being forced to work. It was a huge problem in the\nUS till the 20th century. It's a huge problem\naround the world, because A, work can often\nbe dangerous and bad for their health, but B,\nthey can't be going to school and having the opportunity\nbetter themselves. If a kid is spending\nall day working, then that kid is\ndestined to a life of working in the\nsame crappy job, because there's no way to\nget the skills that allows them to grow and go further. Now, one-- we will talk in the\nnext few lectures-- in a few lectures about\ninternational trade. And one criticism of\ninternational trade is people say, \"Well, if\nyou allow these developing countries to sell more stuff\nto the developed world, that will-- they'll put\nthe kids to work more.\" So if we have free trade and\nVietnam can suddenly sell a bunch stuff to America, that's\nmore kids they;re going to put to work making that stuff. So one common argument you\nhear against free trade is it's bad for kids, but in\nfact, that argument is not necessarily right, because it\nignores an important point. Manny? AUDIENCE: [INAUDIBLE] JONATHAN GRUBER: No,\nthat's a different issue. The point-- that's right,\nbut the point it ignores is free trade makes\nfamilies richer. And the families\nare richer, they may want to buy more\neducation for their kids. So on the one hand, it's true. Free trade makes kids more\nvaluable in the labor force. On the other hand, it\nmakes family richer and they want more\neducation for their kids. So to look at that two\nDartmouth professors did a study, who\nlooked at Vietnam, and looked at what happened\nwhen Vietnam liberalized trade in rice. So let's go to figure 15-6. Now, we haven't gotten\ninternational trade yet, so I'm just going to sort\nof hand wave through this. You don't need to really\nunderstand this graph, except what the bottom line is. OK, what happened was\nbefore trade liberalization of Vietnam, before\n1989, you could only sell rice made in\nVietnam in Vietnam. So what that meant\nwas the supply of rice was s sub v. The demand\nfor rice was d sub v, and the amount of rice\nsold was q sub v. And kids worked in the rice paddies. When they liberalized\ntrade, suddenly Vietnam could sell to a\nmuch larger market. They could sell to the\nworld market, d sub w. That's a bigger market. So they were able to shift\nup their supply curve and sell more rice. They could sell more\nrice, because now they're selling to the whole\nworld, not just to Vietnam. You don't need to notice this\nin the graph so much intuition. If you give someone\na bigger market, they're going to\nmake more stuff, OK? Yeah. AUDIENCE: But doesn't that\nalso put them in competition in other countries, whereas\nif it was just like-- if each country is just\nselling to themself, then Vietnam would have-- JONATHAN GRUBER: No, they\nliberalized in the sense that they let it send out. I didn't say they let more in. AUDIENCE: Oh. JONATHAN GRUBER: OK,\nbut we'll come back to international trade, OK? So basically, the\npoint is, there was this demand shock that\nallowed them to sell more rice. So what effect does that have\non the market for child labor? Let's go to the highly\ncomplicated last figure and let me walk\nyou through this. Here is the market\nfor child labor, OK? On the x-axis is the\namount of child labor. On the y-axis the\nwage of kids, OK? We start at point one, initial\ndemand and initial supply, wage 1, L1. Now we liberalize\ntrade, and that leads to more demand\nfor child labor, because we want to\nproduce more rice. So that shifts us out\nto D2 and point two. So we have more child labor. That's bad. But what this ignores is\nfamilies are now richer, and with the income effect, they\nwill buy their kids education. They'll pull their kids out of\nworking and put them in school. That's represented as a shift\nto the left of the supply curve. So we move from point\ntwo to point three through the income effect. Families are now richer. And indeed, if the income\neffect is large enough, you could move to point four. You could actually have a\nreduction in child labor. Why? Because the benefits\nof more kids working in terms of producing\nmore rice is exceeded by the value\nof the firms of taking-- of the families of\ntaking the extra money they're making and putting it\ninto education for their kids. And in fact, the studies showed\nthat we did move to a point like point four, OK? We actually found\nthat child labor fell when they\nliberalized trade, that the intuitive\nargument, that gee, if they sell more, more kids are\ngoing to work, it's wrong. That in fact, when you sell\nmore, yes, more kids-- demand for more kids, but\nfamilies are so rich, they put their kids in education\nrather than their fields, OK? And that is a wonderful sort\nof counterintuitive story of how what-- I'll talk about economies\nlike free trade, how free trade can actually have\nan unexpected positive effect. We might think it's negative."}, {"content": "And there's a question."}, {"content": "Come up if you want to talk,\nbut we've got to end now. So thank you for\nsaying a minute extra, and I will see you\nguys on Wednesday."}], "16. Input Markets II\u2014Labor and Capital": [{"content": "[SQUEAKING] [RUSTLING] [CLICKING] JONATHAN GRUBER: All\nright, let's get started. Today, we're going to continue\nour discussion of factor markets. If you recall, last\nMonday, we started talking about the labor market. And we talked about how workers\nmake the decision between work and leisure. And we talked about\nthe implications for setting the wage\nrate in the labor market. What I want to do today is\nreturn to that labor market equilibrium and talk\nabout the important case of the minimum wage. So today, I want to talk about\nthe labor market equilibrium and how it's affected\nby the minimum wage because it's an interesting case\nwhich allows us to introduce some complications as to how we\nthink about the labor market. So let's go back and think\nabout the labor market. So let's go to figure 16-1. The labor market,\nlike any other market, has a price and a quantity. The quantity is the\namount of labor supply. That's on the x-axis. The price is the wage. That's on the y-axis. The supply curve\nthat's upward sloping-- typically we'll assume an\nupward-sloping supply curve. But as we discussed last time,\nthat doesn't have to be true. If income effects dominate\nsubstitution effects, which they very well may,\nyou could actually have a backward-bending or\ndownward-sloping supply curve. So we talked about\nthat last time. Having taught that\ninteresting case, typically, we'll\nassume supply is upward sloping or at least\nnot backwards bending, not downward sloping. But remember, that's\nan assumption. So this upward-sloping\nsupply curve is not necessarily as obvious\nas a downward-sloping demand curve is. Downward-sloping demand\nwill almost always exist unless there's\na weird Giffen good, whereas\nupward-sloping supply is a little more questionable. So we have the equilibrium,\nand we have this equilibrium at L1 workers at a wage W1. So now we know where\nthis comes from. So basically, going\nall the way back to producer theory where\nwe just gave you a W, now we're telling\nwhere the W comes from. We're telling you where the\nwage comes from that you then plug into the firm's\noptimization for them to produce goods. Now, let's imagine that\nwe have a minimum wage. So let's go to figure 16-2. So this is a\nregulation which says that you're not\nallowed to pay workers below some minimum level. And let's say we set that\nminimum wage at the level W2 above the market wage W1. Quick question. What would happen\nif we passed a law and set a minimum wage\nthat was below W1? So there'd be a\nregulation which insists you couldn't pay workers\nbelow W2, but W2 is below W1. What would that do\nto the labor market? Nothing. And here's the key point. Markets in economics\nwill always endeavor to avoid government\nregulations if they can. So if a government regulation\nis not binding, it won't matter. Markets will just avoid it. So the interesting case is\nonly where the minimum wage is binding, as in the figure 16-2. So what happens? Well, if you set a\nminimum wage at W2, workers at that high wage\nwould love to work a lot. That's a high wage. They're high in\nthe supply curve. They would like to\nwork L sub s hours. They would like to\nsupply L sub s amount of labor supply to the market. Firms, however, if forced\nto pay a high wage, W2, are going to\nsay, wait, I'm only going to pay that high wage if\nthe marginal revenue product of labor is sufficiently high. Remember, we talked about the\nmarginal revenue of product last time. It's the marginal product\nof labor times the price. So if you're going\nto raise the wage I'm going to have to pay workers,\nunless that affects the market price, I'm going to need to\nhave a higher marginal product of labor, right? The demand equation\nwas, I said, the wage equal to the marginal product\nof labor times the price. Well, if the price\nhasn't changed with the minimum\nwage going in, I'm going to need a high--\nif the wage is forced up by the minimum wage, I'm\ngoing to need a higher marginal product of labor. How do I get a higher\nmarginal product of labor? By hiring less workers because\nthe marginal product of labor's diminishing. So if you're going to force\nme to pay a higher wage, you're going to force\nme to only hire workers until the point where the\nmarginal product of labor justifies that higher\nwage, which means I'm going to hire fewer workers. So firms demand only L sub d. Well, workers can't get jobs\nfirms don't want to give. So the equilibrium is L sub\nd jobs at a wage W sub 2, OK? What does this do to welfare? We can see before, before the\nminimum wage was in place, the market featured a consumer\nsurplus that-- here, consumers are firms, right? But there was a consumer\nsurplus of A plus B plus C. That is, firms\nwere willing to pay what was on the demand curve. They only had to pay W1. So their surplus\nwas A plus B plus C. Workers were willing to\nwork at a wage that's given by the supply curve S sub 1. They were paid at W sub 1. So they got a\nsurplus of D plus E. So here, the firms get\nthe consumer surplus. The workers get the\nproducer surplus because the workers\nare now the producers. Now let's say you roll\nin a set minimum wage. Well, two things have happened. One thing is you've then\ntransferred some resources to workers. That's the area B. You've taken\nthe area B that firms used to get, and now workers get it. That's the idea. You want to make\nworkers better off. So you transferred to\nworkers the area B. On the other hand, you've\ncreated a deadweight loss of the area C plus\nE. You've created deadweight loss in\nthe area C plus E because now there\nare fewer jobs. There are workers\nwho would happily work at a higher\nwage who are not being allowed to work by\nthe limited demand that comes from the minimum wage. So the bottom line is you end\nup with fewer workers, a higher wage, and ambiguous\nwelfare implications. Clearly, social\nwelfare goes down. Whether worker\nwelfare goes up or not depends a bit on the size of\narea B versus the size of area E. It's not clear if worker\nsurplus goes up or not. It depends on size of B\nversus E. In this diagram, workers are a net better off,\nbut it doesn't have to be true. What's clear is that social\nwelfare has gone down. Because remember,\nas I talked about, the cheat, the shortcut I\ntalked about when we talked about oligopoly, is,\nroughly speaking, welfare is proportional to\nthe quantity in the market. Essentially, the\nfurther you deviate from the perfectly\ncompetitive quantity, the bigger the deadweight loss. So that's what happens if\nyou put in a minimum wage. Questions about that?"}, {"content": "OK? Well, that seems\npretty straightforward, and that's what I\nlearned growing up as a kid in economics class. But then some empirical\neconomists, some very famous empirical economists,\nstarted doing a series of articles that\nactually studied, gee, what happens when the\nminimum wage does change. They did things\nlike, for example, comparing what happened\nwhen New Jersey raised its minimum wage but the state\nof Pennsylvania next door did not, and looked at fast\nfood workers in New Jersey, where the minimum\nwage went up, compared to fast food workers\nin Pennsylvania where the minimum\nwage didn't go up. And what they found was\nthere was no difference in employment, that jobs\ndidn't fall in New Jersey even though the\nminimum wage went up. And a series of\nfollow-on studies continue to find that, actually,\nhigher minimum wages didn't seem to cause jobs to\nfall, which is directly in contradiction\nwith this graph. So what's going on? That led to a big\nquestion and revision of what's going on in these\nmarkets that leads to that. And there's really\nthree possibilities for what's going on. Possibility one is that the\nminimum wage wasn't binding. Maybe New Jersey set a minimum\nwage below the market wage. But actually, empirically,\nthat's not true. We can look at what workers were\npaid before the minimum wage. It was well below where\nthe minimum wage was set for restaurant\nworkers that were studied in that most famous study. So this is not true. The minimum wage was binding. There's a second\npossibility that's absolutely consistent with a\nperfectly competitive market. What's a possible\nanswer for why I could impose a minimum wage in\na perfectly competitive labor market and have\nemployment not go down? Yeah?"}, {"content": "AUDIENCE: Price goes up. JONATHAN GRUBER: The price\nthat the firm charges goes up. But in a perfect\ncompetitive labor market, that still wouldn't happen. You might see some\nprice adjustment, but you'd still\nsee some adjustment in the marginal\nproduct of labor. But what else\nabout this diagram? Yeah. AUDIENCE: The firm's demand for\nlabor is perfectly inelastic. JONATHAN GRUBER: The firm's--\nactually, you're close. It'd be the worker's supply of\nlabor is perfectly inelastic. It's the right idea. If workers are perfectly\ninelastic in their supply of labor, then the\nsame amount of workers will work no matter\nwhat the wage. So basically, you're just\ngoing to essentially end up-- you'd also, in fact--\nthat's a good point-- also get inelastic demand,\nthe same thing. If either supply or\ndemand is inelastic, you'll end up with no\neffect of a minimum wage. So that's another possibility. But in fact, we've\ndone a lot of studies. So you could have\ninelastic supply or demand. But in fact, we've done lots\nof studies of supply and demand in these markets,\nand that's not true. Remember, supply was\nlargely inelastic for men, but it was somewhat\nelastic for women. And these low-income\nmarkets have a good mix of men and\nwomen working in them. Demand has been shown\nto be somewhat elastic. So neither supply nor\ndemand's very elastic, but they're sufficiently elastic\nthat that rules out as zero. So the third possibility and the\none economists have focused on is that we're not in a\ncompetitive labor market. They're focused on a\nnoncompetitive labor market. Just like we discussed\nnoncompetitive markets for goods with a\nmonopoly and oligopoly, you can have noncompetitive\nmarkets for labor. It's the basic same idea. So now let's look at-- so when we thought\nabout-- let's go back, think about perfect\ncompetition, the basics of perfect competition. We thought about\nperfect competition. The basic idea was, remember,\nI talked about laying out a bunch of rugs in a market\nwhere you could literally shop costlessly across\nall the people selling their little fake Eiffel towers,\nlittle statue Eiffel towers. And you could perfectly shop. It was easy to go\nfrom carpet to carpet. There was full information."}, {"content": "The prices were posted. And so basically\nwhat you ended up was perfectly elastic demand\nfacing any given firm. Any given firm, if\nthey tried to charge one cent more for their Eiffel\ntower, no one would buy it. If they charged one cent less,\nthey'd immediately run out. Everyone'd buy it."}, {"content": "Well, when we are\nmodeling labor markets-- and I discussed this last\ntime, but not very well."}, {"content": "So I want to come back to it. When we're modeling\nlabor markets, we're thinking about the same\nfeature of perfect competition. But here, it's not\nconsumers shopping over where to buy their goods. It's workers shopping\nover where to work. It's workers saying, gee, in\na perfectly competitive labor market, the idea is I know\nwhat I could earn at any firm and I can easily\nshop across firms, see where I'm going to work. So if any firm tried to pay me\none cent less than the market wage, I'd never work there. And if they tried to pay me one\ncent more than the market wage, every worker in the world\nwould want to work there. So in a perfectly\ncompetitive labor market, any given firm faces a perfectly\nelastic supply of labor. So we can see that\nin figure 16-4, which we actually showed-- and\nI'll let you skip this since we covered it-- 16-4, which I actually\nshowed in the last lecture. Remember the last lecture. I was focused on this\ndownward-sloping demand curve, but I casually threw in\nthis flat labor supply curve and botched explaining it. Now I'm explaining it,\nhopefully more clearly, which is to any given firm,\nthe labor supply curve is perfectly elastic because\nworkers can perfectly shop across job opportunities. So if that firm tried to pay\nless, they'd get no workers. So they faced a perfectly\nelastic supply of labor. But just like, in\nreality, there's no such thing as a perfectly\ncompetitive product market, in reality, there's\nno such thing as a perfectly\ncompetitive labor market. In fact, we can't shop easily\nacross all possible jobs and know what every\njob could pay. And the fact that we can't means\nthat firms on the labor market side will have market power. Just like we talked about\nmonopolists and oligopolists having market power\nover consumers through barriers to\nentry, firms will have market power over workers\nbecause workers can't perfectly shop across their\njob alternatives. So as a result, firms\nmay be able to get away with paying you less than\nwhat you might earn elsewhere. In a perfectly\ncompetitive labor market, a firm could never\npay you less than what you're worth elsewhere\nbecause you'd just go work somewhere else. But now, if McDonald's wants to\npay you less than you might get at Wendy's, but it's hard to\ngo find out what Wendy's going to pay you-- you have to go\na distance down the road, and you have to ask\nthem, and you're shy and it's embarrassing-- then\nMcDonald's might be able to get away with paying you less than\nyou might earn at Wendy's. So this is very much\nparallel to monopoly. In fact, we call\nthis a monopsony. A monopsony is a\nlabor market where firms have market\npower over workers just like a monopoly is a\ngoods market where firms have market power over consumers. Now, this is not so crazy."}, {"content": "And in fact, it applies\nvery much to me. Think about my situation at MIT. I've been here 25 years. I just got my 25th\nyear rocking chair, although actually it's\nnot a rocking chair because it comes in the box\nwith the rockers off it. And it arrived in my office,\nso it's sort of a short chair. My wife's 5 foot, and\nshe always complains how chairs are too big for her. So she sat, and she's like,\nit's a perfect chair for me. So now I have a nonrocking\nrocking chair in my office that she sits in. But anyway, I've been\nat MIT for 25 years. It's going to be really\nhard for me to move. I like my house. I like my colleagues. I like my friends. Kind of, I like my\nview out the window. It's going to be kind\nof hard for me to move. Moreover, it'd be pretty\nhard for me to figure out what I'd get paid if I moved. I can't go to other\nuniversities and say, hey, what would you\npay me if you hired me? That's be awkward. I can't really ask my\ncolleagues what they make. That's awkward. So at the end of the day,\nMIT has market power over me because I don't\nreally want to move and I can't really\nfigure out what I'd get paid if I did move. And MIT will exploit\nthat market power over me by paying me less than\nI might earn elsewhere. And we know this as a\nfact because in academia, the only way to get a raise is\nto go get an offer from someone else and have them say how\nmuch more they'll pay you, and then you take that to your\nboss and they say, match this. But if you're not\nwilling to do this, as, frankly, MIT knows\nI'm not willing to do, then MIT can\nessentially underpay me. So basically, any\nresponsible profit-maximizing or even nonprofit employer\nwill exploit this market power and they'll pay me less\nthan my market wage. And that means that MIT\nwill earn surplus on me. In a perfectly\ncompetitive labor market, the firm earns no\nsurplus on the worker. They pay the worker their\nmarginal revenue product. So if you go to this figure,\nwhat am I paying the worker? What I'm paying them is\nexactly the marginal revenue product just like, in\na competitive market for the goods, a firm is selling\nat exactly their marginal cost. So just like a firm makes\nno surplus in a perfectly competitive goods market,\na firm hiring workers makes no surplus in a\ncompetitive labor market. But in a monopsony market, the\nfirm makes surplus over me. They pay me less than they'd\nhave to because I don't shop and find a better opportunity. Now, are there questions\nabout how that market works? I'm not going to do all\nthe math and graphs. It's all the same as monopoly,\njust flipping demand and supply curves. It's a pain in the ass."}, {"content": "I'm not going to do it. I just want you guys to\nunderstand the intuition. So please, since I\nwent through this, are there questions about\nthis or how it works?"}, {"content": "OK. Now let's take this\nnoncompetitive labor market and let's throw\nin a minimum wage. Well, as before,\nif the minimum wage is below what the firm\nwas already paying, there's no effect. So let's assume it's a\nbinding minimum wage. Now, let's say the\nbinding minimum wage is above what my true\nmarket wage would be, what my wage would be in the\nperfectly competitive market. So in a perfectly\ncompetitive market, my wage would equal my marginal\nrevenue product of labor, right? That's in a competitive market. In this noncompetitive\nmarket, my wage is below my marginal\nrevenue product of labor. Firms are exploiting me\nbecause I can't effectively shop for a better job. I don't want to or\nit's hard to do so. Now, in this\nnoncompetitive market, if we set a minimum\nwage that's higher than the marginal\nrevenue product of labor, then the analysis is just\nlike it's a competitive firm. Once that marginal\nwage is higher than the marginal\nrevenue product of labor, it's just like a\ncompetitive firm. So it's not that interesting. The interesting case is, what\nif the minimum wage comes in and it's above the wage I make\nbut below the marginal revenue product of labor? So let's say McDonald's,\nsomeone working there yields a marginal revenue\nproduct of labor of $10, but they're only being paid $7. Let's say you roll in\nminimum wage of $9-- so above what they're\nbeing paid now, but below their actual marginal\nrevenue product of labor. Will the firm fire that worker? Why not? Yeah. AUDIENCE: They're still paying\nthem-- they're still making a profit off of that worker. JONATHAN GRUBER: They're\nstill making surplus, which is as long as the\nmarginal product of labor's bigger than the wage,\nthey love that worker. So before-- so let's write\ndown the numbers as an example. So imagine my marginal revenue\nproduct of labor at McDonald's is $10, but my wage is $7. And then you come and you\nset a minimum wage of $9. Well, 10 is still\ngreater than 9. So the firm has no\ndesire to fire me. So all you've done is\njust given me money. And where'd that\nmoney come from? The surplus the firm earned. So all you've done is\nshifted the surplus from-- you've shifted producer\nsurplus to consumer-- I'm sorry, consumer surplus--\nconsumers are the firms-- to producer surplus,\nthe workers. So in a monopsony\nmarket, a minimum wage doesn't cause deadweight loss. It just shifts surplus around. And that's a really\nimportant outcome because that, once again,\nsays the government isn't always bad here. This is just like--\nif you want to think about this graphically, go\nback to exactly the analysis we did of regulating monopolies. Remember we talked about\nregulating monopolies. We talked about, if a regulator\ncomes in and sets a price below the monopoly price but\nabove the competitive price, it reduced the deadweight\nloss of monopoly. It's the same thing. And if you set a minimum\nwage above the market wage but below the marginal\nrevenue product of labor, then you simply transfer\nsurplus to workers without causing deadweight loss. Now, that raised the\nquestion, of course, is the minimum wage\nin between the wage of the marginal\nproduct of labor? Well, we don't know,\nbut let's go back to the studies that\nmotivated this. The very fact that\nthe minimum wage doesn't seem to\ncause unemployment suggests we are\nhitting the sweet spot, suggests we are hitting\nthe sweet spot, that we're basically managing, with the\nminimum wage policy, at least to date, to essentially\njust find a way, without the government\nspending any money, to shift resources from\nbusinesses to workers. So what does this mean? Well, it means that around the\nlevel of current minimum wages, we can raise the minimum\nwage by a small amount pretty costlessly. It doesn't necessarily mean\nthat a $15 minimum wage is OK. So in some sense,\nthe existing-- this is the important thing\nabout empirical economics. You only learn the answer in\nthe range that you study it. So for example,\nthere've been studies that have looked at what happens\nif you have a $10 minimum wage, and those show no unemployment. There haven't been studies\nthat show what happens if you have a $15 minimum wage. Now, Seattle just actually\nput in a $15 minimum wage about two years ago. So we actually can\nrun the experiment. And the early evidence\nis the Seattle $15 minimum wage did lower\nemployment, that the Seattle $15 minimum wage actually went\nabove the marginal revenue product of labor. And once it's above, you're\nback in the competitive case. You're back in the case where\nyou're lowering employment. Yeah? AUDIENCE: How can you increase\ncompetitiveness in the market? JONATHAN GRUBER: Well,\nthat's the other question, is how could you\nincrease-- so you tell me. How could you increase\nthe competitiveness of a labor market? AUDIENCE: You make it easier\nto tell how much money you would get at each place. JONATHAN GRUBER: So Norway\nhas a day every year they call Envy Day,\nwhich was yesterday, I believe, where they literally\ncan go online and look up anybody's income in Norway. They literally make public\nevery single person's tax return in Norway. And you can go online and\nlook at what everybody makes."}, {"content": "That would do it. So you could provide\nmore information. You could make it easier\nto move between jobs. For example, there's a lot\nof restrictions in our labor market, like noncompete\nclauses, which say that if you\nwork for one firm, you can't ever go\nwork for another firm in that industry for x years. That gives some monopsony\npower to firms, et cetera. So we could do things which try\nto loosen the flow of the labor market, and that would\nclose this gap between wage and marginal revenue\nproduct of labor. Now, let's go back to Seattle,\njust to conclude this. This doesn't mean the\nSeattle policy was a bad one. The bottom line is what\nwe learned from Seattle was that basically,\nemployment fell a small amount and a bunch of workers\nmade a bunch more money. So is that good or bad? Well, it depends. If you're one of the\npeople that lost their job, it's really bad. If you're one of the workers who\ngot a raise up to $15 an hour, it's good. How do you weigh them\nagainst each other?"}, {"content": "That's exactly what we'll talk\nabout in a couple lectures. So once we start talking\nabout normative economics, about is a policy good or bad,\nthere's typically trade-offs. And this is a classic example. What we're learning here is, is\nthe minimum wage in the range we are now, right now, the\nfederal minimum wage at $7.25-- the evidence suggests\nit could easily rise without causing that trade-off. The evidence suggest\nwe could increase the federal minimum wage\nby some nontrivial amount, at least up to $9 or\n$10, without causing much of a trade-off. But once you get too\nfar ahead of that, there starts to be a trade-off."}, {"content": "Question about that?"}, {"content": "Yeah. AUDIENCE: Are there any states\nwhere it's actually still that low? JONATHAN GRUBER: Oh, yeah. Many states don't have\ntheir own minimum wage. Massachusetts is at $11,\nbut we're pretty unusual. We're one of the higher ones. A number of states have $7.25\nas the minimum wage, OK? And the evidence seems to be,\nfrom states like Massachusetts and others which are on the\n$10, $11 range, it doesn't seem to lower employment. It seems like we could clearly-- we'd be safe raising that\nfederal minimum wage. We would simply be\ntransferring resources and not causing unemployment. Yeah? AUDIENCE: Is there\nanything about the cost of living in areas where the\nminimum wage is more expensive? Is it possible that if a\nMcDonald's worker makes more money in this\nstate, McDonald's is more expensive in that state? JONATHAN GRUBER: That's\na great question. So what I assumed was I\nassumed firms would just say, oh, you got me. I'm going to throw some\nof my profits at workers. Firms don't have to do that. Firms could say, well, if\nyou make me pay workers more, I'm going to raise my price. Now, if it's a\ncompetitive output market, that shouldn't happen, right? Because in a competitive\noutput market-- well, no. Marginal cost goes up. It's not clear. It's not clear whether\nthat would happen or not, and the evidence is\nthat it's unclear whether higher minimum\nwage causes higher prices or whether it just\ncomes out of profits. We don't know yet, OK? All right, so that's what I\nwant to say about labor markets. Now I want to move on and\ntalk about capital markets. Now, as confusing as our\ndiscussion of labor markets was, that's easy compared\nto capital markets. Capital market's a lot\nharder to understand. And that's because\ncapital itself-- labor's something you\nget your hands around. It's the time you spend at work. Capital is this sort\nof amorphous thing that I've kept\npushing off defining. So I'll define it now. We talk about capital as this\nvague collection of buildings and machines and the other\nstuff that goes into production. And we know where\nlabor comes from. It comes from our work. But where does\ncapital come from? Well, capital is\na harder concept, but there's one unifying thread\nthat all elements of capital have, which is they\nrepresent the diversion of current consumption\ntowards future consumption. Capital is about\ndiverting consuming today towards consuming in the future. In fact, the original concept\nof capital came from farmers. Farmers, every year, when\nthey would pick their grain, they had a choice."}, {"content": "They could eat all\nthe grain, or they could save some to plant\nfor next year's grain. Now, the more they saved, the\nmore they'd have next year, but the less they'd have today. So farmers faced a trade-off-- literally, consumption today\nor consumption next year. That's what we mean by capital. In other words, in\ntoday's market economy, the link is not that direct,\nbut it's the same basic idea-- that firms have a choice,\nfirms and their investors have a choice. They can take what they\nmake and eat it now, or they can invest it in\nhaving more in the future. So basically, when we\nthink about capital, we're not going to think about\ncapital as physical capital. We're really thinking about\ncapital as financial capital. What links all types of capital\nis their financial aspect. What links machines and\nbuildings is all the aspect that, by putting\nmoney into them today, you have less you can\nspend on fun stuff today, but more you'll be\nable to spend tomorrow. And it's this\nfinancial aspect that links all forms of capital. Now, how do firms get\nthe money to invest in machines and buildings\nand stuff like that? They get it through going\nto the capital market. Where do firms get this\nmoney that they invest? They get it through going\nto the capital market, which is basically the pool of\nmoney that firms can draw on to make their investments. So think of it\nliterally as I'm a firm. I want to build a building\nand buy a machine. I literally go over, and\nthere's a big pool of money. And I have to take the money out\nof there to go buy my machine or build my building. And where does the money\nin that pool come from? It comes from household\nsavings decisions. So the capital\nmarket is a market where the demand for capital\ncomes from firm's interest in investing and having\nmore in the future. The supply of capital comes\nfrom people's decisions to save. And essentially,\nthe money firms use to buy stuff is\nborrowed from people. And that's the bottom line\nof how capital markets work. So just as the\nsupply of labor that determines how many\nworkers a firm can hire comes from your decision\nof how hard to work, the supply of capital\nthat determines how many machines a firm can\nbuy comes from your decision of how hard to save. So let's look at figure 16-5,\nequilibrium in capital markets. Let's start with the demand. We already talked, last\nlecture, demand for capital. The demand for capital comes\nfrom the marginal revenue product of capital. It's the marginal product\nof the next machine. So the demand comes from\nthe marginal product of the next machine times\nthe price the firm can get for its output, which\nis the marginal revenue product of capital. So it's the same\nlogic as for labor."}, {"content": "There's nothing\ninteresting there. Same logic as for labor. The supply's what's\nmore interesting here. Where does supply come from? The supply comes from\nhousehold savings, how much money is\naround for firms to actually get to\nget these machines. And how do they get it?"}, {"content": "They borrow. And what do they borrow at? They borrow at the\ninterest rate I. So I represents the\nrate that firms pay households to get their money. So think of this as-- we'll\ntalk about how it really works. But in theory, the idea is\nthink of literally a marketplace in the center of town. Downtown Boston, Haymarket,\nthere's this marketplace. And a firm comes and says,\nI need to borrow money to buy a machine."}, {"content": "And a person's there\nwith their savings and they say, well, I'll\nloan you some money. What interest rate\nyou going to give me? And that's the\nmarket for capital. So where the supply of capital\nmeets the demand of capital yields the interest rate. So basically, what this means is\nas the interest rate's higher, what that means is I have\nto pay people back more to borrow their money. So an interest rate of 10%,\nif I borrow $10 from you, I pay you back\n$1.10 next period. If I borrow $10, I pay you\nback $1.10 next period. If the interest rate's\n20%, if I borrow $10-- if I borrow $1-- I'm sorry. If I borrow $1 from you, I\npay you $1.10 next period. If I have 20% and I borrow $1, I\npay you back $1.20 next period, et cetera, OK? So basically, that\nis essentially how the transaction works. And the key point\nhere is the reason the supply curve is\nupward sloping is the more you're willing\nto pay me for my money, the more I'm\nwilling to lend you. So if you come to me\nand say give me $1 and next year I'll give you\nback $1, I'm like, I don't know."}, {"content": "Why would I do that? If you say, give me $1 and next\nyear I'll give you back $1.10, you're like, OK, now\nI'm interested. $1.20, I'm very interested. $1.50, for sure. Literally, I just\ngive you my money and, next year, I\nget back 50% more?"}, {"content": "Why not? So basically, the higher\nthe interest rate, the more I'm willing\nto loan the firm and, therefore, you get an\nupward-sloping supply curve. Now, of course,\nin reality, people don't actually-- we don't sit\nin Haymarket, downtown Boston, and give money to firms. In reality, this\ntransaction happens through capital markets. And essentially, there are three\nmechanisms by which implicitly I loan money to firms. The first is I could\nliterally buy corporate debt. I could literally loan\nthe money to firms. I could literally go\nand the firm could say, I, General Motors,\nam issuing a bond. This is through\nbond, issuing a bond. And the way that bond works is\nI promise that for every dollar you spend buying my bond,\nyou'll get 1 plus I dollars back at the end-- or next year, say, depends\non how long the bond is. So literally, you're loaning the\nmoney to the firm by buying-- you're buying their\npromise to pay you back. Now, a second way you can\nloan money to the firm is through investing\nin their equity. You can buy their stock. The way this works is GM says\nto you, buy a piece of me and you'll get paid back not\nsome fixed interest rate, but you get paid back\naccording to how well GM does. So with corporate\ndebt, I get paid back something that's predetermined. When I buy stock or\nequity, I don't get back a predetermined amount. I get back some-- it depends\non how well the company does. But it's the same basic idea. I'm giving the company\nsome money today in return for my getting\nmore money, I hope, tomorrow. That's the diversion\nof consumption from today to tomorrow. And the third thing I could do\nis I could put it in the bank. Now, how is that\nloaned to companies? Because the bank then\nloans it to companies. Why do banks say they'll pay\nyou interest on your money? Why did banks going crazy-- I'll give you 1-- it used to be interesting. Now it's 1%, 2%. When I was a kid, I\nwas like 10%, 12%. We'll give you lots of money. And we'll talk later about\nwhy it was so much higher when I was a kid. Why are banks so\neager to do that? It's not out of the\ngoodness of their heart. It's because when you give\nthem dollars, they turn around and loan them. They add a bunch to\nthe interest rate and loan them out to firms. So those dollars\nyou're giving the banks and they're paying\nyou 2% interest, they loan to firms at 6%. And that's why bankers are rich. So basically, the reason a bank\nexists is because it's a way-- corporate debt\nand equity markets are hard and complicated. It's much easier to put\nyour money in a bank. You put your money in a bank. But when you put\nyour money in a bank, you're essentially\nloaning it to companies. That's essentially\nwhat you're doing. So through these mechanisms,\nwe have a capital market where essentially, by my\nputting money away and diverting from today's consumption,\nI'm loaning to a firm. They'll produce\nmore, and they'll pay me back more in the future."}, {"content": "Questions about that? OK, so let's talk about where\nthe supply curve comes from. We know where the\ndemand curve comes from. It just simply comes\nfrom the marginal revenue product of capital. Where does supply\ncurve comes from? The supply curve comes from what\nwe call intertemporal choice. As I said, economists like\nputting fancy names on things. That helps us get\npaid more money. It just means choosing over\ntime, intertemporal choice. Intertemporal choice\nis essentially about how do you decide\nhow much to save. What's going to\ndetermine that is going to be your\ndecision of how much you value money today versus\nvaluing money tomorrow. So for ease, let's imagine\nI'm considering two periods, this year versus next year. When I talk about periods, I'm\ntalking about days and years and whatever. It's the basic logic. It's about now\nversus the future. Whether I say days or\nyears, it doesn't really matter right now. The point is I'm just talking\nabout today versus the future. So let's talk about this\nyear versus next year. And let's imagine prices\naren't going to change. I'll come back to\nprices next lecture. But let's imagine the price of\ngoods aren't going to go up. There's no inflation\nin this economy, which is roughly true today. And let's suppose I'm\ngoing to take next year off to care for my children."}, {"content": "Lord knows why I'd want to\ndo that when the youngest one's 19, but imagine\nthey still need my care. So let's say I'll take next--\nthis example gets dated. Let's say I take next year\noff to care for my children. And let's say my income\nis $80,000 a year. Now, here is my-- but I'm going to take\nnext year off unpaid. So I'm going to work\nthis year for 80k. Next year I'm going\nto take off unpaid. So I have a couple of choices. I could work this year,\nearn my 80k, spend my 80k, and have nothing\nnext year to live on. I could work this\nyear and eat nothing and save all of\nthe 80k to live on, or some combination in between. And we could illustrate--\nbut the key difference is every dollar\nthat I don't consume this year that I save to consume\nnext year earns interest. And that's where\nthe trade-off comes."}, {"content": "So let's look at figure 16-6. This is a familiar-looking\noptimization diagram. Now my optimization is not\nover pizza versus cookies, but my optimization is over\nconsumption this period versus consumption next period. It's a bit mind-blowing. We're a little\nscience-fictiony here, right? We're now not talking about\nchoosing between two goods, like leisure and consumption\nor cookies and pizza. Now I'm talking about two time\nperiods, consumption today versus consumption tomorrow. But that's the key\nthing about the tools we learn with consumer choice. Those tools are\nincredibly powerful."}, {"content": "You just need to shove your\nproblem into that framework. And we're going to shove our\nproblem into this framework. The problem we're facing is how\ndo I decide how much to save. Well, savings is a bad\njust like labor's a bad. What do we do when we\nhave a bad to model? We don't model the bad. We model the complementary good. So our choice is, how\nmuch do I consume today? My choice is, how much\ndo I consume today and how much am I going to save? Well, saving is a bad, but the\nother way to think about it is, how much am I\ngoing to consume today versus how much am I\ngoing to consume tomorrow? Then that's two goods and I can\nmodel them against each other. And that's what I\ndo in figure 16-6. I model consumption today\nversus consumption next year. So here's my choices. As I said, if I consume\neverything today, I'm at the\nx-intercept at 80,000. I have 80,000 to consume\ntoday, nothing next year. If I consume everything\nnext year, what do I get? Well, let's say the\ninterest rate is 10%. What that means is then\nI'll have $88,000 next year. Why will I have more next year? Because by saving,\nI earn interest. By diverting my consumption to\nthe future, I earn interest. At 10%, that means I would\nhave $88,000 next year. So my budget constraint is the\nline with the slope minus 1 plus I. My budget constraint is\nthe line with the slope minus 1 plus I. In other words,\nthe price of consumption today in terms of consumption\ntomorrow is minus 1 plus I. OK, let me think about it."}, {"content": "Let me say that again."}, {"content": "It's really confusing. The price of consuming today\ninstead of consuming tomorrow, assuming no inflation--\nso prices are the same in the market-- is minus 1 plus I. Think about that. I find it useful to think back\nto the labor case for parallel. In the labor case, what did we\nsay was the price of leisure? What was the price of leisure? Someone raise their\nhand and tell me. In the labor-- yeah? AUDIENCE: The wages. JONATHAN GRUBER: The wages. Why? AUDIENCE: Just because that's\nthe opportunity cost of not-- JONATHAN GRUBER: Right. So by that same\nlogic, can tell me why is the price of\nconsuming today 1 plus I? AUDIENCE: Because if\nyou choose to save, then we're effectively richer. JONATHAN GRUBER: Exactly. The opportunity\ncost-- remember, we are an annoying discipline\nwith a dismal science. We're telling you, hey, enjoy\nthat cookie, but by the way, if you weren't eating that\ncookie, you could have 1 plus I cookies tomorrow. So just like we nag you for\nsitting around watching TV, we nag you for eating\ntoday by saying, hey, the more you consume today,\nthe less you can have tomorrow. And in fact, that trade-off\nis that for every cookie you consume today, you forgo\n1 plus I cookies tomorrow. So that's the budget constraint. The slope is the opportunity\ncost of consuming today in terms of\ntomorrow's consumption or next year's\nconsumption, which is 1 plus I. That's the slope\nof the budget constraint, is the opportunity cost. And then, then we say, OK, well,\nthat's the opportunity cost. That's the budget constraint. Well, how do I decide? Well, then we know how to\nmake these decisions, which is go to utility function. You can write down the\nutility function, which is a function of C1 and C2. Now, what is C? C is all my pizza and cookies,\nbut we're aggregating it up. Just like our utility\nfunction last time was a function of\nleisure and consumption-- we said consumption was\nthe bundle of goods you eat and leisure is this thing. Now we're saying, OK,\nour utility function now is a function of this trade-off. Now, you might\nsay, wait a second. How can both those\nbe utility functions? And the answer is you have\nsome meta-utility function that includes consumption today,\ntomorrow, leisure, pizza, cookies, et cetera. But we can think about\nthis in sequential steps. First, we decide how we're\ngoing to split our income. Then we can decide what to\nspend it on each period. Then you can do a separate\nconsumer maximization decision. But our first\nquestion is simply how am I going to split my income. Well, that's going\nto be a function of my taste for consumption in\nthis period versus next period and the price the bank will\npay me for delaying consumption till next period. Now, what happens? Questions about that? Now, what happens\nin the scenario when the interest rate goes up? What do you think happens if\nthe interest rate goes up? Yeah?"}, {"content": "AUDIENCE: There's [INAUDIBLE]. JONATHAN GRUBER: Right. So what do you\nthink you should-- what do you think will happen\nto your consumption pattern? Yeah? AUDIENCE: You should\nspend less today. JONATHAN GRUBER:\nSpend less today and save more because\nit's rewarded. And why is that not\nnecessarily true?"}, {"content": "Yeah? AUDIENCE: Because you might only\nneed a certain amount of money to live. So you don't have to\nsave as much today because you'll make-- JONATHAN GRUBER: Because\nof what two effects? Income and substitution effects. You gave exactly the intuition\nthat the substitution effect gives you. The substitution effect\nis exactly right. If the interest\nrate goes up, that's like the price of\nconsumption today going up. And if the price of\nsomething goes up, the substitution effect\nsays you do less of it. But if interest rate\ngoes up, you're richer. And if you're rich, you\ndo more of everything, including consuming today. The income effect\ngoes the other way. It's like labor. Once again, income and\nsubstitution effects is why we bothered\ntelling you so. Because income and substitution\neffects, in these cases, go against each other. Let's look at figure 16-7, OK?"}, {"content": "In figure 16-7, we\nstart at point A. Now imagine the interest\nrate doubles to 20%. Now imagine the\ninterest rate doubles. As you said, that pivots the\nbudget constraint upwards. You could still consume\nonly $80,000 this year, but now for every dollar you\nsave, you get $1.20 next year. That has two effects\non your decision. The substitution effect, we get\nby drawing an imaginary budget constraint-- that's\nthe dash line-- tangent to the original\nindifference curve but at the new slope. By definition, that means\nyou consume less today. You consume less\ntoday by definition. If the price of\nsomething goes up, the substitution effect\nalways says you do less of it. You consume less today,\nwhich means you'll save more. Remember, savings is just\nincome minus consumption in period one. So just as labor was\n24 minus leisure-- and so if we just solve for\nleisure, we could get labor. Savings is just income minus\nconsumption in period one. So if we solve for consumption\nin period one, we get savings. People see that? So basically, the point here\nis the substitution effect says, well, gee, the price\nof consumption in period one just went up. It's more costly in terms\nof future consumption. I'm going to do less, but then\nmy savings is going to go up. Substitution effect\nsays you save more. But the income effect\nsays, wait a second. You're now richer. Every dollar of your\nsavings you are doing now yields twice as\nmuch in interest. If you're richer, you'll consume\nmore of everything, including period one consumption. So the income effect takes\nyou back the other way. Now, whether the income\neffect dominates are not, we don't know. In this case, it\ndoesn't dominate. In this case, you\nstill, on net, end up consuming less in period\none and saving more. But we don't know what's\ngoing to dominate."}, {"content": "And in fact, the evidence\nhere is incredibly weak. I won't spend a long\ntime on the evidence because it's not nearly as\ninteresting and strong as labor supply. The evidence is incredibly\nweak even about the sign. And let's come to the intuition\nthat was given for why. Well, think about how people\nmake savings decisions. Lots of people\nhave savings goals. I want to have x by\nthe time I retire. Typical way if you ask\npeople about their savings-- if you ask them,\nthey typically say I want to make sure I\nhave x in the bank in case I'm in an accident. I want to make sure I have\ny by the time I retire. Well, in those models, if\nthe interest rate goes up, savings rates go down. Because after all, to hit a\ntarget with a higher interest rate, I can save less. So it's actually\nnot that surprising that you'd have\na higher interest rate leading to less savings. It's kind of\nintuitive, actually. If people have savings\ntargets, a higher interest rate would lead to less savings\nbecause they can get to their target more easily. So actually, we don't even\nknow which way this goes. It's, I think, one of the\ngreat unsolved mysteries in economics empirically,\nis, once again, we typically assume-- and with a gun to\nmy head, I would say it's probably true that\nhigher interest rates leads to more savings. But the evidence on which\nthat rests is pretty weak."}, {"content": "And the key point for you is\nto understand it's uncertain and it depends on whether\nincome and substitution effects dominate. Questions about that?"}, {"content": "OK. So now let's step back\nand put it all together and think about you making\nyour decision about life. You can think about\nyour decisions about your life in three steps. Step one is you decide\nhow hard to work. Step one is you decide, how\nmuch money do I want to make? Well, that's about\nmaximizing utility over consumption and leisure. Step two is, having decided\nhow much you're going to make-- and that yields your labor. Step two is, deciding how\nmuch you're going to make, you decide, well, how do I\nwant to spread that over time? How much do I want to consume\ntoday versus tomorrow? Well, that's about\nintertemporal choice. That's about deciding\non C1 versus C2, and that's going to\nyield your savings. Step three is, now that\nI know how much I'm going to consume\neach period, now I want to maximize utility\nacross all my goods I might want to\nconsume-- x2, across all the goods I want to consume. That was our original\ncookies and pizza example. So you could think of\nit as a hierarchical set of consumer\noptimization problems that you're going to solve. Now, you might say,\nwell, gee, Jon, that's sort of confusing\nbecause, in fact, the interest rate and how much am I\nsaving could determine how hard I work, right? Let's say the interest\nrate goes way up and I have a savings target. I have to work less hard\nto hit that savings target. And I'd say to\nyou, good for you."}, {"content": "Take more advanced economics. More advanced\neconomics, we recognize this is one integrated whole\nand we allow these systems to affect each other. But for here, just think of\nthem as separatable steps, independent steps. But in practice,\nI hope you can see the steps will be integrated\nand they'll affect each other. Think of it. If the price of a good\nyou really want to buy goes up a lot, not only will\nyou buy less of that good; you might save more to\nbuy it and work harder. So you can imagine how\nthese things are integrated."}, {"content": "But for now, we'll keep\nthem separable, OK? Questions about that?"}, {"content": "OK. Next time, we're to\ncome back and talk about all the interesting\nstuff in capital markets and how we make decisions\nabout how much to save and things like that."}], "Overview Artificial Intelligence Course | Stanford CS221: Learn AI (Autumn 2019)": [{"content": "All right. Let's get started. Please try to have a seat if you can find a seat and let's, uh, get the show on the road. So welcome everyone to CS221, this is Artificial Intelligence. Uh, and if you're new to Stanford, welcome to Stanford. Um, so first let's do some introductions. So I'm Percy, I'm gonna be one of your instructors. I'm teaching this class with Dorsa over there. So if Dorsa wants to say hi, stand up. Hi guys, I'm Dorsa. Um, I'll be co-teaching [NOISE] this class with Percy. I'm a professor in robotics and robotic interactions. Super excited about teaching this class and [inaudible]. Great. So we're going to be trading off throughout the quarter. And we also have a wonderful teaching team. So these are your CAs. So if all the CAs could stand up and I'll give you each person an opportunity to say three words about what you're interested in. So um, let's start with [inaudible] because you're the head CA. Hello. My name is [inaudible]. I'm a PhD student, and I'm interested in natural language processing. Yay."}, {"content": "[LAUGHTER] Hi. My name is [inaudible]. I'm a second year masters student. I'm interested in, um, machine learning and data mining. Hi. I'm [inaudible]. I'm a second year masters student and I'm interested in machine learning and natural language processing. Hi everyone, my name is [inaudible]. masters student and I'm interested in computer vision. [BACKGROUND] [NOISE] Let's go over there. [BACKGROUND] [NOISE] Great. Now, any new TAs in the back? No. Well, um, well, they're all on the slide. Okay. So uh, as you can see, we kind of have a very diverse team and so when you're thinking about kind of final projects later in the quarter, you can tap into this incredible resource. Um, so three quick announcements. Um, so there's going to be a section every week which will cover both kind of review topics and also advanced, uh, uh, topics. So this Thursday there's gonna be an overview. Um, if you're kinda rusty on Python or rusty on probability, come to this and we'll get you up to speed. Um, homework, the first homework is out, it's posted on the website. It's due next Tuesday at 11:00 PM. So remember the time, that matters."}, {"content": "Um, all submissions will be done on Gradescope. There's gonna be a Gradescope coast- code that will be posted on, uh, Piazza. So look out for that, um, later."}, {"content": "Okay."}, {"content": "So now let's, let's begin. So when I first started teaching this class, uh, seven years ago, I used to have to motivate why AI was important and why if you study it you'll have a lot of impact in the world. But I feel like I don't really need to do this. Now it's kind of inescapable that you pick up the news in the morning and you hear something about, you know, AI. And indeed we've seen a lot of success stories, right? AIs that can play Jeopardy or play Go, Dota 2, pro- even poker, all these kind of games at super human level performance. It can also, you know, read documents and answer questions, do speech recognition, uh, face recognition, um, even kind of medical imaging. And all these tasks are, uh, you read about how successful these, uh, technologies have been. Um, and then if you take a look at outside the kind of the technical circles, there's a lot of people, um, in policy, um, and trying to ask what is going on with AI. And you, you hear about, uh, these kind of very, uh, broad claims of how transformative AI will be, um, to the future of work and, um, to society and so on, and even some kind of bordering on, uh, pretty castro- you know, catastrophic consequences. So what's gonna happen in the future, no one knows, but it is fair to say that AI will be transformative. Um, but how do we get here? And to do that, I wanna take a step back to the summer of 1956. So the place was Dartmouth College, John McCarthy, who was then at MIT, and then, uh, after that he founded the Stanford AI Lab, um, organized a workshop at Dartmouth College with, um, some of the best and brightest minds of the time; Marvin Minsky, Claude Shannon, and so on. And they had this not so modest goal of trying to think that every aspect of learning or any feature of intelligence could be precisely captured so that a machine can be just, uh, simulated. So they were after the, the big question of how do you kind of solve, um, AI. So now they didn't make that much, uh, progress over the, the summer, but a lot of programs and interesting artifacts came about from that time. Um, there were programs that could play checkers or prove, uh, theorems, and sometimes even better than what, um, you know, the human proof will look like. Um, and there was a lot of optimism. People were really, really excited, and you can see these quotes by all these excited people who proclaimed that AI would be solved in a matter of years. But we know that didn't really happen and there's this kind of folklore example, um, people are trying to do machine translation. So you take an English sentence like 'The spirit is willing but the flesh is weak', you translate into Russian, which is what, um, the choice language by the US government was at that time, and you could, uh, translate back into English; and this is what you get, 'The vodka is good but the meat is rotten'. Um, so the government didn't think that was too funny, so they cut off the funding [LAUGHTER] and, um, it became the first AI winter. Um, so, so there was a period where, you know, AI research was not very active and was not well- very well funded. Um, so what went wrong here? Um, these were really smart people, right? Um, they just got a little maybe ahead of themselves. So two problems; one is that the compute was simply not there, right? It was millions or even billions of order of magnitude compared less than what we have, uh, right now. And also, the problems, the way they formulate them, intrinsically relied on camp- exponential search which, um, no matter how much compute you have, you're never going to, you know, um, win that race. Um, they also have limited, you know, information, and this is maybe a kind of a more subtle point that if I gave you infinite compute and I asked you to translate, I don't think you would be able to figure it out because it's not a computation problem. You just need to learn the language and you need to experience all the subtleties of language to be able to, you know, translate [NOISE]. But on the other hand, AI wasn't solved, but a lot of interesting, um, contributions to computer science came out of it. Lisp was- is- uh, had a lot of ideas that underlay ma- many of the high level programming languages we have, garbage collection, um, time-sharing, allowing, uh, multiple people to use the same- one computer at the same time, which is something that, uh, we kind of take for granted. And also this paradigm of separating what you want to compute, which is modeling, and how you do it, which is inference, which we'll get to a little bit later. Okay. So um, people forget quickly and, um, in the '70s and '80s, there was a renewed generation of people getting excited about AI again. Um, and this time it was all about knowledge, right? Knowledge is power and, um, there were a lot of expert systems which were created. And the idea is that if you could encode expert's knowledge about the world, then you could do kind of amazing things, and at the time the knowledge was encoded in generally a set of rules. Um, and there were a lot of programs that was written, and you'll notice that the, the scope is much narrower now. The goal isn't to solve it- all of AI, but to really focus on some choice and problems like diagnosing the diseases or converting customer's order parts into parts, and, uh- customer orders into parts and, uh, this was the first time that AI, I think, really had a real impact on industries. So uh, people were actually able to make useful, you know, products out of this. And knowledge did actually play a key ingredient in curbing this, you know, exponential growth that people were worried about. But of course, um, it didn't last long. Um, knowledge as deterministic rules was simply not rich enough to capture all the kind of nuances of the world. It required a lot of manual effort to maintain and, um, again, um, a pattern of over-promising and under-delivering that seems to plague, um, AI people, led to the collapse of the field and the kind of a second AI winter. Um, okay, so that's not the end of the story either."}, {"content": "But actually it's not kind of really the beginning either. Um, so I'm going to step back further in time to 1943. So what happened in 1943? So there was, um, a neuroscientist, McCulloch; and logician, Pitts, who were wondering and marveling at how the human brain is able to do all of these kind of complicated things. And they wanted to kind of formulate a theory about how this could all happen. So they developed a theory of, um, artificial neural networks, um, and this is kind of you can think about the root as of, you know, deep learning in some sense. Um, and what's interesting is that they looked at, um, neurons and logic, which are two things that you might not kind of necessarily associate with each other, and showed how they were kind of connected mathematically. And a lot of that early work in this era were of- around artificial neural networks, was about studying them kinda from a mathematical perspective. Um, because at that time, the compute wasn't there, you couldn't really run any kind of training new models or um. And then 1969, something interesting happened. So there's this book by Minsky and Papert called Perceptrons. And this book did a lot of mathematical analysis. And it also showed that linear models, one of the results of many, was showing that linear classifiers couldn't solve the XOR problem. Um, the problem is- another way to think about the problem is basically given two inputs, can you tell whether they are the same or not, or different. And, um, so it's kind of not a- shouldn't be a hard problem but linear classifiers can do it. And for some reason, which I don't quite understand, it killed off neural nets research even though they had said nothing about if you had a deeper network, what it could do. Um, but it's often cited that this book, ah, swung things from people who were interested in neural networks to the field of AI being very symbolic and logic driven. Um, but there was always this kinda minority group, um, who were really invested in and believed in, um, the power of neural networks, and I think this was always just kind of a matter of time. So in the '80s, there was a renewed interest. Um, people kind of discovered or rediscovered the backpropagation algorithm which allowed a kind of, for a generic algorithm that could train these multilayer neural networks because single layer remember was insufficient to do a lot of things. And then one of the kind of the early success stories, as Yann LeCun in 1989, applied a convolutional neural network and was able to recognize hand digit- written digits, and this actually got deployed, um, by the USPS and was reading kind of zip codes. Um, so this was, you know, great, ah, but it wasn't until this decade that the, um, this area of neural networks really kind of took off, um, under the moniker deep learning. Um, and, you know, AlexNet in 2012 was kind of a huge transformation, um, where they show gains on the, kind of ImageNet ba- benchmark and overnight transformed the computer vision community. Um, AlphaGo as, you know, many of you know, and many kind of other, um, and there were kind of the rest is history. Okay, so- so there's this kind of two intellectual traditions. Um, you know, the name AI has always been associated with the kind of John McCarthy logical tradition, that's kind of where it started. But, um, as you can see that there is also kind of this neuroscience inspired tradition of AI, and the two are kind of really had some deep philosophical differences and over the decades fought with each other kind of quite a bit. But I want to pause for a moment and really think about, [NOISE] maybe if there were actually kind of deeper connections here. Remember McCulloch and Pitts, they were studying artificial and neural networks, but the connection was to logic, right? So from even in the very beginning, there is kind of this synergy that, you know, some- some people can kind of often overlook. And if you take a look at AlphaGo, which [NOISE] if you think about the game of Go or many games, it's a mathematically, you can write down the rules of Go in logic in just a few lines. So it's a mathematically well-defined logical- logic puzzle in some sense. But somehow, the- the power of neural networks allows you to develop these models that actually play Go really- really well. So this is kinda one of the deep mysteries that has, kind of, uh, I think is kind of o- opens standard challenge, you know, in AI. Um, as with any story it's not a full picture, and I want to point out on this slide that, AI has drawn from a lot of different, you know, fields, many of the techniques that we're gonna look at, for example, maximum likelihood, came from your statistics or games came from economics, optimizations, gradient descent, hence from- was, you know, in the '50s completely unrelated to AI. But these techniques kind of developed in a different context. And so AI is kind of like, you know, it's kind of like a New York City. It's- it's like a melting pot where a lot of the- these techniques that kind of unified and apply to kind of interesting problems. And that's what makes it, I think really interesting because of the- the new [NOISE] avenues that are opened up by kind of unique combinations of, um, existing techniques. Okay, so- so that was a really bre- brief history of, you know, where- how we got here. Um, now I want to pause for a moment and think about, you know, what is- what is the goal? What- what AI people are trying to do? And again this- this is kind of there's two ways to think about this which and- sometimes the conflation of these causes a lot of confusion. Um, so I like to think about it as AI as agents, and AI as tools. So the first view asks the kind of standard question of, how can we create or recreate intelligence? And the second one asked, you know, how can we use technology to kind of benefit, you know, society? [NOISE] And these two are obviously very related and they have, ah, a lot of shared technical, um, overlap, but, you know, philosophically they're kind of different. So let me kind of explain this a little bit. So the idea with AI agents is, and this is, I think a lot of what, um, um, gets associated with AI, um, and especially as, you know, with science fiction. That kind of, ah, po- portrayal certainly kind of encourages this kinda view where [NOISE] you're human- we're human beings. And what you do is you look in the mirror and you say, wow, that's must- that's a really smart person. And you think okay, how- how- what- what- what can humans do that is, you know, so amazing. Well, they can, um, they can see and they can perceive the world, recognize objects. Um, they can grasp cups and drink water and not spill it. [NOISE] Um, they can communicate using language as I'm doing to you right now. Um, we know facts about the world, [NOISE] declarative knowledge such as what's the capital of France and procedural knowledge like how to ride a bike. We can reason with this knowledge and maybe ride a bike to the capital of France. And then, really importantly, we're not born with all of this, right? We're born with basically nothing, none of these capabilities, but we are born with the capacity and potential to acquire these over time through experience. And learning it seems to be kind of this critical ingredient, which drives a lot of the success in AI today but also with, um, you, know, human intelligence it's clear that learning plays such a central role in getting us to the level that we're operating at. So each of these areas has kind of spawned entire sub-fields, and people in it are kind of wondering about how you can make artificial systems that have the language, or the motor, or the visual perceptual capabilities that, you know, humans have. But are we there yet? Um, and I would- I would like to think that we are, ah, very far. So if you look at the way that machines are, have been successful, it's all with a narrow set of tasks and, you know, millions or billions of examples, and you just crunch a lot of computation, and you can really kind of optimize, um, every- any tasks that you're going to come-come up with. Whereas humans operate in a very different regime. [NOISE] They don't necessarily do any, you know, one thing well, but they are have such a kind of diverse set of, you know, experiences, can solve a diverse set of tasks and learn from each individual tasks from very few examples. And still it's a kind of a grand challenge, in from a, uh, cognitive perspective, how you can build systems with this level of capability in that humans have. So the other view is, you know, AI tools. Basically we say okay well, you know, it's kind of cool to think about how we can, uh, you know, recreate intelligence. But, you know, we don't really care about making more, um, things like humans. We already have a way of, you know, doing that, that's called babies. [LAUGHTER]. Um, so when instead what we'd really like to do is not making something that's like a human but making systems that help humans. Because, you know, after all, we're- we're humans, I guess it's a little bit selfish but, um, we're in charge right now. Um, and- and a lot of this- this view and a lot of the success stories in AI are really different from the things that you expect, you know, this, uh, this humanoid robot to come into your house and be able to do. For example this is a project from Stefano Ermon's group. Um, there's a lot of poverty in the world and, um, part of it is- is just kind of understanding what's- what's going on and they had this idea of using, uh, computer vision on satellite imagery to predict things like, you know p-, uh, GDP. Um, so this is obviously not a task that, you know, the- our ancestors in Africa were like, you know, getting really good at. Um, but nonetheless it uses convolutional neural networks which is a technique that was inspired by, um, you know the brain and so that's- that's kind of interesting. Um, you can also have another application for saving energy by trying to figure out when to cool on datacenters. Um, as AI, is, uh, being deployed in more kind of mission critical s-, uh, situations such as self-driving cars or authentication. There are- there are a f- few th- new issues that come up. So for example, there are- thi- this phenomenon called adversarial examples, um, where you can take, um, these cool-looking glasses, you can put them on your face, and you can fool the computer, um, as- of- save our- our face recognition system to think that you're actually, you know, someone else. Um, or you can post these, uh, s- stickers on stop signs and you'd get this, uh- s- save our system to think that it's a, um, a speed limit sign. So there's obviously- there's- clearly these are, you know, big problems if we think about that the widespread deploy- deployment of AI. Um, there's also a less catastrophically but also p- pretty, um, you know, upsetting which is, uh, biases that you- many of you probably have read in the news about. So for example, if you take Malay which is a language that, uh, doesn't distinguish, um, in this writing form between he and she and you stick it into Google Translate. Um, you see that she works as a nurse but he works as a programmer, which is encoding certain, uh, societal biases, um, in the actual models. And one kind of an important point I wanna bring up is that, you know, it's -- it's how is machine learning and AI kinda working today? Well, it's, um, you know, society exists. Society is generating a lot of data. We're training on this data, and kind of trying to fit the data and try and mimic what it's doing and then using predictions on it. What could possibly go wrong, right? Um, and so- so certainly people- a lot of people have been thinking about, um, how these biases are kind of creeping up and is an open and active area of research. Something a little bit more, uh, kind of s- sensitive is, you know, asking well,  these systems are being deployed to all these- all these people whether they kinda want it or- or want it or not. Um, and this, uh, this actually touches on, you know, people's, uh, you know, livelihoods. It actually impacts people's lives in a serious way. Um, so Northpointe was this company that developed a- a software called COMPAS that tries to predict how risky, um, criminal risk or how someone- how risky someone is essentially. Um, and ProPublica this organization realized whoa, whoa, whoa, whoa. You have this system that, uh, given an individual didn't reoffend is actually, um, more- twice as likely to classify blacks as incorrectly as, you know, non-blacks. So this is, uh, seems pretty problematic. And then Northpointe comes back and says actually, you know, I think we- I think we're being fair. Um, so given a risk score of 7, uh, we were fair because 60% of whites reoffended and 60% of blacks reoffended. Um, the- the point here is that there's- there's- there's actually no, um, solution to this in some sense sadly. Um, so people are finding or formulating different notions of fairness and equality between, um, how you predict or record it on different kind of, um, groups. But, um, or you can have different notions of fairness and which all seem reasonable from first principles but mathematically they can be, um, incompatible with each other. So this is- this is again an open area of research where we're trying to figure out as a society how, um, to deal with the schema that machine learning might be using these in kind of critical situations. Okay. So summary so far, um, there's an agent's view. Um, we're trying to really kind of dream and think about how do you get these capabilities like learning from very few examples that humans have into, you know, machines and a whole- maybe opening up a kind of a- a different set of technical capabilities. But at the same time, and we really need to be thinking about how these AI systems are affecting the real world. And things like security, and biases, and fairness all kind of show up. It's also interesting to note that, you know, a lot of the challenges in deployment of an AI system don't really have necessarily to do with, um, you know, humans at all. I mean, humans are incredibly biased but that doesn't mean we want to build systems kind of in our- in, um, that mimic humans and kind of inherit all the kind of the flaws that humans have. Okay."}, {"content": "Any questions about this? Maybe I'll pause for a moment."}, {"content": "So let's go on. Um, so what I wanna do next is give an overview of the different topics, um, in the course. Um, and the way to think about all this is that, um, in AI we're trying to solve really complex problems. The real world is really complicated. And- but at the end of the day we want to produce some software or maybe some hardware that actually runs and does stuff, right? And so there's a very considerable gap between these things. And so how do you even approach something like self-driving cars or, um, you know, d- diagnosing diseases? You probably shouldn't just like go sit down at a terminal and start typing because then, um, there- there's no kind of- no overarching structure. So what this class is going to do is to give you one example of a structure which will hopefully help you approach hard problems, and think about how to solve them in a kind of more principled way. Um, so this is a paradigm that I call the, um, modeling inference and learning paradigm. Um, so the idea here is that there's three pillars which I'll explain in a bit. And, uh, we can focus on each one of these things kind of in turn. So the first pillar is modeling. So what is modeling? The modeling is taking the real world, which is really complicated and building a model out of it. So what is a model? Model is a simplification that is mathematically precise so that you can, you know, do something with it, uh, on a computer. Um, one of the things that's necessary is that modeling, um, necessarily has to simplify things and, you know, throw away information. Um, so one of the kind of, uh, the, you know, the art is to figure out what information to pay attention to and what information to keep. Um, so this is going to be important for example when you work on your final projects and you have a real world problem, you need to figure out, um, you can't have everything and you have to figure out judiciously how to, um, manage your- your resources. So here's an example. If you want to for example build a- a system that can find, uh, the best way to get from point A to point B in a graph- in a- in a city you can formulate the model as a- a graph where nodes are points in the city, and edges rep- represent ab- ability to go between these points with some sort of cost, um, on the edges. Okay. So now once you have your model you can do, uh, inference. And what inference means is asking questions about your model. So here's a model you can ask for example how- what is the shortest path from, um, this point, uh, to this point. Right. And that's because now your model land is a mathematically well-defined, uh, problem now you can- it's within the realm of, uh, you know, deve- developing algorithms to, you know, solve that problem. And most of the inference is ki- being able to do these computations, um, really efficiently. And finally learning addresses the problem, where does this model come from? So in any kind of realistic setting, um, the model might have a lot of parameters. Maybe it has, you know, millions of parameters and how do you s- if it- if it- wants to be faithful to the, you know, real world that how do you get all this, uh, information there. Um, manually p- encoding this information turns out not to be a good idea. This is, um, in some sense what, um, AI from the '80s was trying to do. Um, so the learning paradigm is as follows. What we're gonna do is specify a model without parameters. Think about it as a skeleton. So in this case we have a graph but we don't know what the edge weights are. Um, and now we have some data. So maybe we have data of the form people tried to go from X to Y and they took 10 minutes, or an hour, or so on, um, and then from this data we can learn to fit the parameters of the model. We can assign, um, costs to the edges that kind of are representative of what the data is telling us, okay? So now in this way, we can write down a model without parameters, feed the data, apply a generic learning algorithm and get a model with parameters. And now we can go back and do, um, inference and ask questions, you know, about this. Okay. So this is kind of the- the- the paradigm. And I want to really emphasize that, you know, learning is not- as I've presented is really not about any one particular algorithm like nearest neighbors or neural networks. It's really a kind of a philosophy of how you go about approaching problems by defining a model and then not having to specify all the details but filling them in later. Okay. So here is the plan for the course. We're gonna go from low-level intelligence to high-level intelligence; and this is the intelligence of, um, of the, of the models that we're gonna be talking about. So first we're gonna talk about machine learning, and like I've kind of alluded to earlier, machine learning is going to be such a kind of an important building block of- that can be applied to any of the models that we kind of develop. So the central tenet in machine learning is you have data and you go to model, its main driver of a lot of su- successes in AI because it allows you to, in software engineering terms, move the complexity from code to data. Rather than having, you know, a million lines of code which is unmanageable, you have a lot of data which is collected in kind of a more natural way and a smaller amount of code that can operate on this data and this paradigm has really been, it's really been powerful. One thing to think about in terms of machine learning is that it, it is, requires a leap of faith, right. So you can go through the mechanics of down- downloading some machine learning code and you train them all but fundamentally it's about generalization, right. You have your data, you fit a model, uh, but you don't care about how it performs on that data; you care about how it performs on new experiences. And that leap of faith is something that's, um, I think gives machine learning its power but it's also a little bit, um, at first glance perhaps magical. Um, it turns out you can actually formalize a lot of this using, um, probability theory and, and statistics but that's kind of a topic for another time. Okay. So after we talk about machine learning, we're going to go back and talk about the, the simplest of models, right. So a reflex model is this. So here's a quiz."}, {"content": "Okay. What is this animal? Okay, zebra. How did you get it so fast? Well, it's kind of a reflex, where your human visual system is so good, um, at, at doing these things without thinking. Um, and so reflex models are these, um, are models which just require a fixed set of computations. So examples like are linear classifiers, deep neural networks, um, and most of these models are the ones that people in machine learning um, use. Models is almost synonymous with, um, reflex on- in machine learning. The important thing that there's no feed for it."}, {"content": "It just like you get your input bam, bam, bam, and here's your output. Okay, so that's, that's great because it's fast. But there's some problems that require a little bit more than that. Right. So for example here's another problem. Okay, quick, white to move. Where does she go? Okay, there's, there's probably like a few of you who are like chess geniuses, um, but for the rest of us, um, I have no idea. I don't know, wait, who's moving again? Um, so, so in these kind of situations, we need something perhaps a little bit more powerful than a reflex. We need agents that can kind of plan and think, um, ahead. So the idea behind state-based models is that we model the world as a set of states which capture any given situation like, uh, a position in a, in a game and actions that take us between states which correspond to things that, um, you can do in the, in this game. Um, so a lot of game applications fall in this as category of robotics, motion planning, navigation. Um, also some things that are might not be- you might think of, um, planning as such as gen- you know, generation, um. In natural language or generating an image, um, you are, uh, can be cast in this way as well. So there's three types of state-based models each of which we'll cover in, um, you know weeks of time. So search problems are the classic, uh, you control everything so you're just trying to fi- find the optimal path. There are cases where there's randomness. For example if you're trying to go from point A to point B, maybe there's traffic that you don't, you know, don't know about or, um, in a game there might be dice that are- die which are rolled, and, uh, there's a third category which are adversarial games which is cases where your playing an opponent who's actively trying to destroy you. So what are you gonna do about it? Um, so one of the games that we're gonna, uh, be talking about, uh, when we talk about games is Pac-Man; and one of the assignments is, um, actually building, um, a Pac-Man agent such as this. So, uh, while you're looking at this, think about how- what are the states and what are the actions and how would you go about you know devising a strategy for Pac-Man to eat all the dots and avoid all the ghosts? So that's something, uh, to maybe look forward to. There's also gonna be a competition. So we'll see how- who ends up at the top. Okay, so state-based models, um, are very powerful and a value to kind of have foresight. Um, but some problems are not really most naturally cast as state-based models. For example, you know, how many of you play Sudoku or have played it before? So as the goal of Sudoku is to fill in these, uh, um, blanks with numbers so that, um, every row and column and three-by-three sub-block has the digits 1 through 9. So there's a bunch of constraints. Um, and there's no kind of sense in which you have to do it in a certain order, right. Whereas the, the order in how you move in chess or something is, you know, pretty important. Um, so, so these type of problems, uh, are captured by these variable-based models where you kind of think about a solution to the problem as an assignment to the individual variables, under some constraints. So constraint satisfaction problems, we'll spent a week on that, um, these are hard constraints. For example two people can be- or a person can't be in the two places at once for example. Uh, there's also Bayesian networks which we'll talk about which are variable-based models with, uh, soft dependencies. For example if you're trying to track, um, you know, a car over time, these are the positions of the car. These variables represent the position of the cars and these, uh, E's represent, uh, the- the sensor readings of the position of the car at that particular position and inference looks like trying to figure out where the car was given all this kind of noisy sensor reading. So that's also gonna be another assignment where you're going to deal with."}, {"content": "Okay. So finally, um, now we get to high-level. What's- so what is high-level intelligence here? Um, and I put logic here, um, for a reason that you'll see clear."}, {"content": "Yeah, is there a question? The Sudoku, can you explain why it's not a state-based model? Yeah, so the question is why is not the- why is the Sudoku problem not a state-based model? Um, you can actually formulate this as a state-based model, um, by just thinking about the sequence of, uh, assignments. But it turns out that, um, you can formulate in a kind of more natural way as a variable-based model which allows you to, uh, take advantage of some kind of more efficient algorithm to solve it. Right, it's- think about these models as kind of different, um, analogy as like a programming language. So yes, you could write everything in you know C++ but sometimes writing in you know, Python or, or SQL for some things might be more- might be easier. Yeah. [inaudible] state based problem where you have both adversarial elements and an element of randomness? Yeah, so the question is how do you categorize state-based models where there is both randomness and an adversary? Um, we're also gonna talk about those as well. Um, and those would be- I, I would classify them as adversarial but there is also a random component that you have to deal with, games like backgammon. Yeah, question. [inaudible] Yeah, so the question is about whether, uh, some of these are more continuous and some of them are more discrete. Uh, I don't necessarily think of, uh, so a lot of the reflex models actually can work in continuous state spaces, for example images. Um, actually it's, it's almost a little bit of the opposite where, um, the logic-based models are in some sense more, you know, discrete but you can also have continuous elements, you know, in there, um, as well. Um, so in this class, we're mostly going to focus on kind of discrete objects because they're just going to be simpler to work with. Okay, so what is this logic? So the motivation here is that suppose you, um, wanted a little companion who, um, you could boss around and, um, help or help you do things, let's say; that's a better way to say it. Um, so you'd like to be able to say okay, you know, tell us some information, um, and then later you wanna be able to ask some questions and have the system be able to reply to you. Um, so, um, you know how- how would you go about doing this? One way you could think about is building a system that you can actually talk to using natural language, okay. So I'm actually going to show you a, a little demo, um, which, uh, is going to come up in the last assignment on logic; um, and well, let's see what you think about it. Uh, okay, so this is going to be a system that is, um, based on logic that I'm going to, um, tell the system a bunch of things and I'm going to ask some questions. So, um, I want you all to follow along and you see if you can, you know, play the role of the agents. Okay. So I'm going to teach you a few things like, um, Alice is a student, okay. So it says I learned something. Now let's, let's quiz, um, is Alice a student? Okay."}, {"content": "Good. So that worked. Um, is Bob a student? What should the answer be? I don't know who's Bob. Um, okay. So now let's do, um, students are, uh, people. Um, Alice is not a person. I don't buy that [LAUGHTER] okay. So, um, okay it's, you know, it's doing some reasoning, right? It's using logic, it's not, uh, just, um. Okay. So now, let's do, um, Alice is from Phoenix. Phoenix is a hot city. I know because I've lived there. Um, cities are places, and if it is snowing, uh, it is, um, then it is cold. Okay, got it. So, um, is it snowing? I don't know."}, {"content": "Um, so how about this?"}, {"content": "Okay. So if, um, a person is from a hot place and it is cold, then she is not happy, okay. True."}, {"content": "Right, um. I guess those of you who have spent all your live in California would maybe appreciate this. But, um, okay, so ho- is it snowing now? How many of you say yeah, it's snowing? How many say no? You don't know?"}, {"content": "Okay. [inaudible] Ah, ah, [LAUGHTER] um, how about if I say Alice is, ah, happy. Okay, so is it snowing now? No, it should be no. Okay. So you, you guys were able to do this."}, {"content": "Okay. So this is kind of an example of a interaction which, um, if you think about it has is ve- very different from where you would see kind of in a typical, um, you know, ML system where you have to show it millions of examples of one particular thing and it can do a kind of one task. This is much more of a very open-ended set of, um, I wish to say that the, the experiences are super rich but they're definitely diverse. I teach- I just give one statement. I say it once and then all of a sudden it has all the ramifications and kind of consequences that built in and it kind of understands in a kind of a deeper level. Of course this is based on, you know, logic systems. Um, so it is brittle but this is kind of just a proof of concept to give you a taste of what I mean when I say logic. So, ah, these systems need to be able to digest this heterogeneous information and reason deeply with that information. And we'll see kind of how, um, logic systems can do that. Okay. So that completes the tour of the topics of this class. Um, now I want to spend a little bit of time on course logistics. Uh, so I wanna- all the details here are online. So I'm not going to be complete in my coverage, um, but I just wanna give you a general sense of what's going on here. Okay. So what are we trying to do in this course? Um, so prerequisites, um, there's programming, um, discrete math and, ah, probability. So you need t be able to code and you need to be able to, um, do some math and, uh, some kind of basic proofs. Right? So these are the classes that are, um, required or at least recommended that you- or if you have some equivalent experience that's, you know, fine too. Um, and what we- what should you hope to get out of this course? Right. So one had- the course is meant to be giving you a set of tools using the modeling inference learning paradigm. It gives you a set of tools and a way of thinking about problems that hopefully will be really useful for you when you go out in the world and try to solve real world problems. Um, and also by- as a side product I also want all of you to be more proficient at your math and programming because those are kind of the core elements that, ah, enable you to do kind of interesting, you know, things in AI. So a lot of AI and you, you read about it, it's very flashy but really the foundations are still, um, just you know math and programming in some sense. Okay. So the coursework is homeworks, exam, and a project. That's what you have to do, um, Homeworks, there's eight homeworks. Each homework is a mix of writing- written and programming problems centered on a particular application covering one particular type of model essentially. Um, like I mentioned before there's a competition for extra credit. There's also some extra credit problems in the, in the homeworks, um, and when you submit code, we're gonna run- we have an auto-grader that runs. It's gonna run on all the test cases but you get a feedback of only a subset. So you can, um, it's like, you know, in machine learning, you have a train set, and you have a test set. So don't train on your test set. [LAUGHTER] Okay. So um, the exam is, ah, testing your ability to use the knowledge that you learn to solve new problems. Right. So there's, um, I think it's worth taking a look at exam because this, this kind of surprises people every- the exam is a little bit different than the types of problems that you see on, on the homework and there are kind of more problem, you know, solving. So the exam isn't going to be like a multiple choice like, okay, you know, um, you know, when was Perceptrons published or something like that. It's gonna be, here's a real life problem. How do you model it and how do you come up with a solution? Um, they're all going to be written. It's closed book except for you have a one page of notes and this is a great opportunity to actually, um, review all the material and actually learn the ah, the content in the class. Um, so the project I think is a, a really good opportunity to take all the things that we've been talking about in the class and, um, try to find something you really care about and try to apply it. Work in groups of three and I really recommend finding a group early, um, and as I emphasize it's your responsibility to find, you know, a good group. Right? Um, don't come to us later like one week before the project deadline and say, \"Oh, you know, my group members they, um, they ditched me,\" or something. We really try to, try to nail this down use Piazza to- or your other social networks to find a good group. So throughout the quarter there's going to be these milestones for the projects. So, um, to prevent you guys from procrastinating into the very end, um, so there's gonna be a proposal where you try and brainstorm some ideas, progress report, a poster session which is actually a whole week before the final report is due, um, and the project is very open. So this can be, um, really liberating but also might be a little bit daunting. Um, we will hopefully give you a lot of structure in terms of saying okay, how do you define your task? How do you implement different, um, baselines or oracles? Which I'll explain later. How do you evaluate? How do you, um, analyze what you've done? And each of you will- each project group will be assigned a CA mentor, ah, to help you, ah, through the process and you're always welcome to come to my office hours or Dorsa's, or any of the CAs to get additional, um, help either brainstorming or figuring out what the next step is. Ah, some policies, ah, all assignments will be submitted on Gradescope, um, there are seven total late days you can use, and most two per assignment. After that there's no credit. Um, ah, we're gonna use Piazza for all communication so don't email us directly. Leave a post on Piazza. If- I encourage you to make it public if it's, it's not sensitive, but if it's, you know, personal, then obviously make it private, um, and try to help each other. We'll actually award some extra credit for students who help answer, um, other student's questions. So all of the details are on the course website. Okay. So one last thing and it's really important and that's the Honor Code. Okay. So especially if you're, um, you know, you've probably heard this if you've been at Stanford. If you haven't, then I wanna really kind of make this clear. So I encourage you all to have- collaborate, discuss together. But when you- when it comes to actually the homeworks, you have to write up your homework and code it independently. So you shouldn't be looking at someone's writeup. You shouldn't be looking at their code. Um, and you definitely shouldn't be copying code off of GitHub. Um, um, that's hopefully should be, you know, obvious and maybe less obvious, you should not- please do not post your homework assignments on GitHub. I know you're probably proud of the fact that your Pac-Man agent is doing really well but please don't post on GitHub because then that's going to be our Honor Code violation. Um, when debugging, um, with- if you're working together, it's fine to as long as it's kind of looking at input-output behavior so you can say to your partner, \"Hey, I put in this, um, input to my test case and I'm getting a 3. What are you getting?\" So that's fine but you can't."}, {"content": "Remember don't look at each other's code. Um, and to enforce this, we're gonna be running MOSS, which is a software program that looks for code duplication, um, to, to make sure that, ah, the rules are being followed and, you know, changing one variable name is- or you'll be so- anyway enough said. [LAUGHTER] Just don't, don't, don't do that. Okay? Any questions about this? I wanna make sure this is important or about any of those logistics. Yeah. [inaudible] The final project, ah, you can put on GitHub. Yeah. Yeah. Yeah, private GitHub repos, uh, is fine. Yeah, question in the back? Is it necessary to have a group or can you do a solo project? Uh, the question is can you, can you do a solo project? You can do a solo project, you can do a project with two people, or you can do a project with three. I would encourage you to try to work in, uh, groups of three because you'll be able to do more as a group, and there is definitely, uh, you know, it, it, it's not like if you do a solo project we'll be expecting like one third of the, the work. So okay."}, {"content": "Anything else? All right."}, {"content": "Okay. So in the fi- final section, I want to actually delve into s- some technical details. Um, and one thing we're going to focus on right now is, um, the, kind of inference and learning components of, of this course. So I'm going to talk about how you can approach these through the lens of, you know, optimization. So this is going to be, uh, it might be a review for some of you but hopefully, it's gonna be a, a good, um, you know, way to get everyone on the same page. Okay. So what is optimization? There's two flavors of optimization that we care about. There's, uh, Discrete Optimization, where you're trying to find the best, uh, discrete object. For example, you're trying to find the best, uh, path or the path P that minimizes the cost of that path. Um, we're going to talk about one algorithmic tool, um, based on Dynamic Programming which is a very powerful way of solving these, um, complex optimization problems. Um, and the key, you know, property here is that the set of paths is huge and you can't just, uh, trial them and compute the cost and choose the best one. So you gonna have to choose something clever. The second brand of optimization is continuous optimization and formally this is just finding the best of vector of real numbers that satisfies or minimizes some objective function. So a typical place this shows up is in learning where you define, uh, objective function like the training error and you're trying to find a weight vector W. So this notation just means it's a list of numbers, D numbers that minimizes the training error. And we're going to show that gradient descent is, uh, uh, easy and a surprisingly effective way of solving these, um, continuous optimization problems. Okay. So to introduce these two ideas, I'm going to look at two, um, problems and trying to kind of work through them. So this might be also a good, um, you know, way to think about how you might go approach a, you know, homework problems. And I'll try to kind of talk you through this, um, in a bit more detail. Okay, so the first problem is, um, you know, computing edit distance. Um, and this might not look, you know, like an AI problem, but a lot of, ah, AI problems have this as kind of a, you know, building block if you wanted to do some sort of matching between, um, you know, two words or two, um, biological sequences. So the input is you're given two strings. Um, we're gonna start writing over here on the board just to work this out. So given two strings, um, S and T. Um, so for example, um, a cat and um, the cats. Okay. So these are two strings and you wanna find the minimum number of edits that is needed to take transform S into T. And by edits I mean you can insert, um, a character like you can insert S, you can delete characters, I can delete this A and you can substitute one character for another. So you can replace this A with a T. Okay."}, {"content": "Um, so here's some examples. What's the edit distance of cat and cat? It's 0, you don't have to do anything. Cat and dog is 3, cat and at is 1, you insert the A or insert a C. Um, cat and cat is 1, um, and a cat and the cats is 4. Okay. So the challenge here is that there are, ah, quite a different number of ways to insert and delete. Right, so if you have a string of- that's very long there's just way too many things to like just try out all of them. Okay, so then, how do we, how do we go about, um, coming up with a solution? So any ideas?"}, {"content": "Yeah. [inaudible] simplify the output in terms of saying that the substitution tells us we considered [inaudible] deletion peoples who considered a substitution or vice-versa by saying like an empty character. Yeah, yeah. So let's try to simplify [NOISE] the, the, the problem a bit. And building up on your what you, um, what was said. So, um, one thing to note is that okay, where so the general principle, let me just write the general principle, um, is to, you know, reduce the problem to a simpler problem because then you can hopefully solve- it is easier to solve, and then you can maybe keep on doing that until you get something that's trivial. Okay."}, {"content": "So there's maybe two observations we can make. One is that well, we're technically saying we can, um, you know, insert into S right but if we insert into S, it makes the problem kind of larger in some sense, right? I mean that's not, that's not good. That's not reducing the problem. But, but whenever we insert into S, um, we probably want to insert things which are in T. We wanna like cancel something out, right? So we wouldn't insert a K there for any reason. We probably wanna insert a S in which case no S matches that and then we've reduced that problem, right? So we can actually think about, you know, inserting into S to S as equivalent to kind of deleting from, um, from T. Okay, does that make sense? All right. So another observation we can make is that, you know, we can start inserting anywhere. We can start inserting here and then jump over here and to this. But this just introduces a lot of, um, you know, ways of doing it which all kind of result in the same answer. So why don't we just start more systematically at one end and then just proceed and try to chisel-off the problem, um, kind of let's say from the end. Okay, so start at the end? Okay, so, so now we have this problem and to draw a problem in a little box here. Um, so let's start at the end. Yeah, question. What's the reasoning used to reach that principle start at the end? [NOISE]. [NOISE] the question is why are we starting at the end as oppo- well, the idea is that if you start at the end then you have kind of a more systematic and consistent way of, you know, reducing the problem. So you don't have to think about all the permutations of where I can delete and substitute. Why is it more systematic to go from the right to the left than from the left to the right? We can also do it left to right. So the end or the start is both fine. This is just- I just picked the end. Yeah. Are we not starting at the end and then give us the optimal strategy? Yeah, the question is how do we know that starting, um, at one end can give you the optimal strategy? Um, so, you know, if you wanted to prove this more rigorously there's some work but, um, I'll just try to give you a, you know, an intuitive answer. Um, suppose you didn't start at the end, and you just made a sequence of steps like I insert here, I delete here, and then I went over here and um, did all those operations to S. I could have equivalently also just sorted those by, you know, where it was happening and then just proceeded from one end to the other, and I would arrive at the exact same answer. So without loss of generality, I can start at that."}, {"content": "Any other questions? Okay."}, {"content": "So yeah. Instead of doing this wouldn't the more viable [NOISE] approach be that trying to recognize some patterns instead of doing this. I think between the two strings \"s\" and \"t\" like some form of- some sort of [NOISE] pattern [inaudible] string. Yeah. So the question is, maybe you can recognize some patterns. Uh, it's like okay, oh, cat. That's- that's- maybe those should be lined up. Um, I guess these examples are chosen so that these patterns exist, but we want to solve the problem for cases where, um, the pattern might not be obvious. So it could be- we want to work it for- it to work for all strings. Maybe there is no pattern, and we still would want to- kind of an efficient algorithm to do it. Yeah. Can't we just like use dynamic programming? Like we go one by one, there was always like [inaudible] - Yeah. Either we're doing, um, substitution, or, um, otherwise it's like the same character. Or we have to insert- Yeah. - um, and then we keep going, and you just like [NOISE] remember each like to- to strings that we have at one point- Uh-huh. -so that if we calculated that we don't have to do it again. Yeah."}, {"content": "Yeah. That's it. Yeah. Yeah. Yeah. Great idea. Let's do dynamic programming. Um, so that's what I'm kind of trying to build up from- uh, build up to. Okay so, um, so if you look at this- so dynamic programming is a kind of a general technique that essentially allows you to express this more complicated problem in terms of a simpler problem. Uh, so let's start with this problem. If we start at the end, um, if the two match then, well we can just immediately, um, you know, delete these two and that's- it's gonna be the same, right? So we can get- we are gonna get some free rides there. Okay, but when they differ, um, now we have many options. So what we could- what could we do? Well, we could, um, um, you know substitute. Okay, we can change the \"t\" to an \"s\". So what does that leave us with? So I can do a cat, [NOISE] \"t\" is the- the cat, the- [NOISE] Okay, so I can substitute. [NOISE] Um, [NOISE] okay. Um, what else can I do? [NOISE] Someone say something I can do. [NOISE] So I can insert, um, insert where into- [OVERLAPPING] So I can insert an \"s\", right? Yes. [NOISE] But that's the same as, you know, [inaudible] deleting from \"t\". So by, uh- you can basically also just delete this \"s\". Um, so this is our cat, [NOISE] and I deleted this \"s\" from \"t\". Okay, so this is, um, let's call it, uh, you know, um, I guess let's call this insertion- it's technically insertion [NOISE]. And then finally what can I do? [NOISE] I can also remove \"t\". So [NOISE] a, ca, the, cats. Okay, so this is delete. [NOISE] And right now you're probably looking at this like, well, obviously, you know, you sho- you should do this one. But in general it's hard to tell. What if I just give you some arbitrary strings, you know, who knows what the right answer is. Um, so in general how do you pick? Yeah. In the second one, the \"t\" is supposed to be for cats. [NOISE] [inaudible] You mean this one? Yeah. So here I inserted an \"s\", right? But then because there's two s's here, I just canceled them out and [NOISE] what was left [inaudible] So you can think about this as really deleting from- What if I'm considering [NOISE] [inaudible] Like in the original problem you said we're transferring \"s\" to \"t\". Yeah."}, {"content": "Yeah."}, {"content": "Yeah. So, um, um, because of this I'm kind of trying to re-frame the [NOISE] problem a little bit. Okay, so which one should I choose?"}, {"content": "Yeah. What about the substitution the other way? Um, the substitution the other way meaning change- \"s\" to \"t\". Sorry there's too many s's and t's here which [LAUGHTER] is going to be a bit unfortunate. And then replace the last s in cats with \"t\". Oh, you could- How do we eliminate that [inaudible] [NOISE] Um, that's- you can think about that as kind of equivalent. So, if you identify two letters that you want to make the same, then [NOISE] you could- you can replace the one to be the other, or the other to be that. I mean if- officially we've been kind of framing it as we're only editing \"s\" which is the reason that it's asymmetric. [NOISE] Okay, so which one of these? Door \"a\" door \"b\" or door \"c\"? Yeah. Would you look [inaudible] between \"s\" and \"t\" for every step [NOISE] [inaudible] because there's \"cat\" in both of them? Yeah, so you could try to look inside but, um, but remember these are- might be really complicated. So you- we wanna kind of a simple mechanized procedure to tell. [NOISE] What about the next letter? The next letter. \"t\" [inaudible] Um, yeah let's- let's pretend these are- you- you can't see inside them. Okay."}, {"content": "[LAUGHTER]. Keep going with each of the different cases. Yeah, okay, so let's keep on going. [NOISE] So, I'm not going to draw everything, but you can also try to break this down into- maybe there's three actions here, and three actions here. All right. Um, and at the end of the day you hopefully have a problem that's simple enough, that, um, where \"s\" equals \"t' or something then you're done. Um, but then, you know, how- how do I- how do I know? Suppose I've solved this. Suppose if someone just told you, okay, I know this cost, I know this cost, I know this cost. What- what should you do? [inaudible] Yeah, you should take the minimum, right? Like remember we want to minimize the edit distance. So, um, there's three things you can do. Each of them has some costs of doing that action which is, you know, one. Every edit is the same cost. And then there's a cost of, you know, continuing to do whatever you're doing. And so we're just gonna take the minimum over those. Yeah. [inaudible] How do we know that that's, like- that's the maximum amount of distance that we have to take? Yeah, so I was trying to argue that, um, with- if you're going to right to left, it's, uh, without loss of generality. Because if you've- went left to right, or in some other order, you can also replay the edits, um, in order. [inaudible] [NOISE] one letter that you needed one assertion like [inaudible] like upstream. But if you went from like the left it looks like as if you're [inaudible]. [NOISE] Yeah. [inaudible] Okay. Yeah. I think it works. [NOISE] Um, okay, so- so let's, um, try to code this up and see if we can make this program work. Okay, so, um, I'm gonna do editDistance. Can everyone see this? Okay, so, um, so I'm gonna define a function that takes two strings, and then I'm going to um, define a recurrence. So, recurrences are- are, I guess, one word I haven't really used, but this is really the way you should th- kind of think about, uh, dynamic programs, and this idea of taking complex problems and breaking it down. It's gonna show up, in you know, search problems, MDPs, and, you know, games. So, I guess it's something that you should really be comfortable with. So, let's um, define recurrence, uh, as follows. Um, so remember at any point in time, I have, uh, let's say a sub problem, and since I'm going right to left, I'm only considering the first, um, \"m\" letters of \"s\" and the first letter \"n\" letters of \"t\". Okay, so recurse is going to return the minimum edit distance between two things, the first \"m\" letters of \"s\", and the first \"n\" letters of \"t\". Um, I'm gonna post this online so you guys don't have to, like, copy- try to copy this."}, {"content": "Um, okay, so, um, okay, suppose I'm gonna- I'm gonna define this function. Uh, if I have this function what should I return? Recurse of-. [inaudible] So \"m\" is an integer, right? So \"n\" is an integer, so I'm going to return the length of \"m\" and the length of \"n\". Okay, so that's kind of, uh, the initial state. [OVERLAPPING] Sorry. Yup. Okay."}, {"content": "Um, All right. So now you need to fill out this function. Okay, so let's- let's um, consider a bunch of cases. So here's some easy cases. Suppose that, um, \"m\" is zero, right? So I have- comparing an empty string with something that has \"n\" letters. So, what should the cost of that be? [NOISE] I heard some mumbling."}, {"content": "[OVERLAPPING]. It should be \"n\" [NOISE] and symmetrically if \"n\" is 0 then result should be \"m\", um, and then if now we come to the kind of initial case that we consider which is the end [NOISE] match a match. So, if \"s\" um, the last letter of \"m\", you know, this is 0-based indexing. Um, so that's why there's a minus 1. So, this matches. [NOISE] Then what should I do? [NOISE] So, now we reduce this to a sub problem, right? [inaudible] So, I have \"m\" minus 1 and \"n\" minus 1. Okay. And now comes the fun case which we looked at. So there's- um, in this case the last letter doesn't match. So, I'm gonna to have to do some sort of edit, can't just let it slide. Yeah."}, {"content": "Question. Would you- do you need a full \"s\" to \"t\" compare or \"s\" through \"m\" and then \"t\" through \"n\" to compare? Worse than doing a full s, a compare. [OVERLAPPING] rather than waiting until, um, first- Yeah. -stream at the last slide than that. There- there's probably a way you can make this more efficient. I'm just gonna try to get the basic thing in there. Okay. So substitution. Okay. So what's a cost of a substitution? I pay 1 to do the substitution, but and in- as a reward I get to, um, reduce the problem to n minus 1 and n minus 1, right? So I lop off a letter from s and I lop off a letter from t. So what else can I do? So I can, um, you know, delete. [NOISE] So that also costs 1. And when I delete, I delete from s and then n. So this remains the same. And then now you can think about the insertion, um, is n minus 1, right? Because remember insertion into s is deletion from t, that's why this is n minus 1. Okay."}, {"content": "And then the result is just gonna be a minimum of, uh, all these things. Okay. Return result. Okay. So just, uh, and then, how do I call this function? Um, a cat, the cats. [NOISE] So let me print out the answer. Um, let's see if it works. Okay. Print out 4. Therefore, I conclude it works now. [LAUGHTER] I mean if you were doing this, uh, you would probably want to test it some more, but in the interest of the time, I'll kind of move on. So let me just kinda refresh."}, {"content": "Okay. So I'm computing this at a distance between two strings and we're gonna define a recurrence that works on sub problems, where the sub problem is the first m letters of s and the first n letters of t. And the reason I'm using integers instead of, um, strings is to avoid like string copying, um, implementation detail, but it doesn't really matter. Um, so base cases. So you wanna reduce your problem to a case where it's- it's trivial to solve. Um, and then we have the last letter matches. And then we have a letter doesn't match and you have to pay some sort of cost. I don't know which action to take. So I'm gonna take them, you know, minimum of all of them. And then I call it by just calling, you know, recurse. Okay. So this is great, right? So now I have a working thing. [NOISE] Um, let's try another test case. So I'm gonna make this. Um, so if I do times 10, this, uh, basically, uh, replicates this string 10 times. So it's a- it's a long string-longer string. [NOISE] Okay. So now I'm gonna run it. [OVERLAPPING] Maybe I shouldn't wait for this. Is there a base case? Um, there is a base case, I- I think that it expanded- it's- what- what's wrong with this code? Very slow. Um, yes, it's very slow. Why is it slow? [BACKGROUND] Yeah, right? So- so I'm recursing. [NOISE] Every point recurses three times. So you kind of get this exponential, you know, blob. Um, so there's kind of a- how do you solve this problem? [BACKGROUND] Yeah. You can memo I think I heard the word memoize, which is another way to kind of think about. Memorize plus, um, I guess, recurrences is dynamic programming, I guess. Um, so I'm gonna show you kind of this, um, way to do it which is pretty, uh, uninvasive. Um, and generally I recommend people. Well, get the slow version working [NOISE] and then try to make it faster. Don't try to be, you know, too slick at once."}, {"content": "Okay. So I'm gonna make this cache, right? And I'm gonna say if m, n is in the cache, then I'm gonna return whatever's in the cache. So cache is just a dictionary mapping. Um, the key which is, um, identification of the problem I'm interested in solving, and the result which is the answer that I computed. So if I already computed it, I don't need a computer again, just return it. And then at the end, if I have to compute it, then, um, I have to put this in the cache. [NOISE] Okay? So three lines or four lines, I guess. Yeah. [BACKGROUND] [NOISE] Yeah. That's a great point. Uh, this should be outside of the recurse object. Yeah."}, {"content": "Glad you guys are paying attention. Um, otherwise, yeah, it would do basically nothing. Any other mistakes? [LAUGHTER] Yeah. Um, there is also function decorators that like implement memoizing for you. In this class, are you okay if we use that or would you rather us like make our own in this case? Um, you can use the deco- you can be fancy if you want. Okay."}, {"content": "Um, yeah. But- but I think this is, you know, pretty transparent. Easy for learning purposes. Okay. So let's run this. So now it runs instantaneously as opposed to- I actually don't know how long it would have taken otherwise. Okay. And sanity check for t is probably the right answer because there's four was the original answer and multiply by 10. Okay."}, {"content": "any other questions about this? [NOISE] So this is an example of, you know, kind of basic, uh, dynamic programming which are, uh, you'd solve a problem trying to formulate it as a recurrence of a complicated problem in terms of smaller problems. Um, and like I said before this is gonna kind of show up, um, um, over and over again in this class. Yeah. [BACKGROUND] Yeah. So the question is why does this reduce, uh, redundancy. [NOISE] Is that right?"}, {"content": "Um, so maybe I can do it kinda pictorially. Um, if you think about, let's say, you have a, um, a problem here, right? And this gets, um, you know, reduced to, um, um, I'm just making kind of a arbitrary, um, diagram here. So this problem gets reduced to these two. And this problem gets reduced to these two, um, and- and so on, um, right? So if you think about- if you didn't have memoization, you will just be paying for the number of paths. Every path is a kind of you have to compute from scratch. Whereas, if you do memoization, you pay the number of nodes here, which a lot of this has shared like here. Um, you know, once you compute this, no matter if you're coming from here or here, you're kind of using the same value. Okay. So let's- let's move on. So the second problem, um, we're gonna talk about is, uh, has to do with continuous optimization. [NOISE] And the motivating question here is how do you do, um, regression? Which is a kind of a bread and butter of, um, you know, machine learning here. [NOISE] So here we go. Regression. Okay."}, {"content": "So imagine you get some points. Okay, so I give you a point which is 2, 4. Then I give you another point, let's say 4, 2. And so these are data points, you want to, let's say, predict housing price from, you know, square footage or something like that. You want to predict health score from, um, your blood pressure and some other things. So this is pretty common in machine learning. And the question is how do you fit a line? I'm going to consider the case where your line has to go through the origin, just for simplicity. Um, so you might want to like find, you know, a fit. Two points is maybe kind of a little bit degenerate, but that's the simple example we are going to work with. In general you have lots of points and you want this to fit the line that best kind of, uh, is close to the points. Okay, so how do you do this? So there's a principle called least squares, which says, well, if you give me a line which is given in this case by a slope w, I'm going to tell you how bad this is. And badness is measured by looking at all the training points, and looking at these distances. Right. So here I have, you know, this particular, uh, a particular, let's say point x_i. If I hit it with a w, then I get, basically the, uh, you know, the y-intercept here, not the y-intercept but the- like the y value here. That's my prediction. The real value was y_i, which is, you know, up here. And so if I look at the difference, I want that difference to be zero. Right. So in, in least squares, I square this, and I say, I want this to be as small as possible, right. Now, this is only for one point. So I'm going to look at all the points. Let's suppose I have n points, and that's a function that I'm going to call f of w, which basically says, for a given weight vector, which is a slope, give me a number that characterizes how bad of a fit, um, this is. Where 0 means that I fit everything perfectly, and large numbers mean that I fit poorly. Okay?"}, {"content": "All right. So, so that's your regression. So how do I solve a regression problem? So how do I optimize this? Can you do this in your head? So if I actually had these two points, what should w be? Okay, it doesn't matter. We'll, we'll compute it. So how do we go about doing this? So one principle, which is maybe another general takeaway is, abstract away the details. Right. Um, this is also true with the dynamic programming, but sometimes, you know, you get- if you're too close to the board, and you're looking at, oh man, these, these points are here and I need to fit this line. How do I do that?"}, {"content": "You kind of get kind of a little bit stuck. Why don't we think about this f, as say some function? I don't, I don't really care what it is. And let's plot this function. Okay. So now this is a different plot. Now, this is, ah, the weight, and this is f of w. [NOISE] Always label your axes. And let's say this function looks like this. Okay. So which means that for this slope, I pay this, you know, amount, for this slope, I pay this amount and, and so on. And what I want to do, I want to minimize f of w, which means, I want to find, um, the w which, um, has the least value of f of w, right? Question?"}, {"content": "Okay. So you take the derivative. So what is the derivative giving you? It tells you where to move, right? So if you look over here, so you can- in general, you might not be able to get there directly, in this actually particular case you can because you can solve it in closed form, but I'm going to try to be more general. Um, so you start here. This, this derivative tells you, well, the function is decreasing if you move to the right. So then you should move to the right. Whereas over here, if you end up over here, the derivative says, the function is decreasing as we move to the left. So you should move to the left, right? So what I'm going to introduce is this, uh, algorithm called gradient descent. It's a very simple algorithm. It basically says, start with some place, and then compute the derivative, and just follow your nose. Right? If the derivative says it's negative, then just go this way. And now you're on a new point, you compute the derivative again, you descend, and now you compute it again. And then maybe you compute the derivative and it says keep on going this way and maybe you overshoot, and then you come back. And then, you know, hopefully you'll end up at the minimum. Okay."}, {"content": "So let's try to see what this looks like in code. So gradient descent is one of the simplest algorithms, but it really underlies essentially all the algorithms that you people use in machine learning. So let's do points."}, {"content": "We have two points here. Um, and I'm going to define, um, some functions. Okay, so f of w, so what is this function? So I'm going to sum over all the different, um, you know, and basically at this point it's converting math into Python. So I'm going to look at all the points. So for every x, y, what the model predicts is w times x minus y. And if I square that, that's going to be the error that I get on that point. Then, if I sum over all these errors then I get my objective function. Okay. Array of- so yeah. So you can put array here if you want, but it doesn't matter. It's, it's actually fine."}, {"content": "Okay. So now I need to compute the derivative. So how do you compute the derivative? So if your calculus is a little bit rusty, you might want to brush up on it. So what's the derivative? Re- remember we're taking the derivative with respect to w, right? There's a lot of symbols here. Always remember what you're taking derivative with respect to. Okay. The derivative of the sum is the sum of the derivative. So now I need to take the derivative of this. Right. And what's the derivative of this? Something squared, um, you bring the two down here, and now you multiply by the derivative of this. And what's the derivative of this? Should be x. Right? Because this is a- y, this is a constant, and w derivative- w times x with respect to w is x. Okay."}, {"content": "So that's it. Okay, so now let's do gradient descent. Let's initialize with w equal 0. Then I'm going to just, um, you know, iterate a hundred times. Normally, you would set some sort of stopping condition, but let's just keep it simple for now. Okay, so for every moment, I'm going to- I have a w, I can compute the value of the function, and also take the gradient of the derivative. Gradient just means derivative in higher di- dimensions, which we'll want later. Um, okay. And then, what do I do? I take, uh, w, and I subtract the, the gradient. Okay. So remember- okay, I'll be out of here. Okay. So, uh, I take the gradient. Remember I want to have the gradient. Uh, gradient tells me where the function is increasing, so I want to move in the opposite direction. And eta is just going to be this, uh, step size to, um, keeping things under control. We'll talk more about that next time."}, {"content": "Okay, so now, I want to do, print out what's going on here. So iteration, print out the function, and t value. Okay. All right, so let's compute the gradient. And, um, so you can see that the iteration, we first start out with w equal 0. Then it moves to 0.3, then it moves to 0.79999999 and then it looks like it's converging into 0.8. And meanwhile, the function value is going down from 20 to 7.2 which happens to be the optimal answer. So the correct answer here is 0.8. Okay, so that's it. Next time we're going to keep, uh, we're going to start on the machine learning lecture."}], "Sam Altman on His Feud with Elon Musk\u2014and the Battle for AI's Future": [{"content": "what is the fundamental conflict between Elon Musk and his various allies meta being one of them and you guys like what what is the disagreement fundamentally about look I'm I don't live inside elon's head so this is a little bit of of speculation uh Elon definitely did a lot to help open eye in the early days and in spite of all of this I'm very grateful and I think he's just a sort of legendary entrepreneur um he's also clearly a bully and he's also someone who clearly likes to get in fights you know right now it's me it's been Bezos Gates Zuckerberg lots of other people hi honestly listeners Barry here and I'm so excited for you to listen to this wide ranging and fascinating conversation with open AI Sam Altman before you watch it I wanted to come and talk to you about a big endof year Push by the end of 2024 in just a few days we want to get to a million Free Press subscribers a million people who Value Independence and curiosity and who above all want a news source that reflects reality if you're here if you're on this YouTube page we know it's not just because you believe in Fearless old school journalism for yourself it's because you think it's a necessity for democracy free pressers tell us again and again that we're not just a media company we're a public trust I'm confident that by becoming one of the first million free pressers you will be getting in on the ground floor so before you watch this video take out your cell phone or open a new tab and go to vf.com subscribe and become a free presser today if you're already signed up you can earn a free year subscription or even a pair of TGIF Socks pre-worn by Nelly if you refer your friends or family members okay one more time before we get to Sam Altman go to the free press's website at vp.com ssubscribe and help us get to our goal of a million free pressers by 2025 we are so close and we really appreciate your support on to the show from the free press this is honestly and I'm Barry Weiss just a few years ago as AI technology was beginning to spill out of startups in Silicon Valley and hit our smartphones the political and cultural conversation about this nent technology was not yet clear or at least it wasn't clear yet to civilians like me I remember asking former Google CEO Schmidt on honestly in January 2022 if AI was just like and this is actually what I said the sexy robot in exmachina I literally said to him what is AI how do you define it I do not understand I cringe listening back to that because today in the waning days of 2024 not only has it become clear what AI is and how to use it chat GPT averages more than 120 million daily active users and processes over a billion queries per day but it's also becoming clear what the political and cultural ramifications and the arguments in the debates around AI are and what they're going to be over the next few years those are the big questions who gets to lead us into this new age of AI technology what company is going to get there first and Achieve market dominance how those companies are going to be structured so that bad actors with bad incentives can't manipulate this technology for evil purposes what role the government should play in regulating all of this at the center of these important questions at least for right now are two men Sam ultman and Elon Musk and if you haven't been following they aren't exactly in alignment I don't trust open AI I don't trust Sam Alman and I and I don't think we want to have the most powerful AI in the world control by someone who is not trustworthy it'd be profoundly unamerican to use political power to the degree that Elon has it to hurt your competitors and Advantage your own businesses they started off as friends and business partners in fact Sam and Elon co-founded openai the company that makes chat GPT in 2015 but over the years Elon Musk grew increasingly frustrated with open AI until he finally resigned from the board in 2018 the feud between ultman and musk escalated this past year when Elon sued Sam and open aai on multiple occasions to try and prevent open AI from launching a for-profit arm of the business a structure that Elon claims is not only never supposed to happen in open AI he likes to remind people that a nonprofit transparent company should not become a closed for-profit one but he argues that changing its structure in this way might even be illegal now on the one hand this is a very complex disagreement to understand every single detail of it you probably need a law degree and special expertise in American tax law neither of which I happen to have but you don't need any special degree or specialization to understand that at its heart the feud is about something much bigger and more existential than open ai's business model although that's extremely important and something we discuss today what this is really about I think foundationally is a fight over who will ultimately control this technology and technology that some say if used incorrectly could very well make human beings obsolete so the stakes are low here to tell his side of the story is Sam ultman we talk about where AI is headed why he thinks super intelligence in other words the moment where AI surpasses human capabilities is closer than ever we talk about the Perils of AI bias and censorship why he donated a million dollars to Trump's inaugural fund as a person who had long opposed Trump what happens if America loses the AI race to a foreign power like China and of course what went wrong and is going wrong between him and the richest man on earth we'll be right [Music] back Sam Alman thank you so much for coming on honestly thank you the last time we spoke and I know you've given a zillion interviews since then but it was in April of 2023 and it feels like a world away Chachi PT had just launched and people were just at the very beginning of trying to figure out like in the abstract what this technology was and how it might transform their everyday lives and now sitting here in December of 2024 chat GPT is a household name so is open Ai and of course some of your competitors are too like perplexity and Gemini and Claude average Americans are using these tools every day everything from math tutoring to debugging code to dra emails and it's very very good at doing that tell me about how chat GPT and I guess AI technology more broadly has changed since we last spoke a year and a half ago and whether or not it's where you expected it to be today or further along so I think there's two different things we talk about one is how much the technology itself has changed and that has gotten way better I if you think about the AI we were excited about back in April of 2023 it was so primitive relative to what we have now and the things that the technolog is capable of are pretty mind-blowing to me but even more than that the the rate at which it will continue to get better over the next year and if we came back in another 18 months and talked about what it can do I think it'll feel like as big or maybe even bigger as a gap from April 2023 to December of 2024 um as projecting that same amount of time I guess that's more like 20 months going forward the other thing that's happened is it's really integrated into society like back then it was still a curiosity something may people had heard of people really use it a lot for like a lot of their work their personal lives their it's I've never seen a technology become widely adopted this fast not just as something people like dabble with but something that people like really use in all the ways you were talking about so that that part of the adoption curve happened much more quickly than I thought I expected the technology to happen quickly give me a sense of like how are you using the tool that you have helped create in your daily life like the way that most people know we're using it Tyler Cowen and lots of people who are like passionate early adopters it almost seems to have like replaced Google for them and it's just like a much much deeper Google is that how for I use it in all sorts of ways but the newest one um a few months ago we reled we released search integration and now chat GPT can search the internet for kind of real-time information and of everything we've ever shipped that was the one that felt like it doubled my usage all at once and since then I mean I must have still used Google for something but I can't remember what it is wow and I switched chat gbt to be my default search in Chrome uh and I have not looked back the degree to which that behavior changed in me for something that was really deeply ingrained and now the fact that like when I remember the way that I used to search um feels like kind of oh man that was like a pre- iPhone kind of equivalent that's the sort of like level of shift that I feel about it um that's that's been the most surprising change to me in the last few months is that I don't I do all my searching now inside of chat what do you call it do you call it searching or is there a verb in the way that Googling is a verb I still call it search I mean I just like people other people say like I chatted it or I chat whatever people say I chatted it a lot like people seem to just only call it chat but I I I would say I just use search Sam in September so just a few months ago you published this Manifesto on your website predicting the emergence of super intelligence in the next few years or as you put it and memorably in the next few thousand days explain to us what super intelligence is tell us how we'll know if it's actually here and how it stands to change people's lives over the next decades one one thing that I use as a sort of my attempt at my own mental framework for it is the rate of scientific progress um if the rate of scientific progress that's happening in the world as a whole tripled maybe even like 10x you know the discoveries that we used to expect to take 10 years and the technological progress that we used to expect to take 10 years if that happened every year and then we compounded on that the next one and the next one and the next one that me would feel like super intelligence had arrived and it would I think in many ways change the way that Society the economy work it what it won't change and I think a lot of the sort of AI commentators get this wrong is it won't change like the Deep fundamental human drives uh and so in that sense you know we've been through many technological revolutions before things that we tend to care about and uh what what drive all of us I think change very little or maybe not at all through most of those but the world in which we exist will change a lot okay well Sam one of the reasons we wanted to have this conversation with you today is not just because we want to hear about the ways that AI is going to transform the way that we live and work but because you're in a very public battle right now with your original open AI co-founder Elon Musk and I think it's safe to say that most listeners of this show will like vaguely know that there's a conflict between Elon Musk having to do with this one of his companies one of his many companies but there's certainly not following the nitty-gritty details of of the various lawsuits and of and of the conflict more generally so I want to try and summarize it for you in the most Fair way that I can and then you'll tell me if I've gotten it wrong or or where I've where I've overstepped so open AI begins in 2015 and it starts as a nonprofit and in a blog post introducing open AI to the world in December of that year you wrote this open aai is a nonprofit artificial intelligence research company our goal is to advance digital intelligence in the way that is most likely to benefit Humanity as a whole unconstrained by a need to generate Financial return since our research is free from Financial Obligations we can better focus on a positive human impact and this was a huge aspect of the brand then fast forward four years in 2019 open AI moves to what it called a hybrid model with a for-profit arm that got a billion doll investment from Microsoft in that year since then Microsoft has ped something like $1 13 billion it might be a higher number more into the company and Elon was one of the co-founders as I mention since the beginning but his relationship with the company soured over time because he disagreed with the shift that I just described the shift from this nonprofit model to a hybrid model and he eventually leaves the company and steps down from the board and that takes us to this year in which Elon has sued you and openai on several different occasions so far this year and he has gone given many interviews and posted countless amount of tweets or X's or whatever we're supposed to call them about this conflict all of the lawsuits claim that you were in some kind of contract violation by putting profits ahead of the public good in the move to advance Ai and then last month and this is the most recent of vment Elon asked the district judge in California to block open AI from converting to this for-profit structure okay that was a mouthful did I summarize it properly and is there anything crucial that I left out or you summarize it properly but uh I mean it was Elon that most wanted to convert not not even convert it was Elon that Most Wanted open AI to be a for profit at one point and had made a bunch of proposals that would have also things like opening I being part of Tesla but mostly just create a new for-profit that he was going to be in control of and you know so other than that I think a lot of the summary there is is correct I have a bunch of thoughts and opinions on it but as a statement of facts that was otherwise mostly correct give us like the 10,000 foot version what is the fundamental conflict between Elon Musk and his various allies meta being one of them and you guys like what what is the disagreement fundamentally about look I'm I don't live inside elon's head so this is a little bit of of speculation uh Elon definitely did a lot to help open eye in the early days and in spite of all of this I'm very grateful and I think he's just a sort of legendary entrepreneur um he's also clearly a bully and he's also someone who clearly likes to get in fights you know right now it's me it's been Bezos Gates Zuckerberg lots of other people and I think fundamentally this is about opening eyes doing really well Elon cares about doing really well Elon started uh and now runs a very direct competitor that's trying to do exactly what open AI does uh and I'll point out is a structure uh you know as like a public benefit Corp and I heard Elon has majority ownership and control and seems like a reasonable thing he would do I think a lot of the press has been misreported we're not like the non even if we go through with of the any of the conversion ideas or Evolution ideas we're talking about it's like the nonprofit goes away the nonprofit doesn't like stop being nonprofit becomes a for-profit we've talked publicly about maybe we evolve our current LLC into a PBC but anything we do would strengthen the nonprofit the nonprofit would continue to exist would continue to serve hopefully better serve the same purpose and the overall mission of the company that you talked about which is develop this incredible technology do it in a way that we think is maximally beneficial to humans and get it out into the world for people we keep doing that I'm incredibly proud of our track record on doing that so far people as you were saying earlier use chat GPT and love it there's an incredible free tier of chat GPT uh we lose money on it it's not ad supported or anything we just want to put AI in people's hands we continue to want to deploy this technology uh so that people co-evolve with it understand it that the world is going through this process it's going through right now of contending with AI and eventually AGI and thinking how it's going to go and everything we're doing I believe Elon would be happy about if he Wen in control of the company he left when he thought we were like on a trajectory to certainly fail um he and also wouldn't do something where he had like total control over open AI but I think it's like a little bit of a sideshow and the right thing for us to do is just keep doing incredible research keep shipping products people love and and most importantly like keep pursuing this mission of AGI to benefit people and getting that out into the world for someone who's just sort of tuning into this topic why is it important Sam that open AI has a for-profit arm or converts in the way that you've been talking about why why is that essential to your growth when we started openi we thought it's hard to go back and remember how different things were in 2015 um that was before language models and chatbots it was way before chat gbt we were doing research and Publishing papers and working on AIS that could play video games and control Rob about of hands and things like that and we we were supposed to get a billion dollars but ended up not we thought with a billion dollars we could make substantial progress towards what we were trying to do as we learned more and got into the scaling language model world we realized that it was not going to cost 1 billion or even 10 but like 100 billion plus and we couldn't do that as a nonprofit so that was the fundamental reason for it okay so like it's Bas and maybe another way to say it is like it's absolutely essential for the computational power to create okay every other effort pursuing AI has realized this and has set up in some way where they can sort of Access Capital markets you've said a lot of different things about Elon in recent days you gave this interview at dealbook where Andrew Ros sorin is sort of asking you how you feel about the conflict and you say sad and you also say that you think elon's companies are awesome and then he asked you you know do you think he's going to use his Newfound political influence to kind of punish you or punish open AI or punish his competitors and you said in that interview that you thought he was do the right thing how do you square that with what you just told me which is that elon's a bully bullies don't typically do the right thing I think they can totally be like I think I think there are people who will really be a jerk on Twitter who will still not like abuse the system of a country they're now in a sort of extremely influential political role for that seems completely different to me until now much of this battle you know for those of us who are like perpetually online and perpetually on Twitter we have been following the conflict via like tweets lobed sub tweets it's all sort of been playing out in real time on Twitter for us to watch open AI though has sort of been in like response mode sometimes or mostly kind of ignoring everything that's sort of how i' characterize it that changed a few days ago when you guys published this very very long memo on open it's like a blog post on open ai's website people should go and read it again we'll put it in the show notes and it's sort of like complete it's it's like a timeline going back to 2015 proving from your perspective that you know via emails and screenshots of texts and explanations of those screenshots and those texts that Elon wanted open aai to or or Elon rather was open to open AI being a for-profit going all the way back then I read all 29 Pages for those who don't want to do that they could go to chat GPT and ask them to summ asked chat to summarize it here's how chat gbt summarized it this article details the rift between Elon Musk and open AI leadership par particularly Sam Alman stemming from musk's dissatisfaction with open AI shift from a nonprofit to a hybrid for-profit model this Feud is crucial chat told me because it underscores the broader ethical dilemma of how AI should be developed and controlled whether it should prioritize public good or corporate profit especially as powerful AI Technologies become increasingly influential in society in the economy I thought that was pretty good what do you think no but on your general point we you are right that we do not sit there and like throw tomatoes back and forth on Twitter um the reason for this one was we had to make a legal filin and we wanted to provide some context we published about this once before also when we had to make a legal filing I've lost track of how many times that Elon has sued us I think it's like four you know withdraws changes goes for this preliminary injunction whatever our job is to build AGI in a way that benefits humanity and figure out how to safely and broadly distribute it um our job is not to engage in like a Twitter fight with Elon but when we have to respond to Illegal filing we will Pro we will and sometimes we'll provide context I think we've only done this twice in the early days of open aai the brand like the way I encountered the brand of it was transparency and nonprofit like those were the things that it over and over emphasized and the reason you said that you couldn't take any equity and the reason you took such a small salary is because you said I you know I don't want to be conflicted I want to always be motivated to do the thing that's best for Humanity the day after open AI launched in December in 2015 you described it to Vanity Fair as a nonprofit company to save the world from a dystopian future you also said that trying to make open AI a for-profit would lead to quote misaligned incentives that would be suboptimal to the world as a whole I guess I want to ask like do you still agree with that but simply you've had to adapt to the reality which is that developing these models takes billions and billions and billions of dollars two things one I I think I was like a little bit wrong about that um and I have been although I have had concerns um I have been impressed by how much not just us but the other AI Labs even though they have this like wild sort of Market or economic incentive have really been focused on developing safe models I think there's many factors that went into that we did get a little lucky on the direction the technology went but also if you deploy these models in a way that is harmful to people you would like very quickly I believe lose your license to operate if it was an obvious one now there are subtle things that can go wrong like I think social media is an example of a place where maybe the Harms W so obvious at the time and then there was an emergent property at scale and you could imagine something happening but the incentive problem has been better than I thought at the time and I will cheerfully say I was like a little bit naive about how the world Works 10 years ago and I feel better now naive how oh the the the pressure the societal pressure on big companies and the sort of the power of researchers to push their companies to do the right thing even in even in the face of this gigantic profit motive have been pretty good but there is something that I don't feel naive about that I felt at the time too which is it continues to be fairly crazy to me that this is happening in the hands of a small number of private companies to me this feels like the Manhattan Project are the Apollo program of our time and those were not done by private companies and I think is like a mark of a well-functioning society do you think that we need a Manhattan Project here I think the companies are going to do the right thing and it's going to go well and I I don't think government effort in this current world would work at all I don't think it'd be good if it did honestly I just I I wish we were in a world where I said this is you know where I felt like that was the way it should and was happening meta right now is also siding with Elon a few days ago meta asked California's AG to block open AI from becoming a for-profit this is what they said in their letter open ai's conduct could have seismic implications for Silicon Valley if open ai's new business model is valid nonprofit investors would get the same for-profit upside as those invest in the conventional way in for-profit companies while also benefiting from benefiting from the tax writeoffs bestowed by the government this Echoes what musk said last year when he said I'm confused as to how a nonprofit which I donated to somehow became a market cap for profit in other words if this is legal like why isn't everyone doing this I don't know why I Med accept that letter but I do know they know that's not how it works I I know that part's in bad faith if if you in any of these worlds our nonprofit will keep going and the people that invest in the nonprofit uh don't like you don't get to have a benefit from a nonprofit donation ACW to a sort of for-profit equity of course and and they know that too you can imagine lots of other reasons that meta might have sent this letter you can imagine they wanted I mean you can imagine they wanted to Curry favor with Elon you can imagine that they felt like it would help them compete with us um you could imagine that they were like annoyed with us for a perceived anti-open Source stance which I don't think is accurate or something that I feel I don't know you should ask them what the reason was for the civilian who's hearing how does a nonprofit become a for-profit what's the answer it doesn't like the nonprofit stays as the nonprofit I believe that the opening eye nonprofit is on a trajectory I hope if we do well to be the largest and most impactful nonprofit of all time that nonprofit doesn't become anything else like many other things this our world our ecosystem can have a for-profit business also but that doesn't the nonprofit does not convert the nonprofit does not go anywhere the nonprofit does not stop doing nonprofit things at the end of the day Sam who is going to profit most from the success of open AI everyone I'll tell you what I hope everyone gives their analogy for um What technological Revolution this is most like you know it's the Industrial Revolution it's like electricity it's like the web the thing I hope for is that it's like the transistor we discovered a new important fundamental physical law whatever you want to call it um we did a bunch of research so did others and it it will seep into all aspects of the economy products everything and you and I today uh are using many devices with transistors in them to make this podcast possible computer has some your microphone has some the all of the internet equipment between and me has a lot but we don't sit here and think about transistors and the transistor company does not sit here and make all of the the money it is this this new Incredible scientific discovery that's seeped into everything we do and everybody made a lot of money that's what I hope AI will be like and I think there's many reasons why it's the best analogy will you have Equity or do you have Equity or what kind of stake do you have in this new capped for profit well so we haven't formed a new entity yet um we have obviously considered uh forming a new entity or maybe converting our existing ALC into one is more accurate um I have a tiny sliver of equity from a old YC fund um I used to have some via sequa fund but that one turned out to be easier to like sell and not keep the position in um so I have a very small amount that was like quite insignificant to me in terms of what I will or won't have going forward I don't I know it's not like there's no current plan or promise for me to get anything I I will and I if I got anything it would not be there were like outlandish rumors about some number that would not happen do you get why people are fixated on that for sure as I've said many times before if I could go back in time I would have taken Equity I think again I understand more about why my earlier misgivings were misplaced I also get that it's weird for me to take it now after not earlier on the other hand I would love to never have to answer this question again and be like normal company I run it I've got some Equity investors don't have to worry that I'm like misaligned there does the whole like a of Suspicion of not having any is one of the decisions I regret the most of opening eye structure things but I understand why people are fixated on it uh that makes sense if you could go back in time how would you have done this from the beginning like let's wind back the clock to 2015 if an oracle had said to me on what was it November of 2015 before we set out number one you're going to need 100 plus billion dollars number two even though you have no idea today how you're going to ever productize this and you think of yourself as a research lab eventually you're going to become a company that does have way to productize it and business model it so you can explain to investors why they're not just funding a research lab um and number three that the incentives of people working on this are going to be more naturally kept in check because it's not going to be what I and many others thought at the time of like one effort that is way far ahead of everyone else but something more like the transistor that seeps out and so there will be better equilibrium Dynamics if an oracle had told me all three of those things that turned out to be true I would say great let's be a public benefit Corp how essential was Elon to getting open AI off the ground like if if the Oracle also told you about this fight that would ensue with someone that you regarded as your close friend would you have said you know don't need him can do it myself no he was really helpful I'm super appreciative I think it was the first time I ever saw Elon Musk was on stage at a conference you were interviewing him you guys had a wonderful Dynamic you seem like you were really good friends he has said some really harsh things about you he's compared you to Littlefinger in the Game of Thrones most devastatingly said I don't trust him and I don't want the most powerful AI in the world to be controlled by someone who isn't trustworthy why is he saying that I think it's because he wants the most powerful a in the world to be controlled by him and again I've seen elon's attacks to many other people many friends of mine you know everyone gets their period of time in his Spotlight but this all seems like standard behavior from him I'm trying to put myself in a position of a former friend a former co-founder of mine saying those kinds of things about me you you seem relatively calm about it no I'm upset by it for sure I I was talking to someone recently who uh I did think of as close and they said like Elon doesn't have any friends Elon doesn't do peers Elon doesn't do friends that was sort of a sad moment for me um because I do think of him as a friend but I I don't know I can look at this like somewhat dispassionately I remember what it was like when he said opening I has has a 0% chance of success and you know you guys are idiots and I'm ping funing and I'm going to do my own thing there were moments since then where it felt like he kind of wanted to reconcile and figure out a way to work together and I remember moments where he's just like you know off doing his thing on Twitter but if it were only towards me I think it'd be much more painful but you know I think you see who he is on Twitter and so I can like hold it somewhat impersonally and just be like this is about Elon this is not about me it still sucks um I've had a long time to get used to it I guess this recent blog post um the that that went up on open AI site said that Elon should quote be competing in the marketplace rather than in the courtroom and the cynical view of course is to say and you've alluded to this in this conversation that Elon who now owns an open AI competitor himself called xai is suing you not out of some concern over AI safety or anything else but really just to get in on the competition what do you say to that you know is this really is the cynical view true is this really just a fight to be the first to dominate the market or you should ask him I hope yeah I hope to I invited him on great you're not just known as one of the most important AI CEOs AI developers in the world you're also a very very well-known proponent of AI regulation and the cynical view here right is that in the very same way that you could cast dispersions on elon's motives you could look at the way that you have lobbied for AI regulations as a way to stifle competition and benefit your company obviously you've heard that argument before I I think too much regulation clearly has huge negative consequences in society right now and many places we have too much I mean Elon has also been a lot of proponent of calling for AI regulation as have as has the heads of most other large efforts when you step on an airplane you think you you know very high likelihood it's going to be a safe experience when you eat food in the US you don't think too much about food safety uh some regulation is clearly a good thing now I can imagine versions of AI regulation that are really problematic and would disadvantage smaller efforts and I think I think that would be a real mistake um but for some safety guard rails on the most powerful systems that should only affect the people at the frontier that only affect opening eye and a small handful of others I don't think we're at the level yet where these systems have huge safety impli implications but I don't think we're like wildely far away either but the argument that some of these startups are making startups like um there's an AI startup called hugging face which is an unbelievable name um the founder of ay company called stability AI they're basically saying what Sam and the other big guys the incumbents are trying to do open aai Google and apple basically asking government to kind of build a moat around you and stifle the competition through regulatory capture what do you say to those people and this is sort of like the the argument between big Tech and little Tech we can frame it in all kinds of ways what do you say to those people who are saying we want to get in on the competition the regulation that people like Sam and others at many other times are pushing for will hurt us and benefit them well if what they're saying is we're behind opening eyes so it doesn't matter and what we're calling for is only regulation at the frontier like only like only stuff that is new and untested but you know otherwise put out whatever open source model you want I don't think it's reasonable for them to make that argument I I I don't know I'm curious what you think if we if we do let's say we succeed and make a super intelligence you know we make this computer program that is smarter maybe more capable than all of humanity put together do you think there should be any regulation on that at all or just they just say none I definitely think first of all I don't even understand what we're talking about when we talk about super intelligence like you understand what that means and the implications of it in a way that I just don't um so that's number one and number two you know if if this technology is as powerful as people like you and Elon and so many others that are closer to it say that it is of course I think it should be regulated in some way how and when is obviously like the relevant question for sure how and when matters a lot but but uh I agree with that and and I could easily see it going really wrong recently Mark andrion was on this show and he talked to me about his perception of what the Biden Administration was trying to do around AI technology he came on and made the argument and told a story really that he experienced he says that the Biden Administration was trying to sort of completely control Ai and what they were aiming to do was to make it so closely regulated by the government that in his words there would only be sort of two or three big companies that they would work with and that they were trying to ultimately protect them from competition is that true do you know what he's referencing was open AI one of those companies I don't know what he's referencing I also will say very very clearly I think regulation that reduces competition for AI is very bad thing that's so openi was not one of those companies no I don't actually know what that's about but it's we've certainly as far as I know have never you weren't in a room ever with the Biden Administration other AI companies no I don't I don't I don't even think like the Biden Administration is competent enough to I mean we were in a room with them but never and other companies in the administration but never like here's our conspiracy theory we're going to make it only you few companies they can build Ai and then you have to do we say never anything like that what was your feeling in general about the Biden Administrations posture toward Ai and Tech more generally you just you just said like you didn't think they'd have the confidence to I think Gina Rondo was is fantastic you know every conversation I had with her I thought she kind of got it um overall I would say the administration was not that effective uh the things that I would most that I think should have been the administrations priorities and I hope will be the next administration's priorities are building out massive a infrastructure in the US having a supply chain in the US things like that when Mark was on I asked him to kind of Steelman the Biden administration's perspective or Steelman the perspective that this should be heavily regulated and he basically drew the analogy to the Manhattan Project and the development of the atomic bomb when the government felt that it needed to make sure that this new science and Innovation remained classified first of all do you think that that's a good analogy and if so if if it is as powerful as nuclear weapons wouldn't it make sense for this to be not open Ai and Gemini and Claud but rather a project of the federal government I think all the analogies are tough cuz they work in some ways and don't work in other ways like you can you can point to things that are similar to the nuclear era you can talk about like you know it takes enormous resources and huge amounts of energy to enrich uranium on one hand or to produce these models on the other um so you can find things like that that work and then the use of one of these models and the use of a new nulear weapon are like quite different things and sort of the geopolitical implications are also quite different things I think to Steelman the argument of people who say things like it's like nuclear weapons I think what they mean is that it's it's extremely expensive and ex has extreme geopolitical consequences we don't know exactly what those are or how to think about them but because we don't know exactly what they are shouldn't we have like a principle of letting the government decide I can imagine other governments at other times in history where we would have we should be very thrilled about that outcome I think putting the current United States government in charge of developing AGI faster and better than our competitors would not likely go well I think the the kind of the decline in state capacity in this country is not a new observation but a mournful one at the beginning of the nuclear age we had people in this country who functioned almost like Chief science officers right I'm thinking about people like vanav Bush who helped launch the Manhattan Project and came up with a National Science Foundation and kind of guided American policy for those first few like very crucial years of n of of nuclear energy does that person right now whether or not they're in DC or not does that person exist like if we wanted to have someone like that who sort of understood the technology had no Financial stake in it and could talk whether it's President Biden or Trump or whoever comes after him sort of the pros and cons not just of the development of AI here but the competition with China like does that does that person exist actually right now in America like could you be that person arguably I think the the willingness it's coming back a little bit but for a long time the willingness of the American public to be excited about future developments in science and technology has been gone I sort of think it went away with the nuclear weapons actually if I had to pick one moment in time there was sort of a you know a weird like few decade hangover before it there was the generational change when the bomb was dropped kind of got older and in power like I don't think America ever embraced the excitement and belief in science and technology driving the world forward to the same degree as as we used to you read these stories about what people like that used to do and how revered they were and how people believed that scientific technological progress more broadly was going to make the world better um that seems missing now and I don't think it's because we don't have an individual who could do that I think it's because the government doesn't want it and the public doesn't want it I mean what do you make of not just the political Vibe shift but the cultural Vibe shift that we've been experiencing since November 5th like if you made that argument to me 8 weeks ago i' would say yeah Sam's probably right now it feels like a different country there's a huge cultural Vibe shift and I think there's a very positive there's positive momentum in many ways I'm not sure that it exists for hey we think science is really important again and science is what's going to save us and you know solve all of our problems do you think that or do you think it's like that's the one area where I haven't felt it I just think that there's a shift in the direction of growth is a good thing technological progress is a good thing nihilism is feels like it's p and falling out of favor like I feel that change happening in a dramatic way now maybe it's because I spend a lot of time on X and like a lot of it's sort of like fomenting there and sort of Leaping from the online into the real world so you know if if you went and like talked to the average PhD student uptown at Colombia I don't think that they would have the same experience I do because everything's so vulcanized as I said earlier I think it is getting better even on S like I I strongly agree with you on the kind of General shift towards excitement about growth and success and having the country and the economy do well um I some I I do somewhat agree as I was saying earlier that I think even excitement about science is in a better place than it's naugher but I when you talk about those people who were like the scientific ambassadors of the country and who people like really listen to and were excited about and you know preach to a willing audience I'm still not sure I feel that I think there's that excitement for business but not for science well one of the companies that I feel excited about um perhaps it's controversial to say this but I just think the founders is one of the most interesting people in the country is Paul mer lucky and his company and um andal Industries and open AI recently entered into an agreement with andil to develop AI with military applications now previously open AI had had a Prohibition against using its technology for weapon now with the caveat of course that you're concentrating on defensive systems at the moment the sorts of things that could you know guard us against attacks like drone swarms perhaps like what's happening in New Jersey right now we don't have time to talk about that what made you change your mind fundamentally about integrating your company's technology um into even a defensive Weaponry system yeah so we have a set of principles that we established and we approved this one for some use cases that comply with those but I think if the leading United States efforts do not help defend the United States and our allies against our adversaries we're going to be in a very bad place and so we need to figure out how to do that a year and a half ago when we were talking part of our conversation was whether or not we were like where the AI arms race with China was I think now it's like well and definitively clear that we are very much in that arms race with China um and you know I think even people who worry about the power of AI in this country feel like well if it's a choice between us and China it's got to be us we got to win spell out for us Sam in your mind because I'm sure you're thinking about this all the time like what it looks like if China wins the AI arms race like what what happens to America what happens to the world whatever China wants and do you think the possibility of that happening is a real one them winning uh I mean we intend to work our hardest to make sure they don't how do we know if they are winning given how much they lie and also steal stuff from us this is the hard thing right we we know what they publicly release we don't know what they don't publicly release um we have a lot of signals and we have a intelligence system but it's my own stance on this is we have got to try to be cooperative and uh arms races are bad for everybody involved we've learned that lesson again and again throughout history but we need to be able to win if we need to I am hopeful that this can be a great moment for world peace and I believe that if there's ever a time for Humanity to come together this seems like a good candidate and I want us to get there but we can't be naive about that President Trump is talks a lot about you know peace through strength is your is the Sam Alman open AI version of peace through strength we have to crush get ahead and win on AI so it's not even a question that China could do whatever it wants not crushes we have to be ahead and then we have to be as willing to work together as possible and I think that is somewhat similar to peace through strength it's like if there's an arms race we'll win it but we don't want to meaning if there's an arms race we want to win but we don't want the arms race period yeah but well it's not even that it's more like if there's any path towards doing this as a collaborative effort we should but we have to be C we can't control what other entities do you mean collaborate with our enemies we collaborate with China yeah actually I'll say that directly I I I think we collaborate with people we don't get along with all the time in areas where it's in our strategic interest to do so and this is one where I think the interests of the world and certainly the mission of our company would dictate that if it is possible to be truly collaborative we should do that are we doing that right now with China on AI like you know more than I do I was going to say you might know more than I like that that will be a big question for the new Administration but that's not going to happen at the company to company level that's going to happen like the presidents at the two countries level if Trump called you tomorrow and said hey Sam I want to make you like aiar AI regulation Chief you can do whatever you want in this position what's the first thing that you would do what's the most important thing that the person in that position would do us infrastructure and supply chain add a little bit more for people that don't know what that means build our own chips here build enough energy to run data centers here change what it takes to build data centers here but be able to like build the very expensive complex supply chain very expensive infrastructure in the United States bias and censorship in AI is a enormous topic and one that we think a lot about here at the Free Press and you know the most obvious example of this the one that trended for days and everyone was laughing at that was when Gemini generated those images of like black George Washington and like a trans naazi and it was hilarious but in a way it was really serious because it felt like only the most sort of like exaggerated hyperbolic obvious example of a much much deeper endemic problem which is the bias that is baked into these Technologies both because of the people programming those Technologies and because of the information that they're sort of scraping online talk to us about how you're thinking about it at chat GPT because obviously the system that is closest to reality it seems to me will will win in the end of the day if if a chat gbt is giving me images of you know he's telling me George Washington was trans I'm like I'm not going to rely on this we don't do that so okay fine but you understand my point how do you think about the problem of bias and how you're solving for it I think there are two things that matter uh one is what flexibility a user has to get the system to behave the way they want and I think or we think there should be very wide bounds like you know there are some things like you don't want a system to tell you how to create nuclear weapons fine we can all agree on that but if you want a system to be pretty offensive and you ask it to be I think part of alignment is doing what its user asks for for Within These broad bounds that Society agrees on the second thing that really matters is what the defaults are so if you don't do any of that which most users don't and you ask whatever controversial question you want how should the system respond and we put a ton of work into both of those things um we also try to write up how the model should behave we call this the model spec such that you can tell if it's a bug or you disagree with us on some stance is it possible to build a like chat GPT or any other technology in this Lane that we can't even conceive of yet that doesn't have a political point of view isn't that inevitable I think no matter how neutral you try to write the thing it will either be useless because it will just say I can't answer that because there's politics and everything or it will have some sort of point of view which is why what we think we can do is write down what we intend for our default people can debate that if there's bugs in there we can look at the bugs if there's problems with how we defined it we can change what the definition is and retrain the system but yeah I don't think any system can be per no two people are ever going to agree that one system is perfectly unbiased but that's another reason why personalization matters so much do you believe that AI or chat GPT has a responsibility to fight pernicious ideas let me give you an example of what I mean like if you knew that by putting your thumb on the scale in the teeniest tiniest way you might be able to usher in a world where there's less racism less anti-Semitism less misogyny and maybe would even be invisible to people because you know they wouldn't know you know at a certain point as we've just talked about this is going to be you know I don't know if this was Mark or somebody else the control layer of all of our information how do you think about that actually here's one thing I've been thinking about recently as a principal like open AI has not adopted this at all but this has just been an idea that I think gets at what you're saying like let's say let's say we discover some new thing where it's like if you do this people learn way better if chat GPT responds always with the Socratic method or whatever students using it learn way better um but let's say user preferences are not to get the socratic message users just say like I just want you to answer my question then like how should we decide what to do there as the default behavior and one idea that I have increasingly been thinking about is what if we're always just really clear when we make a change to the spec and so you'll never have our thumb the scale hiding behind an algorithm which I think Twitter does all the time for example and all sorts of weird things there like We'll always tell you what the behav what the intended behavior is and if we make a change to it we'll explain why but if we do discover something like what you just said uh or like what I just use as an example and we say okay when people are using it for Education we are going to use the Socratic method um because it does seem to have this measurable effect and here's why we're doing it we can debate that publicly maybe we change our default if you convince us otherwise um um anyone can of course change that in their user preferences because the AI is like a tool for you and should do what you want but I think the thing that would be wrong is if we changed that and didn't reflected in the spec and didn't tell people we were changing it um you know I think the like black box of the Twitter algorithm for example it's like doesn't feel good to me Sam you've donated a million dollars to Trump's inauguration and it turned some heads because in the past you've called him a racist a misogynist and a conspiracy theorist among other things you've been a prolific donor to democratic candidates and causes over the years but now you say that Trump is going to lead us into the age of AI and you're eager to support his efforts to ensure America stays ahead is this a change of heart a political Evolution A vibe shift inside of you what's going on all of those things and also I I hope I mean like he's our president and I wish him every bit of success and anyway we can you know work to support this part of what he wants to do we want to do what's the vibe shift inside of you we know that there's one going on inside Silicon Valley and one going on in the culture how have you changed in the past few years I mean a ton of ways but one one is that I uh you know I've watched for the last maybe 10 12 years as I think things have gotten off track things have been good in some ways but I think gotten really off track in terms of how we think about the importance of growth uh and economic success and a focus on the right things in in the country and in the world more broadly and I think it got it got very off track and I'd say the vibe shift is a hope that as we're facing down one of these most most important moments in technological history um that can help drive a VI A vibe shift back to what I believe in very deeply which is that growth is the only good way forward do you think growth and the growth of open Ai and the growth of AI more generally is a patriotic Duty yes I I actually wrote something like I someone just sent this back to I wrote something more than 10 years ago about how growth like I think it's my very first blog post ever about how growth was the central ingredient to democracy working well and I I think the world got badly confused about that and I'm happy to see it re recognized I'm going to use my 30 seconds on a lightning round Sam lightning round what are the Drone things what are the flying objects flying over New Jersey right now I have no idea I'm really interested in this question do you know um no we're reporting on it a lot I find it interesting that various electeds are saying it's the Iran Mothership or China do you think Twitter has become better or worse since Elon Musk took control worse you're having a baby will you will you let your kid have an AI friend yes will you let them go on social media at some point will you let them have screen time yes what's your favorite sports car you love sports cars there's a lot of good ones I can't pick one what's your favorite of yours no I can't pick a single favorite I'm mcar f one favorite movie The Dark Knight do you have any normal Hobbies I like have dinner with my friends I go hiking I like you know exercise I just like sit around my friends doing dumb stuff I I don't know yeah it feels pretty normal you built a treehouse recently why did you do that why' you do that um it was Thanksgiving and uh we looking activity for like the adults and the kids that we all thought everybody was at our Ranch and we want an activity we all thought would be fun and was not just sitting around drinking all day and it was great would you box Logan Paul no will we enter World War II in 2025 I hope not what's your New Year's resolution I know what it does Sam Alman thank you so much for coming on honestly thank you"}], "I played Pokemon, but with 50+ New Types": [{"content": "some of you may have heard but a while back Jacob and their team created a little something called Pokemon too many types it's just a normal game of Pok\u00e9mon Emerald but you might notice some things are just a little bit different everyone has talked about how chaotically fun this game is and I finally found the time to play it myself let me tell you everyone was right this was the most insane backwards chaotic playthrough of Pok\u00e9mon I've had in quite some time Professor Birch is being mauled by a dog in the grass right outside my house for the millionth time and after digging around in his stuff I helped myself to a poo but not just any poo for you see this one is silly obviously I blast the Angi poo to Smither and with that have now earned the freedom to explore the world on my own yep it's Dawning on me that I have no idea how anything works anymore trainers had all these new Pokemon they're pulling out moves I've never seen before types don't line up the way I'm familiar with it genuinely felt like I was playing Pokemon for the very first time again weasel is water fluffy snam is ice Bean Machop is fighting stinky Papio give that thing a shower it reachs up that's super effective I suppose that Mak makes a lot of sense going into this game I decided not to look at the type chart at all which by the way looks like this I'm going to have to unfortunately use my brain and logic to figure out how to win every single battle until I'm the Champion which may be a bit trickier than you would even guess for example this impidimp he has now been turned into a dark gamer Uno reverse type naturally I figured gamer might work similarly to the stinky type and be weak to water that makes sense right all right look I'm I didn't make the game all right guys I'm just figuring out the riddles however let's see what gamer has to say against water type take a shower what it's got what so so here's the logic you got to think about not only is it a gamer type it is an UNO reverse gamer type oh oh yeah of course yeah as much as I might think I know how things would work you're going to witness that it doesn't always pan out the way it seems I scooped myself up a krabby which as you can see is no longer water type and entered the rustboro forest only to be challenged by a te-a grunt with a single snow runt I wasn't worried until I realized the hard way that despite its silliness poo still doesn't like grass and crabs don't mix well with ice wiping this early in a Pok\u00e9mon game is genuinely so humbling and I don't like it at all honestly I didn't even want to tell you that it happened in the first place but we run it back because this isn't a Nuzlocke and my little pets are perfectly healthy after being dunked on this time we sent the grunt hight tailing it back into the bushes despite feeling dumb and stupid and pathetic for wiping to a level 9 Team Aqua grunt with one Pok\u00e9mon I waltzed into the first gym with my chest out like I earned being there as most of you know Rox San is typically a rock type trainer but she's now studied the ways of the ancient type Pok\u00e9mon which I didn't think would be much different until she completely steamrolled me oh I got doggy but doggy isn't going to do too much here God damn it waste of a turn no well her leip is crazy sus ancient grass type how was I supposed to predict that one what even is that now aware of the threat she had in her back pocket it I was able to navigate the rematch with Krabby the fossil killer earning us our very first gym badge also Geodude is boring ugly Rock I just wanted to share that one with the room we took a nice boat ride over to duford where we got to meet lots of new friends in the local cave like clink the prime steel guys and sabaly the gamer who has a little bit of an Easter egg attached to it someone just pointed something out okay will you trade yeah will you move yep yep yep yep yep yep after saying hi and bye to Steven doing who knows what all alone with his cave rocks we headed off to challenge Broly I opened the gym doors and was immediately hit with a wall of pure disgusting stench trying not to physically Decay we crawled through the Gym's Maze and were met by stink Master Broly and his smelly ass team Krabby knocked his Mankey out cold but sock came out and started overwhelming my Pok\u00e9mon one after the other get so much knowledge oh my God like why wouldn't it be so you can imagine I am not happy that this stupid thing is sweeping my team right now luckily the Vulpix I caught earlier was able to tank its hits with its new fluffy type and together with our own little stinker of a stunky we were able to finish the fight I snatched that badge from Broly's greasy hand and basically swam to slate Port myself to wash the fumes off my clothes to dissociate that disgusting experience away I went and caught myself a new friend a ground friend to be specific as well as a little fluffy Stuffle we also got to kick out Team Aqua who was holding the poor slate Port museum lady hostage with a gun thank God they were only armed with a harmless water gun horsey because I do not want to know what dealing with an actual threatening gun type Pok\u00e9mon would even look like battling more trainers on the route up to mville got got me back into the mood to take on the third gym so I shoved Wall-E out of the way and headed up to Watson things started off normal but quickly spiraled out of control because after Sab ey beat up his Porygon Watson immediately brought out his Ace you know his famous star Pokemon whimsicott and this thing just starts spamming its new move called hype train yep Watson specializes in Prime type Pok\u00e9mon which would definitely be a funny little hint hint nudge nudge if I was streaming this on Twitch but alas here we are unfortunately one cannot gift Prime Subs to a YouTube channel sadly all you can do is click the Subscribe button isn't that just a shame well whether you clicked the button or not I got wrecked by this cotton ball hype train works the same as roll out where each consecutive use gets stronger and stronger and this whimsicott must have had some sort of Aimbot on because it didn't miss a single one it literally demolished my team the second it stepped onto the battlefield I was also a bit unprepared and forgot to level everyone up so let's just forget that fight even happened like it wasn't even fair so it doesn't count round two was where the real action was this battle was much more neck and neck knowing what Watson's tactics were going into the fight I was able to play around it much more easily jayen doesn't fall for the same charade more than one time I'm like an AI learning machine all right I never lose the same fight TW I I don't stop no don't look at that with Watson defeated I was now one step closer to becoming the strongest trainer in all of this Topsy Turvy hoen I caught myself a hone Edge swablu and Skarmory while scaling the mountain and even had time to smack the Team Magma nerds around while heading to Lava Ridge to avoid another embarrassing underleveled situation I got everyone up to Flannery's level cap for a nice clean fair fight that's like I think the thing that is hardest for me wow oh God reading comprehension I think that's what I've decided I'm my god oh wow my crabs buddy holy what is the downside of this Mystic fire I'm just so weak to Fire and warm hugs do I have to wipe to every gym plannery she's mean I don't know what that Ninetails is eating but that thing is not normal after changing absolutely nothing about my strategy and just running back into the gym directly from the Pokemon Center I demanded a rematch like her team of fluffy Pokemon aren't that tough I just wasn't ready to be paralyzed and incinerated the whole fight by her puppies and kitties and that roed up monster of a Ninetails this time Kingler and sand slash were able to double team Flannery's fluffy team with much more ease earning us the heat badge with half the gyms now defeated it was finally time to deal with some long overdue Family Matters it's well known that our father Norman abandoned our home to be a gym leader in pelberg leaving me and mom back at the house alone little root has like five people living in it and one of them's a huge nerd that's like a social death sentence for a growing child and I am filled with a burning desire for justice after all this time all those days of having nothing to do but watch Birch go into the same stupid patch of grass and get mauled by the same stupid dog over and over and over I get to walk into Norman's gym and challenge him as an equal whatever reasoning he had to leave us is going to be revealed in our battle and it better be good good I walked through the doors the air was weird and tense each trainer I battled looked at me like they already knew exactly who I was and shifted their glance away out of embarrassment shame what is going on here not even the helpful gym guy had anything to say to me he wouldn't even tell me the type theme of the gym I burst through those final doors to find Norman looking out his windows at the horizon he's been waiting for me all right you ready to fight Norman and his very fun and normal gym have you not picked up on it yet I haven't picked up on anything he say just keep going what is he going to do what What Pokemon do do he have flil okay I don't get it I don't what is this riddle I'm just watching glump is it because he's only using attacks that are acute and family like no lony he can't be a fluffy trainer that was what flanner was cuddle slam no fluffy furry he said is he a furry trainer yes Norman can't a man have hobbies nor look there's nothing wrong with being a furry many of my friends are furries but to abandon your family to selfishly pursue your passion for lucariosklaw board if I was ever going to defeat a divorced man and his beloved furry I switched around some of my Pok\u00e9mon headed back in and again began the onslaught of devastating glumps and cuddle slams weaving through paralyzing warm hugs and even the occasional cute charm eventually it came down to our last Pokemon uh okay slash oh oh no sh sneak please you have a chance here please yes now that my furry father has been vanquished I was filled with an overwhelming energy and drive it was like I unlocked a version of myself that was capable of defeating anyone and everything in front of me I beat up all of Team Aqua that was infiltrating the weather Institute cleared Winona's song and dance gym without breaking a sweat Maxi stole the blue orb to awaken Groudon like an idiot so I had to teach him a lesson again you're going to use the wrong orb idiot why do you think the blue orb would be good for Groudon he hates Blue Team Aqua rats did the exact same thing so I had to do the exact same thing to them I was on a roll it felt like I was back in my element finally familiar with the types and was absolutely thriving we pulled up to tan Liza's gym ready to let nothing slow us down except it looks like they specialize in a type I hadn't seen up until this point space well time to slow down since I didn't have anything that could really handle space Pok\u00e9mon I went and caught myself a Balon because everyone knows ohot type is good against space I mean come on as well as prepared sand slash and stunky for the fight I wasn't too confident but made my way to the gym leader room to find clay what where's ton Liza aren't you supposed to be in you Nova I wasn't anticipating this but I guess I should just start expecting the unexpected from this game it's a double okay it's still a double battle 41 oh we lose we we definitely [Music] lose gun T this is in space wait what the is going on here I don't know what's good against gun how is song sure we'll go do that shoot what the he just shot my my my Goyle he shot my guy again that's so much damage for not very effective we'll do do that oh he's dead he's so dead bare arms oh my God what is this dude this guy's fighting me with the Constitution so this isn't actually a space type gym like I was originally led to believe this is in fact a gun gy and I am being blasted to Kingdom Come by Mr red white and blue over here I failed to expect this level of unexpected but how could I we switched around my team again this time for a high noon dual battle headed back in but honestly it wasn't looking that great on attempt to of fighting a man with assault weapons and air cutter again no no take it take it boy Bo take it stop how can you do this there's nothing I can do about it there's nothing this fight sucks [Music] balls whatever I genuinely think this clay fight was the most out of left field chaotic flabbergasting Pokemon battle I've gone through in my entire career as a Pok\u00e9mon player I don't think anything Pok\u00e9mon could create would ever elicit the kind of shock and despair I felt fighting clay the drift Veil gym leader in my Pokemon Emerald game okay I don't think this is enough yet I just oh he went again sorry that's so lucky oh is this it yes clay you you rooting tooting fing  I'm not talking to you I'm not talking to you get me out of here I basically crawl out the gym with my badge like I just got out of a fight with Wy coyote because I basically did and now I got to go deal with whatever commotion Team Magma is creating in the space station withered and tired I walk up the stairs to Maxi and Steven arguing about God knows what at this point girls girls I'm going to give it to you straight I'm having a bit of a day we all know we're just going to Hash this out in a battle so let's just cut the chitchat Steven get your ass over here and after all of what I just went through you guys are not going to believe what Steven put me through in that cursed Space Center yeah so the first fight I went into it unprepared because I didn't know the team Maxi and friend were packing so that was a bit of an unfortunate disadvantage it's all right we run it back but this is where things go drastically downhill hyper voice Steven you're just leaving me in the The Trenches why even try at this point Thunder oh my fuing God Steven you idiot why do they only go against me why do they only go against me Steven Steven you are theing Elite 4 champion of ho don't use Thunder on Agron it doesn't it in no world is it ever good I swear to God [Music] Stephen you're actually you're actually joking Stephen you're my guy I've always had your back I've been team Steven since day one but what in the world was that this is not the play style of the region Champion buddy get up don't talk to me I need some hair to blow off some much needed steam I infiltrated Team Aqua Hideout because Archie apparently didn't get the memo of my threat of a knuckle sandwich if he ever tried to use red on Blue Kyogre knuckle sandwiches delivered but unfortunately too late Kyogre is already halfway across the Pacific Ocean to go drown Groudon can any of you adults do anything right hello Earth to Archie's brain it's Hollow I scaled the sky Tower to wake up Rayquaza and rat on the siblings duking it out in the middle of suolis off he flew and after a bit of non- gentle parenting the two slink back in their rooms in shame yay Land and Sea across the globe are safe once again if I catch your asses playing with these fing orbs again I swear even though it was the eighth and final gym before taking on the Elite 4 Juan wasn't an issue for some competitors he could have been difficult because he actually ran a full-on crab t team very intimidating but I've also got a crab and my crab is stronger than his crabs so we won after all I've gone through this was the hardest I've had to claw my way to the Elite 4 in a long time but that just means Victory is going to taste oh so much sweeter I entered Victory Road anticipating an easy dungeon clear but from the Shadows emerged Wall-E I've beaten you before I can be you get holy mother okay maybe that one was a bit of a fluke I wasn't ready this time will turns out Wally's tough I didn't expect it but he really is this made me realize I'm not prepared for everything with my current roster of Pokemon and if I'm going to become the champion I need to make some big changes I've been swapping around my team pretty casually over the course of my adventure but after locking in I decided on this as my final roster primarina Kingler AIS slash beware and two new members of darmanitan the Angi fire monkey and duraladon the you guessed it gun look I've seen the power of being able to pull up with a gun I think I'm going to need that in the fights that are ahead of me with these changes I was able to rematch Wall-E and take home the win this time this is it these guys are my team and they're the ones I'm going to become the best with while doing some final training before the Elite 4 there was just a little tiny unexpected hiccup along the way what was that oh my Freddy you would never he would never have to teach it too I'll get rid of earthquake for a bite of 87 five nights what what what the it's Parish song Oh My Freddy what am I turning into you're not like this Freddy for those of you who are unaware five nights is basically an unhinged version of Parish song where after five turns both Pokemon on the battlefield are hit by a 250 base Power Attack and Bite of 87 is straight up a brand new on hit KO move where if you get bit you die instantly but there's only a 30% chance of it actually connecting highrisk High reward Type move equipped with a plethora of new threatening moves and mons my team was now prepared for the final Gauntlet I flashed my badges to the guards and took a step into Sydney's domain I like that look you're giving me let's have a good match as someone once taught me you got to be prepared for the gun Phoebe was up next with her gamer Pok\u00e9mon and even though I was able to take down her team with my loaded deroon and shower giving primarina the highlight of the fight was when she brought out a Freddy Fazbear of her own huge win beware oh it's Freddy V Freddy here it's got to be Freddy V Freddy and you know what Freddy [Music] does oh he got the first one he got it that's mying Freddy right there doesn't miss he hits that frontal lobe everying time I walked into glacia room Larry the third fight was against Larry who normally is a gym leader and Elite for member in Pala but looks like he also works for hoen jeez man three full-time jobs that cannot be legal you got to talk to HR he led with a Golem that only knew stealth rocks and explosion which is chaotically hilarious but right after that he sent out a W of a slacking that took out my duraludon primarina and AIS slash finally Kingler was able to knock it out after pulling off a few Dragon dances sorry crab Raves since I basically had a crab bazooka on my hands Kingler just swept him from there after the Larry jump scare I didn't even know what to expect for the final member it could genuinely be anyone Cynthia red clay butt again what no you're joking he's in theing vent no wait I F facing the wrong way I didn't know that's what happened when you click the VIN from that side I'll be honest Not only was I flashed for simply going about my E4 challenge but Elite 4 sussy Baka and his sus team went dummy mode on me I'm scared so I shoot oh no wait this isn't good this thing's got to go no he's faster he's dead what I thought no where is he oh nice crit no they all vent stop venting well now I guess you get another crab Rave I do no he he avoided it no Krabby I'm sorry a I was not anticipating a battle where their whole strategy was to hide in vents scattered all over the room and when they popped out they hit like trucks not even my five nights attack could hit them in the vents which meant I was just getting my own mons attacked by animatronics admittedly we were vaporized but shut up there's nothing in the rules about trying again it's not a Nuzlocke I refused to call it there because I will not let my legacy end with see that girl she was on her way to become the next hoen Champion but she couldn't get past Elite Four member sashy Boda poor thing the Second Battle went much better because not only was I able to play around all the venting but halfway through the fight Kingler finally learned a better crab move this whole time I was being forced to use 50 base power vice grip but now that we've got 100 base power crab hammer it was lights out for these imposters and with that it was time all that stood left in front of me was the champion Wallace which makes sense because Steven was definitely fired after that Maxi fight out came his first Pok\u00e9mon which was a simple why not now let me explain something here because this thing is far more threatening than you could ever believe this game has introduced so many new types into the world of Pok\u00e9mon many of them are extremely powerful but there's one type that Reigns amongst them all the absolute worst and that's baby type it's pretty self-explanatory which Pok\u00e9mon fall under the baby category Igglybuff cleffa Budu bonley literally the baby Pok\u00e9mon you know what this type is weak to literally like all of them think about it if you hit a baby with anything they're going to be taking damage it's a baby so now you're probably thinking okay so why does the final boss of hoen lead with why not the baby type it's also Uno reverse that's right every single type Effectiveness against this thing is now flipped it's a defensive monster just waiting to counter and mirror coat your whole team to death for simply breathing on it too hard I was genuinely so so scared of this thing I dragon tailed it out of there that's a nightmare for another time his lattos got dragged out which is crazy to say I was relieved to see compared to that masochist of a why not but of course it's still a lattos so it takes out my duraldon with a single Thunderbolt Kingler comes out to finish it off so next came syali which I'll just let you watch how this one played out I don't think I get past this thing what even is this type type Emerald he's a type type type type I don't even know what that is but it's got to be weak to Monkey so type type is more of a modifier than anything it just doubles all type interactions oh  so okay so I die here what so here's a little glitch sometimes uh let's say the max damage you can deal is 999 if the game register doing more it overflows into one HP so this is Dar manit tan died and came back to life basically pretty much yeah well that gives us enough time to Banana Blitz again yeah we take those all right nope I don't want to hear it we take those the next chunk of the battle plays out pretty normally Wallace did have some pretty scary Pok\u00e9mon including Steven's Metagross he very likely lost custody of until I was face to face with this stupid little bomb again it tried everything it could to bait my AIS slash into attacking it but we stayed patient I knew I had a single shot at this so AIS slash charged up as many swords dances as it could muster before slicing that thing to the Moon a final Beast entered the ring a through Abomination called Sans Shedinja this is the only Pokemon in the decks with the Sands type and it can only be touched by a very small selection of types A tried and true nightmare unfortunately for you Wallace I've played the genocide route of undertale I know exactly what it's going to take to bury this thing for good and he's right here it's a beautiful day Sans shinja but insects like you should be burning in [Music] hell I did it the strongest Pok\u00e9mon trainer in this Wacky World of hoen is me it took so much more than I thought it would to be here way more humiliating wipes than I'd like to admit I lost a lot of battles but shut up you try playing it then with the power of friendship logic determination and maybe just a little bit of love we've beaten Pokemon to many types and with that we're pretty much wrapping up on 2024 this was a big Jaden year for many personal and content related reasons and I just wanted to say thank you guys as always for watching after all this time I'm forever grateful for my team and friends who are always supporting me and I'm looking forward to working even harder in 2025 I still can't believe I really just love making videos this much even after 10 years I hope that you'll continue to support me no matter what projects I'm working on next year and I promise to do my absolute best until next time bye-bye"}], "25. Health Economics": [{"content": "[SQUEAKING] [RUSTLING] [CLICKING] JONATHAN GRUBER: So\ntoday, we're going to have sort of a\ndifferent kind of class since it's the last class. Today, I'm going to talk\nabout essentially how we bring to bear the set of\nissues we've talked about this semester to a\nreal-world topic, and actually, how it plays\nout in policy and practice. And I'll draw on some\nof my own experience, having applied the kind\nof tools we learned in 14.01 to the field of health\ncare economics for 25 years, and how that has led\nme to be able to help in the development of health\ncare policy in the US, and talk about sort of where\nhealth care policy stands at this point. So let's get a little\nbit of background about health care in the US. Basically, when we're talking\nabout health care in the US, we have to recognize that\nthe US spends, by far, the most money on health\ncare of any developed nation in the world. We spend about 17 and 1/2%\nof our gross domestic product on health care. That amounts to almost $10,000\nper man, woman, and child-- every man, woman,\nand child in America. That dwarfs the\nrest of the world. The typical European nation\nspends about 2/3 as much as a percent of\nGDP on health care. England spends less than\nhalf as much on health care. So basically, we spend\na lot on health care as a share of our economy. And what do we get for it?"}, {"content": "Well, the evidence here-- the first fact is clear."}, {"content": "The evidence that we get for\nit is a little bit mixed. So if you look at the\ntypical thing on the web, you know, US health\ncare is terrible. Our money's wasted. You'll see that on things\nlike infant mortality, we rate, like,\n20th in the world. Or life expectancy, we're,\nlike, 20th in the world. So by those metrics,\nwe don't do very well. But in fact, those metrics\nare misleading because we also have-- we have the most unequal health\ncare system in the world. So the right way\nto think about it is to think about the\nhaves and the have-nots. The haves, which is us and\nmost people in America, people who are\nwell-insured in the system, actually get probably\nthe best health care in the world, Now that might\nbe disputed by many people. But I think about\nthis like an economist would think about it,\nwhich is, how would you decide whether you would prefer\nproduct A versus product B, whether they buy product\nA versus product B? Every year, one million\npeople come to the US to get treated for their\nhealth care problems."}, {"content": "No one leaves. No one's going to\nEngland for surgery. No one's flying from the\nUS to England for surgery. They're coming here."}, {"content": "If you're in the system, we\nhave the best health care in the world. Unfortunately, if you're\nout of the system, we have some of the worst\nhealth care in the world. So a white baby born\nin America today, there's roughly a slightly\nmore than 0.5% chance the baby will die\nin their first year. That's comparable\nto northern Europe. If you look at a black\nbaby born in the US, the odds they die\nin the first year are about twice that, which\nis worse than Barbados. So the problem in the US is\nnot that our outcomes are bad. The problem is\nthey're very unequal-- that we're spending\nall this money. We're delivering good,\nbut not exceptional, outcomes for people\nin the system and bad outcomes for\npeople out of the system. So clearly, we're not\ngetting a lot of value-- it's not like we deliver\nexceptionally good outcomes to people in the system. We're slightly better,\ndespite spending a lot more, and we're worse for\nmany Americans who are left out of the system. So that's sort of the setup of\nwhere we are, which is really, you have two\nfundamental problems in health care in the US. Our spending is too high, and\nour access is too unequal. Now so I want to focus today's\nlecture on those two aspects and think about how can we\nbring the kind of lessons we've learned in this course\nto thinking about addressing those problems. So I'm going to focus on the\naccess problem and the cost problem."}, {"content": "Let's start with\nthe access problem. Now in America, before 2010,\nwe had about-- or before 2014, we had about 50 million\nuninsured Americans. 50 million people\nwho did not have health insurance in the US. We're the only\nnation in the world-- only developed\nnation in the world with a significant\nuninsured population. Now the fact that 50 million\npeople are uninsured, is that a problem? On its face, if I just\nsaid here's a fact. 50 million people in America\ndon't have health insurance. Based on that fact\nalone, can you tell me whether there's\na problem or not? You shook your head no."}, {"content": "Why not? AUDIENCE: Because it might be\nbetter for you not to have-- JONATHAN GRUBER: Yeah. You know, many more people than\nthat don't have flat-screen TVs and don't own homes. Why do we think\nthat we should care if people don't have something? The answer would be, we\nwould only care if what? Under what condition? When do we-- yeah-- AUDIENCE: [INAUDIBLE] JONATHAN GRUBER:\nIf-- well, they'd be better off if\nthey did have it. Now they could be better off\nbecause they could be richer, but that's not our problem. Given their budget,\nthey're not buying it. What-- under what condition\nis the market not-- under what type of conditions\nwould the market not deliver the best outcome? AUDIENCE: If there's\na failure, like-- JONATHAN GRUBER: If\nthere's a market failure. So the fact that\npeople aren't insured doesn't matter except A, if\nthere's a market failure, or B, for redistribution purposes. Remember, that's\nthe two reasons we want the government involved. So if health insurance markets\nwere perfectly functioning and people who were\nuninsured were roughly equally distributed in\nincome as everyone else, there'd be no cause for worry. But in fact, that's not true. We've talked in\nthis class about why markets like health insurance\nwon't function well, which is a problem\nof adverse selection. The problem is\ninformation failures which will lead health insurance\nmarkets not to function well. And the people who\nare uninsured tend to be much poorer than the\npeople who are insured. It's also\nredistributional concern. So the reason we care\nabout the uninsured are both because\nof market failures and for redistribution, that\nthey tend to be lower-income. What's interesting\nis the uninsured don't tend to be the\npoorest in society. They tend to be the near poor. So here's the way sort of\nhealth insurance coverage works in the US. For the vast majority\nof Americans-- 60% of American-- 60% of Americans\nhave what's called employer- sponsored insurance. So like your most\nof your parents, like me, they get health\ninsurance from their employer. The typical upper-income\nAmerican gets health insurance from their employer. The typical average-income\nAmerican does. About 60% of Americans. Then-- and I'm going to\ndo this sort of pre-ACA. So before 2014,\nbefore the big change that was put in place by\nthe Affordable Care Act, you had about another,\nmaybe, 6% that bought into what we call\nindividual or non-group health insurance. That is, they went out on\ntheir own and bought insurance. But that's a tiny\nmarket compared to ESI. And the reason is because of\nexactly the adverse selection problem we talked about. Think about yourself\nas an insurer. And you're worried about\nyourself as an insurer. And think about\nwhat your goal is. Your goal as an insurer\nis to essentially absorb risk in a way that allows\nyou to make a profit. So what you want is\nyou want to live off the law of large numbers. You know that with a\nlarge enough group, you could be able to predict\nwhat their costs will be. And therefore, you can\njust make a profit on top. So insurers love-- when\nMIT comes to an insurer, they're delighted. They're like, look, you got--\nbetween MIT and Lincoln Labs, you've got about\n10,000 employees. I, with great\ncertainty, can predict what the costs will be next\nyear for a group of 10,000 employees. And so I, as an\ninsurer, can know I can just charge that, plus\nX percent, and I'm golden. But when Jon Gruber\nwalks in the door, they're like, why are you\ncoming to me, individual? Maybe because you know\nyou're sick, maybe because you love skydiving. I don't know."}, {"content": "But I'm wary of you, so I'm\nto charge you a lot of money to get health insurance. As a result, most-- very few\npeople bought health insurance on their own. And in particular, the\nreason they didn't is because insurers would not\noffer health insurance to people if they were at all sick. They would do things\nlike having what we call pre-existing\nconditions exclusions. These were features of insurance\ncontracts which said, look, you walked in the door, Jon,\nand you want health insurance. But I know, in the past, you've\nhad cancer or asthma or knee surgery. I'm going to tell you,\nI'm going to insure you, but not for any expenses that\nmight arise from recurrence of those past injuries. So you had cancer in the past. Anything that comes up in the\nfuture because you had cancer, I'm not going to cover. Anything that comes\nup in the future because you had knee surgery,\nI'm not going to cover. Anything that comes up in the\nfuture because you had asthma, I'm not going to cover it. So I'm going to give you,\nessentially, partial insurance. So it's going to be\na market failure. I'm going to insure you, but\nonly for part of what you need. Alternatively, they could\nuse pre-existing condition solutions-- they could\nuse what is called medical underwriting,\nwhich was basically saying, OK, Jon, come in. I'm going to give you an\nexam, and if you look sick, I'm going to deny you insurance. Or if you look sick, I'm going\nto charge you 100 times more than someone else. So these were not\nillegal or even immoral. These were just ways\ninsurers came up with to try to deal with the\nadverse selection problem. As a result, this\nwas a market that did not function very well. Question about that? AUDIENCE: [INAUDIBLE] JONATHAN GRUBER: No, totally\nlegal in every state-- virtually every state,\ntotally legal and not immoral. I mean, this is just they're\nmaximizing their profits."}, {"content": "It's what companies do. And the point is that when\nthey did this, what this meant was if you didn't have\nemployer-sponsored insurance or insurance from the\ngovernment, which I'll come to next, then you\nwere subject to the fact that if you got\nsick, you might not be able to get insurance,\nwhich is sort of weird. Insurance is supposed\nto cover if you're sick. But in fact, if\nyou were sick, you might not be able to get it. So that was the fundamental\nmarket failure we had here through adverse selection. Now we also-- that was\nemployer-sponsored insurance, so that was about 2/3\nof the population. You also had on the order\nof 15% of the population had government-sponsored insurance-- probably more like 20%. 20% of the population\nhad government-sponsored. Insurance. The two big programs here are\ncalled Medicare and Medicaid. Now if you ever\ntake my 1441 class, I will only hold you\nresponsible for one thing if I ever meet you\n10 years later, which is remember the difference\nbetween these two programs. Medicare is health\ninsurance for the elderly. Medicaid is health\ninsurance for the poor. And those are our two big\npublic insurance programs. And about 20-- and if\nyou're in those programs, you're also set. They don't have any\nof these features. If you're in, you're\ncovered for everything. So about 20% of\npeople are there. And then finally, if you add up\nthe numbers, we had about 15-- the numbers don't quite add\nup, but you had about 15% of the population was uninsured. 15% uninsured. So you had about 2/3 private,\nabout one fifth public, and about one sixth uninsured. And those are individuals\nwho typically were not the poorest because the\npoorest people got Medicaid. The typical uninsured\nperson is, like, what we call the working\npoor, someone who's got a job, but it's a crappy job that\ndoesn't offer health insurance. But they make enough\nmoney that they can't qualify for being\nin the low-income program. So your family is struggling at,\nlike, $40,000, $50,000 a year, high enough income\nthat they're not qualifying for Medicaid but not\nin a good enough job they're getting health insurance. That's your typical\nuninsured family. 2/3 of the uninsured\nare in families that are headed by a\nfull-time, full-year worker. They're not typically the\nunemployed down-on-their luck people. They typically\nare the people who are trying to play by the\nrules, as they say in politics, but typically can't get a\njob with health insurance. So that's your basic landscape. And what we know\nfrom that landscape is that a lot of\nthe access problems were because of this\ngroup and this group because the people who couldn't\nget in this market, and as a result, were often uninsured. That was a lot of what\ndrove the access problems. So that was sort of the first-- one of the two big problems\nthat faced our system. And for many, many years,\nwe knew we had that problem. And for about 100\nyears, we've tried to reform health care in\nthe US to deal that problem. And probably about\nevery 17 years, on average, there was a big\nattempt to reform health care, and they always failed. And they always\nfailed because they failed between two extremes. There were two extreme\nviews that could never quite meet in the middle ground. And they come to what I\ntalked about last time, which is how do we solve the\nproblem of market failures in insurance markets? Well, one version of\nsolving that, I described, was subsidization. You could-- remember,\nwith my MIT program, if I paid the healthy guys\n$500, they'd all buy two, and I'd solve the problem. So one version\nwas subsidization. The problem is\nsubsidization only works if it's big enough to\novercome these problems. And no one ever proposed\nsubsidization big enough to overcome these problems. In my MIT example,\nI was going to give $400 to every\nhealthy-- first of all, it means giving money\nto healthy people, which is sort of\npolitically difficult. Like, hey, the healthier you\nare, the more money you get. It seems a bit weird. Also, it's just hard\nto solve these problems by just subsidizing people. Insurance companies\nare still too good at trying to get\nrid of the sick people. And even if you subsidize\npeople who come in, insurance companies will\nalways have an incentive. They'll say, great, healthy\npeople come, we'll subsidize. They'll still want\nto avoid the sick. So it doesn't solve the\nproblem in insurance companies. I didn't talk about\nthis last time, but as MIT's\ninsurance company, I should try to shed\nthe sick people. And that problem still\nexisted under this solution. The other extreme, which is\nsort of back in style again, is the single-payer model,\nwhich is saying, look, let's just have the government\nprovide health insurance to everyone. We have the government provide\nSocial Security to everyone. The government provides\nhealth insurers to every elderly in\nAmerica through Medicare. Everyone over 65\nin America, boom, gets government-provided\nhealth insurance. Talk about socialism. Every American gets that. In Canada, everybody gets\ngovernment-provided health insurance. Why not just do it here? Let's get rid of all the\ncrap with insurance companies we don't like. After all, insurance\ncompany administrative costs are about 15% of\nmedical spending. So, boom, we could lower\n15% of medical spending. That is, you know, that's\nlike $500 billion a year. Boom, it's gone. So basically, why not-- so\nsingle payer is something a lot of people\nhave advocated for. Let's just have one giant\nuniversal health insurance program. Now the problem with this-- the problem with the\nsingle-payer approach is largely-- there's pros and cons to\nthe economics perspective. But the problems here\nare largely political, which is that to make\nsingle payer happen, you have three enormous\npolitical barriers, which come back to economics. Everything comes\nback to economics, but they play their way out\nin the political system. The first problem\nis paying for it-- paying for it, which\nis that single payer-- to have the government give\neveryone health insurance means a massive expansion\nin the government, which means a big increase in taxes. And we know taxes\nhave deadweight loss."}, {"content": "We know taxes are\npolitically unpopular. Now here's what's\nmisleading about that."}, {"content": "Here's the fundamental thing. So I worked for the\nstate of Vermont. The state of Vermont wanted to\ndo their own single-payer plan. If any place can do\nit, it's Vermont. They're, like, super lefty. They essentially have\none insurance carrier, which is Blue Cross anyway. They're a small state. It seemed like if anyone\nwas going to do it, Vermont was going to do it. So I worked with them to\nput the numbers together, what it would cost them. And I had good\nnews and bad news. The good news was,\nI said to Vermont, if you do single payer you will\nlower the cost of health care in Vermont total by at\nleast 10%, at least. That was conservative. The bad news is to\npay for it, you're going to have to more than\ndouble the entire amount of taxes collected\nin state of Vermont. And that second sentence\njust killed everything. What's the problem? The problem is that right now\nhealth insurance in America is paid for by\nessentially a hidden tax. What's the hidden tax? It's the fact that when\nyour employer gives you health insurance, they pay\nyou less wages as a result. Remember our tax\nincidence discussion. And we said that essentially\ntaxing the employer falls on the\nemployer-employee depending on basically elasticities. Well, you can think of health\ninsurance the same way. When your employer gives\nyou health insurance, he doesn't just\neat the whole cost. He says, look, I'm paying you\na total set of compensation, part of which is\nhealth insurance. So I'm going to pass the\ncost of that health insurance on at least partially\nto your wages. That's essentially a hidden tax. So at MIT-- right now, I\nhave a health insurance plan through MIT, which costs about\n$18,000 a year for my family. I pay about $6,000 a\nyear out of my paycheck. MIT pays $12,000. But the truth is, MIT\npays me $12,000 less. They don't just give me\nthat health insurance out the goodness of their heart. They take it out of\nmy wages, or least partially out of my wages. That's essentially a hidden tax\nthat Americans pay every year to finance health insurance. If we went to single payer,\nthat hidden tax would go away. I would get a $12,000 raise. That's great. But I'd also face\na high new taxation to pay for the\ngovernment-sponsored plan. Now given that the total\ncost would fall-- we should be able to net this out\nin a way that most people win. The problem then\nbecomes the politics, which is you're tracing a hidden\ntax with a non-hidden tax. And that's very\nugly politically. So people don't believe their\nemployers will pay them more if you don't make the employers\nprovide health insurers, like, oh, the employers\nwill just pocket it. And I could teach them tax\nincidence till my face is blue, but they just won't believe it. They'll say employers\nwill just pocket it. But I have to pay this\nnew tax for single payer. So that's the first\nproblem single payer faces is that people don't\nreally understand that trade-off between\ngetting rid of the hidden tax and adding a new non-hidden tax. That's problem one. Problem two is the problem\nwe talked a little bit about, behavioral economics,\nand about loss aversion. There's a general feature,\nwhat we call status quo bias in human thinking. Status quo bias, which\nis, essentially, it is harder for me to\ngive up what I'm used to than to grab something new. We talked about the mug example."}, {"content": "Remember, I talked about mugs. So basically, you\nhad to pay me more to get the mug away from me than\nI was willing to pay to buy it. That once you have something,\nyou value it more than if you didn't have it yet. Well, right now,\n60% of Americans have employer-sponsored\ninsurance. And if we say to them, give\nthat up for Berniecare, they're going to be,\nlike, eh, I don't know. I kind of like my\nemployer-sponsored insurance. You know, yeah,\nyou might tell me Berniecare is\ngoing to be better, but that's just you talking. I know what I have\nright now, which I have employer-sponsored insurance. I don't want to move away\nfrom that status quo. So status quo bias makes\nit hard, in general, to do radical changes\non an economic system. And this is a perfect example. It's going to be hard\nto get people to give up what they have for something\nthat they don't really know about yet. That's the second problem. The third problem is,\nonce again about money, but really beyond the\nscope of this course, which is the problem of the insurance\ncompanies and lobbying, which is that the insurance business\nis big business in America. Health insurance companies\nmake about $900 billion a year. If you said to them, hey,\nhealth insurance companies, would you guys mind just\ngiving up your $900 billion to begin a single-payer\nhealth care, they'd actually say, yeah,\nit's been a good run. Go for it."}, {"content": "No. They're going to lobby and\nfight that because they want to keep their business. And that's going to be a\npretty hard force to overcome. So single payer has\nalways struggled with dealing with these\nkinds of political problems. And that's why we've been stuck. We've been stuck between\none alternative, which is subsidization, and the\nother alternative, which is single payer. And that's where\neconomists have come in-- came in the 2000s,\nfolks like myself, to talk about a\nnew alternative way to do it, which was\nessentially to try to bring in some of the\nbest features of these two approaches. And the solution we proposed-- so if you want to\nread more about this, I've actually written a\ncomic book to explain it."}, {"content": "It's a graphic\nnovel, technically. It's called Health Care Reform. It's, like, $9 on Amazon."}, {"content": "And so I like to think of\neverything in terms of images. Now I'm not going to draw one."}, {"content": "I'm not going to try\nto draw anything. But the way I like to think\nabout this is the solution we came up with, which we first\npioneered here in Massachusetts and then brought to\nthe whole country through the Affordable\nCare Act, is what we call a\nthree-legged-stool approach, three-legged-stool approach. Leg one is deal\nwith this problem. Deal with the insurance\ndiscrimination problem. And so leg one is ban\ninsurer discrimination. No more pre-existing conditions,\nno more medical underwriting. That is, if I walk in the door,\nand you have offered anyone-- you have to offer me health\ninsurance at the average price for my age. And you have to offer it to me. So any 40-year-old who walks\nin the door wanting insurance, you have to sell it to them,\nand you to sell it to them at a fixed 40-year-old price. You can't say, you're sick. I'm not going to sell it to you. So the first step is to\nban insurer discrimination, to try to solve that problem. Now the problem this\nraises is you have simply-- if you do this alone, you've\ncreated a new problem, which is if you tell insurers\nthey can't discriminate against the sick, you don't\nsolve the adverse selection problem. You're just making\ninsurers go bankrupt."}, {"content": "Now here's the way I\nlike to think of it. I'm sure none of you\never gambled on sports. But if you had\ngambled on sports, you might know the way\nsports gambling works is that there's a guy in the\nmiddle, called the bookie. And the bookie's\ngoal is to not-- is to get exactly the same\nnumber of bets on either team. So they take no risk, and just\nmake their profits off the top. So what bookies do is\nthey set point spreads. So the Patriots played the\nDolphins this past weekend. I am-- sadly, I'm\na Dolphins fan. The Patriots played\nthe Dolphins. The point spread was\nsomething like-- does anyone know what the spread\nwas in the Patriots' game? I think is was, like, 8 points. So that spread was chosen. The Patriots were favored by 8. What that meant was\nyour bet was either the Patriots win by either\nmore, or the Dolphins win, or the Patriots win by\n8, or by less than 8. So one side is Patriots\nwin by 8 or more. One side is Patriots win by\nless than 8, or Dolphins win. And the reason you\nhave that bias thing is because people think\nthe Patriots are better. They are better. And as a result,\nyou want to get-- if you set an even bet,\nPatriots win, Dolphins win, everyone would bet\non the Patriots. You'd lose money. So you want an equal\ndistribution of risks. So what you want is you\nwant to set the point spread so the distribution\nof risk is equal. Then having done that, you just\nmake your money off the top. Now imagine I passed a law\nwhich said all sports books have to reopen at halftime and make\nthe same bets available they made before the game started. Well, for those of you who\nwatched the exciting game this weekend, you\nrealized at halftime, it became pretty obvious\nthe Patriots weren't going to win by 8, that\nit was a lot closer game than people thought. So if they reopen\nthat, a bunch of people would suddenly bet\nagainst the Patriots. The Patriots ended up\nlosing, and the insurers would have gone bankrupt-- the\nbookie would've gone bankrupt. Insurers are just bookies. That's all they are. They just want a predictable\ndistribution of risks. So if you tell them, you have\nto offer health insurance to everyone for the\nsame price, but only the sick are going to buy,\nthey're going to lose money. So that's why we need the\nsecond leg of the stool, which I talked about last time, which\nwas the individual mandate. The individual mandate,\nwhich is to say, OK, insurers, if you offer\nhealth insurance to everyone at a fair price, we will,\nas our part of the deal, make sure everyone\nbuys health insurance. So when the 40-year-old walks\ninto your office wanting insurance, you can know it's\nnot because they're sick."}, {"content": "It's just because they have to. So we say to insurers, you\nprice insurance fairly, and in return, we'll\nmake sure you get the fair distribution of risks. So you say to me--\nmy MIT insurance, you price insurance\nat $1,500 and don't try to keep out the sick,\nI'll make sure everyone buys. And you'll make\nyour $100 profit. So that's-- the mandate was\nessentially trying to bring-- was trying to allow--\nget rid of discrimination by bringing in the\nentire pool of people so insurers could fairly price. The problem with that is you\ncan't mandate something people can't afford. So in Massachusetts,\nwhere we were creating this plan\nin the mid 2000s, the typical family\nhealth insurance policy was about $12,000 a year. The poverty line for a\nfamily was $22,000 a year. We couldn't exactly\nmandate people that they spend 55% percent\nof their income on health insurance. That was not really feasible. So the third leg of the\nstool we came up with is subsidies to make health\ninsurance affordable, saying, if you're\nlow-income, we will offset the cost of your insurance just\nlike the subsidy approach here. We'll offset the cost\nof your insurance to make it more affordable. We'll do it on an\nincome-related basis, so it doesn't cost so much. So we're not going to\nhave to pay for everyone's insurance like single payer. Remember, single payer,\nessentially taking someone like me, who's\nhappy with my insurance, swapping it out for new\ngovernment insurance. This is saying, no, if you're\nhappy with your insurance, stick with your insurance. But if you're low-income and\ncan't access the employer market, this gives\nyou a new place to go. And that was the idea\nthat became Romneycare, the plan here in Massachusetts,\nand eventually then became Obamacare, or the\nAffordable Care Act. So this is essentially\nthe idea of that plan. Now, did it work? Unambiguously, yes."}, {"content": "Now you won't find\nanyone more biased than me on this question. But I think what-- I think if I've tried to teach\nyou one thing in this class, it's that we need to rely on\nreal facts wherever possible. And if not, we could\nturn to theory. But here we have a set of real\nfacts that we can turn to, which is that\nessentially what we did in Massachusetts with this\nlaw is we covered about 2/3 of the uninsured population. At the federal level,\nwe covered about 45% of the uninsured population. It was a lower number because\nthe federal law did not apply to undocumented\nimmigrants, which are about a quarter\nof the uninsured. It's not an issue\nin Massachusetts, but a big issue in other places. That's about a quarter\nof the uninsured because the federal\nlaw did not apply to undocumented immigrants. So as a result, the\nshare cover was lower. But a large number\naren't covered."}, {"content": "Yeah. AUDIENCE: If there was\nan initial mandate, then how was there anyone\nwho was left uninsured? JONATHAN GRUBER: Great question. So there are three reasons why\npeople were left uninsured. The first reason was a\nquarter of the uninsured were undocumented\nimmigrants, and the law didn't apply to them. So right now the upper bound\nwas 75%, just to start. The second reason is that the\nindividual mandate contained exemptions to make it both a\nlittle more humane and, quite frankly, politically feasible. So if you could not\nget-- if your income was below the poverty\nline, you were not subject to the\nindividual mandate. And if you could not get\ninsurance for less than 8% of your income, you\nwere not subject to the individual mandate. So there were exemptions. And the third thing was\nthe individual mandate was not, like, we're going\nto throw you in jail. It was a tax penalty. And many people decided they'd\nrather just pay the penalty than buy health insurance. So for those three\nreasons, a number of people did not get health insurance\nunder the Affordable Care Act. Now there's a bunch of\ninteresting questions, like should the mandate\npenalty be bigger? How should we handle that?"}, {"content": "There's a lot of-- I could go for hours on this. But that's basically the\nstructure of what we had. So basically, that worked. It didn't get us to\nuniversal coverage. It wasn't as effective as\nsingle payer would have been, but it was the largest\nsingle insurance expansion in American history. And the evidence is clear. It brought many\npeople into insurance. It improved people's\nuse of health care. It improved health. So basically, that was kind\nof the step forward on access. Now the problem with\nthis is it's only a step. There's still many\nuninsured, and this has been politically really\nchallenging, because these two answers are quite simple. Just give people money or\njust have single payer. This is super complicated."}, {"content": "I can talk about these\nin about 15 seconds each. These took five\nminutes to go through. And people thought it\nwas just too complicated. It didn't make sense. Lots of reasons-- we could\ntalk lots reasons people didn't like it. So it's never really been\nas politically successful as people like myself,\nwho helped develop it, would have hoped. And it's left a lot\nof people uninsured. So we haven't solved\nthe access problem. We made a big step forward,\nbut we haven't solved it. And that's the ongoing debate\ntoday we see, particularly in the Democratic Party. The Republican Party\nreally doesn't focus much on insurance coverage. But the Democratic Party does. And they're-- that's why there's\na lot of energy behind single payer right now is like, look,\nyou tried the kind of halfway ground. That kind of worked, but\ndidn't work all the way. So let's just go all\nthe way to single payer. Yeah. AUDIENCE: The initial\nmandate, does that-- I guess, for the\nmore people living in poverty, does that work\ntogether with Medicaid or-- JONATHAN GRUBER: Yeah. Basically, a lot-- actually,\nit's quite interesting. It worked quite\nwell with Medicaid. A lot of people\nwho aren't insured, actually, are people\nwho are already eligible for free\nMedicaid coverage and just don't take it. Now we don't quite know why."}, {"content": "It could be language barriers. They don't understand. A lot of people-- a lot\nof even legal immigrants just don't understand\nthey're eligible. It could be people just don't\nwant a government handout. They're embarrassed taking\nhelp from the government. It could be people\nthink, I don't need it. I'm never going to be sick. We don't know why. So part of what\nthe mandate did was say, look, you already\nhave free health insurance. Just pay attention and take it. That's part of the effect it\nhad was bringing people in. So a large part of\nthe coverage increase is actually bringing in people\nwho were already eligible, just weren't taking it up before. So that's kind of where we are. So where we stand\nnow in coverage is we've taken a\ngiant step forward. We've covered probably\nabout now, probably, between a third and 40% of\nthe uninsured in America. But we're sort of right now\nkind of stuck at that point. And the question is, do we\njust sort of stick there, or do we try something\nmore aggressive? With the political\nproblems, I don't know."}, {"content": "But that's going to be the\nchallenge going forward. So that's-- questions\nabout that-- because that's where we\nare on problem number one, which is access in coverage. Now let's turn to problem\nnumber two, which is cost. Cost is way harder."}, {"content": "What I just did\nwas the easy part. It's way harder to get\nyour health care costs, and here's why. Two facts that are seemingly\ncontradicted if you think about it. Fact one. Since 1950, US\nspending on health care as a share of our\neconomy has quadrupled. We've gone from--\nmore than quadrupled. We've gone from 4% of our GDP\nbeing health care to over 17%. And it's been worth it. If you look at the\nimprovements in our health, and you value them in\nthe way economists do, which is we have statistical\nvalues of life we apply, or statistical values in\nimprovement in health, the improvement\nin our health has been worth the money\nspent on health care. You guys don't realize it. Health care totally\nsucked in 1950. Babies born in 1950 were\nfour times as likely to die before they reached\ntheir first birthday. If you had a heart\nattack in 1950, you were four times likelier\nto die within the first year. To put it in terms all young\nhealthy people care about, if you hurt your knee skiing\nin 1950, tore your ACL in 1950, or tore your cartilage, you\nwere in the hospital for a week. You were on crutches\nfor six weeks and had arthritis the\nrest of your life. Today, you go to an\noutpatient center. You get arthroscopic surgery. You're back on the slopes\na couple weeks later. Health care is just way better,\nand our health is way better. America is a much better off\nnation, spending 17% of GDP on health with how healthy\nwe are than we were in 1950. And once again, do\nthe economists tests. No one ever advertises, hey,\nwould you like 1950s health care at 1950s prices? No one out there is offering\nthat because it's worth it. That's fact one. Fact two is we waste a huge\namount of money on health care. By some estimates, about a third\nof what we spend on health care is totally wasteful, does\nnothing to improve our health. Now how can those two\nfacts be consistent? It's worth it,\nbut it's wasteful. Well, the answer is that the\nother 2/3 is super awesome, that basically the\nincrease in health care, where it's been productive,\nhas been amazing. But we dragged along all this\nunproductive spending too. So it's good news and bad news. So the good news is,\nwell, that's great. We just cut out the one\nthird that's unproductive, we've solved our problem. Literally, if we could\njust simply cut out the one third\nthat's unproductive, we'd spend the same amount as\nEurope does on health care. We'd solve our entire\nlong-run fiscal problem. The bad news is that it's\neasy to look back and see what the one third was. It's hard to look forward and\nsay what it's going to be, that health care comes with\na huge amount of uncertainty about what's going to work and\nwhat's going to be worth it. And as a result, it is\nvery hard to say, OK, fine. We'll cover this. We won't cover\nthat, because it's hard to know what's going\nto work and what's not. And so, essentially, you're\nin this very difficult spot. So what are the\nkind-- that's the sort of fundamental\ntrade-off that we face. So what are the potential\nsolutions to this problem? So essentially, there's a\ncouple of different solutions to the problem, two different\npaths we can follow. Path one is the regulatory\npath, which is basically the path that Europe follows. What Europe does is they\njust much, much more heavily regulate the delivery\nof health care. And they do that in two ways. One is they actually have\nregulations about what health care you can get. So for instance, England has\nthe euphemistically named NICE, the National Institute for\nHealth and Care Excellence, which actually tells people\nthey can't get some things. It literally rations. So for example, for many\nyears-- it's no longer true-- in England, if you're over 75,\nyou could not get a transplant. They said, look, we got a\nlimited number of kidneys. You're going to die soon anyway. Let's give the kidney\nto a young person. Actually, kind of makes sense. The idea is, look, we have\nsome limit on our kidneys. Why should it be determined\nby some random fact, like when you got on line? It should be\ndetermined by who gets the most value from the kidney. It's going to be someone who's\n30, not someone who's 75. So one regular route\nis to literally have regulations like that. That's actually pretty rare. Most countries don't actually\nregulate in that way. Most countries kind of let\nyou get what your doctor says you should get. There's three routes."}, {"content": "So one route is\nsort of regulatory. The other route of regulate--\nso one route is sort of what we call sort of\nregulating, you know-- I don't want to call\nit access-- sort of technological regulation,\nregulating which technology you can get. The second kind of regulation\nin Europe is supply regulation. So they basically don't\nlet there be many doctors. And there are not many\ndoctors and hospitals. So there are as many\nMRI machines in LA as there are in Canada. Basically, just not many place\nto go get an MRI in Canada. So if you' hurt\nyour knee in the US, you go, you get an MRI,\nlike, the next day. In Canada, you get\nit six weeks later. So the only way to control\nit is to actually regulate the supply of medical care. Just give people less\nstuff they can use. And the third way to control-- the third regulatory mechanism,\nand the most important, is price regulation. We are the only nation in\nthe world which essentially lets the free market determine\nthe price of health care services. Every other nation\nregulates the prices that people pay for their\nhealth care services. Now the question we\nhave to ask is why? Why does that make sense? Well, the answer would\nbe that we think-- it would make sense if we think\nthere's a fundamental market failure in the determination\nof health care prices. And in fact, it\nturns out there are numbers of market failures in\ndetermination of health care prices. So one market\nfailure, for example, is imperfect information. I don't know-- I can't shop\neffectively-- when I'm in the back of the ambulance\ndying from a heart attack, I can't be, like, you know\nthat hospital looks expensive."}, {"content": "Take me over there. I want to shop there. You can't really shop. It's a hard market to shop. And if you could,\nprices aren't posted. You don't really\nknow what it costs to get your heart attack\ntreated in different places. So imperfect information. There's also\nimperfect competition, which is if you have your\nheart attack on Cape Cod, there's, like, one-- or Nantucket, which is\nan island, with no way off but a ferry,\nthere's one place to go. There's one hospital. They have a perfect monopoly. You can't get off the island. You're going to die otherwise. So it's imperfect competition. There's even\nimperfect competition where you think the\ncompetition might be perfect. So take Boston. There are so many\nhospitals in Boston, you cannot literally fall down\nwithout hitting a hospital. Yet there is an\nenormous dispersion in the prices hospitals charge. In particular, the\nvery famous hospitals, like Mass General\nHospital, charge multiples of what less\nfamous hospitals charge, even though less famous\nhospitals are really nearby. Why? Well, because they\nhave essentially what we call a reputational\nmonopoly, that even though they don't have an actual physical\nmonopoly, people are like, I want to go to MGH. They're the best, even if\nthey're not necessarily the best. They just have this\nview of being the best. And they can charge\nhigher prices as a result, even if their outcomes\naren't necessarily better. In other markets, we\nthink perfect information would allow us to get rid of\nthese kinds of inefficiencies. It doesn't exist in health care. As a result, perfect\ncompetition simply does not work in\nhealth price setting. And as a result,\nall other countries regulate health care prices--\nand then not other countries-- even the US can\nregulate health prices. So the Medicare program\nhas regulated prices. That covers millions\nof Americans. It's just for the\nnon-government, private health insurance in the US, there's\nnon-regulated prices. Now I am not, despite my tone,\nsaying that regulating prices is the answer. It's not clear. Regulating prices comes\nwith a huge number of additional problems\nlike we talked about. We talked about\nregulated monopolies, which is the government may not\nknow the proper price to set. The government may\ndo a terrible job. They may get lobbied. They may be corrupt. Indeed, in the US, the\n1970s, virtually every state did regulate hospital prices. And every state\nwent away from that because they thought\nthe system was broken. So it's not like\nthere's any-- it's not like the European\nsolution's an easy answer. That's why the other route that\npeople have been pushing lately is a different route, which\nis the incentives route, which is basically to say,\nlook, we don't want to regulate supply or prices. What we're going to\ndo is we're going to say, doctors and\nhospitals, you get together and form these units we\ncall Accountable Care Organizations, ACOs. This is a big innovation\nof the Affordable Care Act of Obamacare, set up these ACOs. These are hospitals and\ndoctors all get together to be basically,\nlike, soup to nuts, all the health care\nyou need in one group. And we say to them, we are\ngoing to pay you one flat amount of money to care for Jon. And then within that,\nyou decide what he gets. You decide what prices\neverybody pays and makes. You figure all that out. But we're going to\ngive you a flat amount. In particular, that flat amount\nis not going to rise much. And that's going to bring\nthe costs of health care under control, where\nbasically every ACO will get an amount that's\na flat amount, and it just won't rise much. And that's how we'll\nbring health care costs under control. That has a number of\nwonderful features. First of all, it's\nmuch less evil sounding than things like\nnot letting [INAUDIBLE] rise or regulating what prices. Second of all, there's much\nfewer regulatory tools. We just say, here's a flat\namount we're giving you per person, and we're done."}, {"content": "So that sounds great."}, {"content": "The problem is we haven't\nbeen able to get it to work. And that's because it turns out\ndoctors and hospitals aren't very good at figuring out how\nto set prices and set supplies. They're just not--\nthey don't know how to really figure this out. And the ACOs so far have not\nactually performed very well. They've not saved much money. So really, we're stuck\nbetween a route which seems a lot easier but we\nhaven't really figured out how to make work,\nand a route which has worked all around the\nworld but seems politically nightmarish. And that's kind of\nwhere we are right now in terms of controlling costs. And that difficulty is\nwhat we find ourselves in. But let me be clear. This is not like, oh, that's\nvery interesting, Jon. I'll go home and\nforget about it now."}, {"content": "This is the entire future. Health care costs are\nthe key to determine the entire fiscal\nfuture of the US. As I mentioned last\nlecture, the US is currently estimated about\n$75 trillion in deficit over the long run. $70 trillion of\nthat is health care. Health care is the\nsingle determinant of the US fiscal\nbalance in the long run. Literally, it's the single most\nimportant government problem facing-- health care cost\nis the single most important government problem\nfacing your generation and the next generation. I like to say that all\nthat matters when we think about the future\nis health care cost and global warming because\neither way we're under water. Basically, those are\nthe two big issues we have to face going forward. So this is a serious issue\nthat your generation is going to have to struggle with-- sorry-- as you go on. So that's health care\nin the US in 40 minutes. So this class--\nyou know, there's a famous skit from\nSaturday Night Live, which is what you remember\nfive years after college."}, {"content": "And it's five minutes, and 3\nand 1/2 minutes of spring break. I don't expect you to remember\nthe formula for-- if you're not going on in economics,\nI don't expect you to remember the formula\nfor deriving cost function. What I expect you to\nget out of this class is A, an interest in economics. And I hope you'll go on. I sincerely hope that. And I'm available\nto anyone who wants to talk about the pros and\ncons of going on in economics. Obviously, I'm more pro."}, {"content": "But I'm happy to talk about it."}, {"content": "So always feel free to\nreach out about that. But B, even if you don't\ngo on in economics, I want this to make you\na more educated consumer of the newspaper. This is-- we are in an era, as\nI said in my very first lecture, where truth and facts\nand the scientific method are, themselves, under attack. And MIT is the last bastion\nof fighting this war. We are the place that explains\nthe scientific method, that uses the scientific method. And we need to use\nthe methods you've learned here to\nthink intelligently-- whatever your conclusions--\nbut to think intelligently about these economics topics. And fundamentally, that\nmeans being annoying. And to illustrate that,\nI'd like to end with a joke that some of you may have heard."}, {"content": "Sorry, I apologize if you have. So the joke is a doctor, a\npriest, and an economist go golfing. They get on the golf course-- and they hit the golf\ncourse, and they're behind someone going\nincredibly slowly. I don't know if there are\nany golfers among you, but the idea is if\nyou're very slow, you're supposed to allow\nthe people behind you to play through and\nget ahead of you. This person won't let\nanyone play through. And he's, like, 50 shots a hole. It's disgusting. And there's, like, 50 people\nlined up behind this guy. And these folks\nare so disgusted, they quit after nine holes. They go back to the clubhouse. They're pounding their\nbeers like, what an asshole. I can't believe he wouldn't\nlet us play through. It ruined our day. And someone comes up to\nthem and says, excuse me, are you new to this club? And they said, yes, we are. He said, well, I can tell\nyou're new to the club because if you weren't new, you\nwould have known the person you were playing behind is blind. And actually, it's\na miracle he can get the ball in the hole at all. And usually, it's an honor to\nbe on the same course as he is. And the person walks away. And there's, like,\na deadly silence. And the people at the\ntable are like, wow. I feel terrible. And the doctor goes, I can't-- I feel terrible. I can't believe I'm-- myself, a man of healing, would\nbe so insulting towards someone who's blind. I'm going to dedicate a wing\nof my hospital to the blind. And he turns to the priest. And the priest says, I\ncan't believe myself, a man of the cloth,\nand that I'm supposed to care for the less able\nin society, would do this. I'm going to set up a free\nsoup kitchen for the blind. And they turn to the economist. And the economist says, well, if\nhe's blind, why doesn't he just play at night? And-- makes sense, right? And basically, the point is\nthat the job of the economist is to sort of be\nannoying and look for the basic\nflaws in arguments, to understand them, to ask\nthe difficult questions, but to have responsible answers. And that's what I hope\nyou'll get out of this course that I hope you'll\ntake forward with you. So thank you very much\nfor sharing it with me. And good luck on the final. [APPLAUSE]"}], "Online Degree = Scam? | IIT Madras Seminar 2024": [{"content": "hi everyone and welcome to a new video today we have my online session with the folks at I Madras online bs degree let me set the context this is not the folks from the standard IIT offline degree this is the online degree which is a lot of them from non- Tech backgrounds a lot of them from a dual degree a lot of them only here for the name of an IIT so the discussion was around is this online degree similar to the offline degree what kind of differences exist U Can you call yourself you know a real graduate from it Madras if you're doing this degree um will the outcomes from both the programs be the same how can the outcomes from this online degree which is very easy to get in be compared with the offline degree eventually because right now there's a lot of iits coming out with online degrees U fairly easy barrier to entry how can you outshine and have similar outcomes as the offline degree U if you're from this batch a lot of discussion around online versus offline how it's very easy to get into these online degrees but the number of people who are actually able to graduate is really less so how difficult is it to get through these degrees some discussion around research whether or not you should get a job follow research do entrepreneurship and a lot of random doubts that we have on a day-to-day basis as Engineers it's a fairly raw talk a lot of raw questions from students and I've tried to answer them to the best of my abilities with that let's get into my online session at it Madras we do want to become someone who is worthy of the name iitm so we are kind of in a place where we don't know what to do I think the phone that you're feeling is probably no different than someone from a tier three college or a tier 2 College who probably feel similar how do you hold up to the it name I think one good thing that happens in this program is the number of people who get out is really less like I saw the numbers and you know it's very hard to pass out there's something there like some level of respect you will get you know you're able to finish the degree how do you see uh the BS program for the students that are pursuing it cently I would say one thing okay think of it like any other BSC or BS program um do not associate yourself you know at all to college in super 30 I've seen two people fail interviews because of DSA only they were very good at web 3 but let's say the company asked DSA and then they so we had to start DSA classes then we saw no one here ised in DSA they're all here for Dev we stop DSA classes and then whatever referals are happening right now are happening purely based on dev should you do it interview you will need it thank you for making time for us so to begin with let me ask you something though what would you like to be a trist sir kirat or by yeah right I'll k so uh all of the students here are to saing the itm BS degree a remote degree uh I'd like to start off by setting the agenda that uh this won't be a Q&A session at all as much as we would love to have one with you but we want to just have a discussion for now uh being someone who is so uh into remote jobs remote structure the entire idea of remote looking at this uh particular degree and the students in this degree what would you suggest them like like I mean networking to important of course we have a lot of uh essential factors with networking uh you you keep speaking that uh networking is very crucial for students to do because that is the way to grow so what do you think uh for people pursuing this degree what kind of uh outlooks to should these people have for networking yeah that's a great question by the way can you hear me well I'm sorry yeah it's all it's totally fine cool uh great question I think especially for you guys considering it's an online degree you probably have to do it more than other people I don't super suggest this in campuses because you know in campuses you have on-site companies and that's part of part is sort of sorted of course not for a remote job but most other jobs you'll at least get a campus placement so you don't have to aggressively uh Network even though it's a very overused term networking um I think what that means over here is just being in small technical groups lead CTO Founders sometimes very technical events meetings toward Asia things like these rather than you know um know what the other way to network is um but long story short U for you guys considering it's an online degree I'm un sure what kind of placements you know um you guys can sit for at the end um and if the answer is you don't have an official placement thingy then it definitely makes a lot of sense remote job or otherwise for you guys to look out H I mean uh the the entire curriculum does have a you know placement cell industrial uh cell that does bring opportunities to students uh but the entire idea of you know placements is totally different for the people following this curriculum right and uh when we look at your videos you know it's all oriented towards corporate the corporate world networking through the corporate world climbing the ladder in a smart way and building your knowledge in a smart way but uh this entire degree deals with data and AI data science in AI mostly uh and this opens up opportunities for research more than corporate in the current world looking at the way these are AI is moving forward now uh considering the remote aspect and also the fact that research is a huge area of uh moving forward what do you look at uh research or corporate because there's a lot of things for us to look at through this degree so that's a tough choice um I have struggled with it uh half of not half of my batch like 20% of my batch went for Masters or phds I'm assuming that's what you mean by uh research so like it's a tough choice it's you earn first or you learn first is the question generally the idea first ear later whoever whichever of my friends have gone for a PhD or a masters in machine learning or AI are very well positioned for this upcoming bull to you know um Sprint past everyone else when it comes to not just monetary outcomes but the network the places they're at the people they're meeting the alpha they'll have in the next 10 years um so specifically in machine learning and yeah probably five years ago was the best time to go for a PhD today also not the worst time um anything else like cyber security or if you're just going you know for uh for a job in the US or for an H1B then these are tricky times uh because a lot of H1B holders are not uh getting jobs have to come back so on and so forth for ML if you get up basically you should go for it like that's research is great research is great for ML I'm I'm myself I'm an ml researcher as of now uh I work in ml in biomed data and uh you know medical side of applications uh when I look at it you know looking at your videos you yourself being someone having such a large fan base and you yourself having a lot of followers uh the guidance is very less the kind of uh there's no structured way of going through research at all uh there's there's a lack of structure there's a lack of hierarchy and I'm a True Believer of this you know if there is no hierarchy it leads to Anarchy that is what I that is what I believe in and the entire research area is totally H so uh when you yourself being someone so structured when you look at your videos it's always structured there's a pathway there's a road map or there's a laid out uh brain map for you and your and you have peers that you suggest to so looking at research and also applying that entire structured concept to it what do you think uh we should should we like stick to the structured concept that exists that has proven to be right or is there any other way to go ahead accordingly I think there's some some structure in research like you have to publish a lot of papers you have to have great cgpa try to go for an internship early find a good professor get in touch with them eventually your professor is going to you know get you in if you're looking at a Stanford or or a UBC so there's some structure there um there is also competition um because you know the structure is very well defined for folks at it Bombay Folks at it Bombay are you know probably the on-site people uh because a lot of these people are getting picked for internships from their second year itself going for you know University internships rather than corporates but there's some level of structure U that said uh of course it's fairly ad hog like in the end it's very hard to tell who got in how they got in um there's no examination that you're giving yeah but I would say you know like there's some level of luck involved and everything but the basic things you should check off like your cgpa needs to be really good some paper if you have published that's great and be in touch with professors if you want to get into uh UBC then make sure you know you know the best professor over there and makes sense I mean okay uh research there is a particular structure now assume that some person goes through all of the structured road map the basic structure that exists does well uh and is in a good position right now would you as a you know would you as someone who's a senior developer right now or a senior software engineer right now who's in CS would you hire someone into corporate research and if you would what kind of criteria would you look at uh for this person assume it's me and I'm into research what kind of criteria are you looking at as of now to hire someone and to corpor interesting so I've talked to a few Founders when this ml Rush came I was talking to Founders understanding who they're hiring for and tldr was they were avoiding researchers of course open a will hire you an anthropic will hire you all phds eventually land here only from the best but if you look at you know General startups building on top of llms um one they can't afford you because you know as an ml researcher you're probably going to make a mill at the very least from open AI so how would a startup that's a starting afford you one two they also might not need your expertise because they're not building at the foundation level they're not building llms they're building on top of LMS so all the companies that I am sort of involved with if I think about it even in web 3 rarely does any of my companies hire a blockchain researcher we work with companies uh who hire blockchain researchers for example if we want to get our contracts audited we'll hire and consult they'll charge us very heavily and they're working with they're hiring or usually are group of phds who are doing cryptography so you know you don't need a job long story short if you're going for research you know you people will pay you for you have value people will find a way to reach you and compensate you and you don't really need to stuck to the stick to the 50 40 hour week right you can provide value other ways to many companies compared to one but if you are looking for one there'll be an open AI or you know someone working who be happy to at least interview you if not hire makes sense makes total sense but there's this one thing that you said you know about startups that you've talked to a lot of startup people and uh you ask them about their ml engineer hiring uh that is another issue now that is a like every company has a a next to them now I mean if you enter Bangalore you'll probably run into someone in the Metro and you ask them what they're doing they'll tell you that they're having a company with a next to them so what should we look out for because as someone who is there who who are studying this data and AI uh when the Bull Run is actually happening when there's a proper hike in Ai and unsure as to what is going to happen in the near future uh what what need what do we need to look at because there's a lot of options out there we don't know which business is going to stand Which business is not going to stand and uh um being researchers or being let just say people who are into corporate how do we look at a company and say okay you know what this looks good I can be here interesting I think that's true not just for AI but generally high growth startups okay you can't judge which one's going to do well until they reach a Tipping Point for example by now you know GTO is probably going to do well zato is public profitable they're going to do well everything else is a gamble um specifically for you know high growth startups but you can look at their funding run Runway things like these and and usually bet on the founders if there are solid Founders one business guy one Tech Guy you can learn from them your worst Cas is you learn a lot from the company U your medium cases the company survives you get a salary your best Cas is the company does really well your Equity grows a lot so specifically for a companies as youve said a lot of B companies in Bangalore not all of them would require or you know most of them wouldn't probably require an AI engineer as I said most of them have delegated all AI things to uh either libraries or to llms they're not doing this in house it's referred uh but I think generally companies are looking for you know whatever that product needs let's take an example uh a good example of an something on top of llm might be what Zoom recently added you know meeting summarizers so they if they're building on top of llms their existing fullstack Engineers can build that specific problem now if they want to fine tune the model they want to bring the model in house bring the pricing down they'll probably negotiate with openi but in the worst case if they do want to build it in house is when they will hire you know a COR ml person but again probably you know contractually things like this so I don't know that answers your question of you know find I it does answer to it does answer my question more or less but it brings up a question you know being someone who's in the tech World for for like a decade or over a decade now I would say um why haven't you gone into the AI bulletin because you've been analyzing the market you've been into the you know economic and financial status of the market and I'm pretty sure you were aware of the fact that AI is going to eek because your your your circle specifically was pretty good I would say you were you were having a one of the top bunch at I right so what made you take a step back and look into web web 3 and you know blockchain I think not everyone from it is following one specific R if I'm honest uh if I'm being honest most of them are following you know trying to get into Fang um rarely of you are following you know hype markets like these and you know making sure they're making their way there it's either you go for a m or a PhD cryptography information security machine learning and then you eventually join the company there hope that the market has survived by then um or you know the market is doing well U or there are very few people like me who are you know changing markets left right and Center U for me uh why have I not done this I followed these markets for a while now for example web RTC followed by web3 I'm not saying I'm not following AI in fact recently I've joined you know U one of these a Rappers that's doing really well as a consult so not necessarily shying away from it that said U since I'm not working at the model there right I don't know I can't I can't extract as much value as I can being a core let's say smart contract writer because I probably have more value as a core smart contract engineer during the bear of the web three than a full stack engineer in AI during the bull so that's a high the learning curve of ml is fairly High compared to you know um let's say something like web3 orc resources are less very limited there's a circle of you know researchers which is why it's really good if you get in like that's sort of a filtering Benchmark for a lot of companies if You' have done you know some sort of research in machine learning unless you've done done that very hard to or you know compete with those people I mean yeah you make a point but uh why is it that if it's if it's so obvious that we need to get into research and if you do get into research that the pay will be absolutely amazing and you have a great future ahead even though this fact is established why is it that the market or the majority of the students in India struggle to find out the fact that okay I need to get into research I need to build my knowledge first work on uh you know cases which are compet which like ask me questions that I need to think in a unique manual for why is that this this mindset is not inculcated and I've been a follower of your videos since you were posting you know uh those sequential videos lectures so Le you had a proper pink and violet layout if you remember that three years ago I guess I've been following you since then and uh even when I look at your videos there haven't been a lot of talks with how research is uh you know giving you a lot of value uh so this entire culture is not inculcated in students and even from your point of view haven't really you know that path I mean it's a given that you are not into AI but why why is this factor missing what do you think it's a personal choice for people right uh for example when I was going for my masters I Accord to Tamu NYU one more Inu I forgot all of them were charging fairly High there was I had to take a loan for sure plus there was covid so there were a bunch of factors that made me not go there U it's not necessary everyone has to do research people can do well without it like entrepreneurship is one part being a engineer C someone is good part being an employe is also a great part and one uh there are a lot of factors that come to the picture like you have to be willing to bet on a market for 5 years for example I was talking to my one of my friends recently who did a PhD in computer vision he was telling me the problem statement I was working on U for five years after you know graduating from it bomb so 9ine years almost that problem statement can now probably be solved by llms so we were looking at it the wrong way we probably should have solved it a different way there's some risk that comes with u you know unless you love the problem deeply uh and you know want to follow it through don't care about mon outcomes as well considering you know if you're giving 9 years as a medical practitioner if you give 9 years you know there's a lot of monetary outcome at the end like infinite money at the end but that's not true for you know most research there's some money and if you do very well then it's more than it but I don't think this needs to be forced on everyone uh people are smart enough to you know figure out U whether or not they want to go into research also there are family situations sometimes you can't afford it if you go for a PhD also you know you're barely subsidized U so you're not living a super Lish lifestyle of course you can save some money um but if you look at your counterparts with working in fan you know they're probably making more there's a lot of uh compromise that you have to do initially uh which is not for everyone that's probably one of the reasons I did not go for it uh as I said I applied never applied for PhD honestly did apply for Masters nothing too specific computer science U goal was to move to the US honestly there's no other research well there a little bit of ml like one of my seniors who went for ML research in NYU is doing really well I started by uh ni company they raised like 80 mil if I did go to NYU he' probably you know be guiding me I was would be doing that that would have been a great part what I'm doing right now was a great part it's very hard to judge thankfully life is very single threaded so you know you don't know what would have happened if you went down the other part maybe my flight would have crashed what knows yeah everyone has like a personal choice yeah I mean I remember watching a video of yours and you mentioning the senior who was like into ML and you looked at him you talk to him and then you realized okay you know what the next buun is V3 and I'll get into that but uh don't you think the ml buun is still going on because that video came came out one year ago I guess this EML bullrun thing that you had with your senior that video came out one year ago or N9 months ago more or less and U your talk was like two years prior that or three years prior that I'd assume so you had that talk four years ago and ml buun is still going on I'd say it's at its peak and I can for sure say that it's going to be at its peak till 2026 so uh how long do you think this is going to run oh I can't predict that would be nice if I could but I there's sentiment shifts though right initially there was a lot of euphoria everyone was getting funded left right and Center now the companies that are getting funded are people who have found real use cases on top of AI who have real Revenue so when move towards business of course open has a metric all llm companies will do really well my talking about they're also building their own llm for companies that's why they're raising at whatever valuation they want but other than that you know um now the next set of value is going to AC or Investments are going to ACR to real businesses will build on top U so will it continue it will honestly the whole problem is whether or not you can find real use spes on top of these things blockchain be AI or you know something else um if you do then you know companies will do well I don't see ml going anywhere honestly it's much better much more sticky what's come out via LMS compared to what you know web3 sols or web RTC sols say so we'll see but of course this is going to do well for the next few years makes sense totally makes sense now uh you being a webc andb web web3 and also blockchain person your content is totally I mean it it it of course deals with uh these Technologies these Landscapes when we when we put out our link you know the link for registration to this and we put a small category saying ask your questions all of these students enrolled in this I madas degree make uh by making sure that they're going to be involved in data and AI okay but all of the questions or not all I mean 40% of the questions said uh is is this a good time to get into web3 is a good time to get into blockchain now these students mind you these students are in the remote degree and half of them are pursuing like two degrees like I am I go to an offline College in Hyderabad and then I do this simultaneously so it is through interest that they they took this in but they're still considering web 3 and you know blockchain because they are thorough Watchers of your content now what there's this fine line you know that you tread when you're a content creator that you should not misguide people you know uh you should not uh you know give the wrong uh idea to people and guide them through to an interest which they which they shouldn't probably look at of course number games number game is huge in India 15 LPA they set uh so when you post videos what kind of uh you know logic runs in your mind that okay I shouldn't probably put out the wrong agenda because these students are data science students and they're still giving questions like these so it's it's kind of a personal concern to be honest I think generally it's not just for your degree any degree people are interested towards course yes if you go to an IIT look at mechanical engineering people 50% 60% are taking coding jobs so it's not just that your degree has data science and people are looking at other CS options every degree you look at most people are looking at CS options getting placed in CS companies rarely are people you know actually taking core jobs um when you join a degree you're fairly young you don't know what you're getting into honestly uh when I was getting in I was struggling between it Bombay mechanical and RI CS pretty randomly I took RI CS but I know eventually I had CS was a good option I have core interest in CS it's also had a decent monetary outcome which might not have been the case at mechanical so if I join mechanical day still a very high probability I would wouldn't have done Justice to my degree would have gone for a CS job so I don't think there's anything bad around uh choosing a different path in CS or otherwise a lot of people in CS eventually become engineering managers PMS so on and so forth though it's very you're fairly young to decide I've done a data science degree so I have to stick to data science U I think it depends on a lot of factors including you know where do you think jobs are where do you think uh how long does it take to get a job how hyping the job is so on and so forth which is why people from all degrees flock towards CS not just this one uh how do I decide whether or not I'm misguiding people on YouTube I thankfully do not think about it uh all the videos that are coming out are pure natural what is happening in my life right now what I'm trying to build right now and I'm putting that out what kind of let's say money I'm making and putting that out U two people get influenced probably uh would that lead to a bad thing for people at it Madras uh data science degree considering that took a data science degree I don't know maybe so you guys should think before you know you decide looking at any content creator H if he's getting into X should I get into X or not do your own research and then you know decide based on that makes sense makes sense and you know the journey for like getting into Cs and also like into and film filming videos putting them on YouTube uh it it it was an exciting one clearly because I've seen you since you're what 55k follow 55k subscribers or something and early subscriber it so uh I'm sure the journey was like amazing and throughout this process I've seen you change your stance a lot of course I mean opinions change especially in the Cs landscape that is totally understandable now one of the most controversial opinion of course considering the Indian market is the DSA one there were videos saying DSA okay no and then videos saying okay DSA you know what maybe and then there's a super 30 now uh in the middle there was a thing saying okay you need to so all the I guess we got like 60 to 70 questions on this just just address that one one thing for like for a minute what do we do for DSA uh in super 30 I've seen two people fail interviews because of DSA only they were very good at web 3 but let's say the company asked DSA and then they so we had to start DSA classes then we saw no one here ised in DSA they're all here for death we stop DSA classes and then whatever referrals are happening right now are happening based purely based on dev should you do it there were interview where you will need it for example for me my very first remote job they asked fairly solid BSA also you guys are in college so you have a lot of time to explore you can do a bunch of things two degrees like you are I don't know why you're doing that you know you're not able to manage DSA but personally I've seen for example you good colleges people do ICPC good sort you know your DSA sorted for a while you have to practice before your interviews U for most the common answer is can do it it's just another two hours every day you have to give U and should not avoid it uh for extremely you know for example you you said you want to go into research so does it make any sense for you to do DSA probably not because similarly there are people who know I want a remote job a very high growth remote job where I get selected based on my skills and nothing else but then you know you don't need H I mean okay coming to the fact that I'm puring two degrees I realize them into data and math a bit too late my original degree deals with blockchain cyber security and IOD and uh I I study blockchain and cyber security daily while I you know go to college but it doesn't involve data and math so I'm not enjoying it as much so I thought you know what I'll just try this out and it worked out for me so I thought okay fine and then it led to research so I'm glad I took this decision uh moving forward though uh when you look at you know DSA there are a lot of Landscapes to look at but uh as someone who is into tech for so long and uh you must know that there will be newer technologies that are coming up for sure I mean it it is an analy cycle at this point is it essential for us to stay in the loop especially with with llms man I mean like every week we have a new announcement from from open AI every week every month we have a new announcement from Gemini anthropic comes up with something insane and then suddenly the CEO changes his drama so is this like uh should we keep up with this or should we just leave it all alone work on our Concepts you know do our research or do are corporate and move forward what do you suggest so so when you say should we focus on this do you say should we focus on the standard DSA or should we focus on the funding anoun yeah should we like focus on standard DS I mean that is again of course a personal opinion for sure but the kind of Bull Run that AI is in the kind of announcement that you're getting on it on a weekly or monthly basis it's insane I mean the growth is insane and if you look at the Nobel prizes that the people won I'm not sure if you're aware of this or not all three in maths physics and chemistry dealt with AI there were AI applications in their respective fields that that shows the kind of influence AI is going at right now and should we like keep up with the pace that AI is moving at is it important to keep it up because when you are in your youngest ages I'm sure there were Technologies which were coming up even in web development or web 3 or blockchain and were you keeping up with the latest you know technologies that were kept that were like bringing forward or did you just mind your own business short answer no I wasn't um there in it as I said there's a very standard what everyone is doing which back then at least was everyone was going to Google us uh everyone was following the path of getting to Google us that's where your invion was limited right there was some people Bombay has a culture of research thean was focusing on Research over there I would doubt they were also looking at funding announcements they were looking at CV uh you know computer vision papers that are coming out so on and so forth so the fancy funding announcements or you know who's getting hired whereare or llm came out um I think more than that smart people focus on what research underlying research is coming out U that will eventually maybe lead to something a better you know 10x outcome like llms did chat GPT something new for sure like everyone tries it and gets allowed what is that next thing that is coming I think most people are focusing there so rather than looking at you know funding announcements and these things if you want to go for research you should focus there research paper for me never did that honestly was going through the but nothing outside that had friends who had to go forar fair enough as much I was allowed to like keep talking to you I think uh over to you all right uh I will come in in a bit again uh hello hello [Music] sorry uh so uh we were talking about our uh curriculum so can you please uh give your review on our curriculum uh yeah yeah yeah I haven't gone through it yet well a little bit I did um looks like a lot of it is your your videos are just on YouTube and also in your Erp is what I could tell I looked at some of your YouTube videos uh it's decent like it's much better than you know traditional College honestly uh or you know whatever TI three colleges U is IT industry oriented probably like Pro again this is fairly relative but compared to other colleges it's decent U also I haven't looked too much into it so you know I'm not the best judge right now we have foundational course which talks about I mean which teaches about mathematics and statistics a little bit in um English also yeah and do we have a little bit of programming python so tell me this what when you when you say little bit of programming in Python how deep are we going here uh this is the foundational course which means it is like stepping stone it is like a basement so this just deals with everything in uh in a very very basic level so from there we are taking to I mean we are taking us in a diploma level which deals with programming completely so here we have pdsa dbms mad projects Java system commands and then uh there is also another diploma degree here which is for specifically called data science where we have six courses and two projects and other diploma also had two projects and six courses as you can seen so it deals with MLF uh machine learning is split into three different courses here foundations techniques and practice we also have a project on it and there is BDM uh here we actually go and talk to a business and do a project analyze your data give them some suggestions that kind of thing happens that is the project and how to do it is the course and uh business analytics and tools and data science are related to the same thing so and then comes the BS degree so here we have two parts we have to choose from this one or this one which is related to uh deep learning and Ai and the other is related to software and software testing engineering and testing so there are some elective courses me sorry I was scrolling too fast these are some some of the elective courses we can [Music] choose is it all right uh I've seen this before uh it's very good uh I mean compared to a different colleg is pretty good uh is there scope for improvement there always is uh but you know love it and and uh I think the bigger problem is this not just proof for you guys like in any college people are rarely learning anything from you know the whatever classes you learn from the community and the problem with you guys might be you guys mean don't meet enough because most people if you ask so you know that might be missing U cabus wise of course it is much better than you know what you would find in a traditional College people are sleeping in a traditional College you guys have an Erp just studying one day before the examination um which is also fun so it seems like you know whatever you guys are paying for you're getting some value from it you have you can learn from it are there better resources maybe for learning the same things from you know maybe yeah that's that's a high level but you know happy to dive deeper uh one thing uh there's a better question that I wanted to ask why um how do you see the BS program like after the promotion that uh she did how do you see uh the BS program for the students that are pursuing it I would say one thing think of it like any other BC or BS program um do not associate yourself you know at all to a colleagues and I say that to everyone even from go to it offline okay you know your degree is your people who the people that you found around you and you know who are now doing really Val because usually colleges if you look at a lot of coding YouTubers which are they from they're all from D because start follow what you guys should really look for is this you know people possible this is having similar outcomes at the out of ID Delhi so what is that thing that you guys are doing like or you're going to do Consulting will probably be the first aliz from from this online program um that's something we'll figure out in a few years U but is that possible in an online degree uh yeah I've seen your stats lot lot of people go to level two there's less you know pressure on you guys to graduate everyone passes together everyone very Clos net I'm seeing you the age Gap is fairly big and you know some are very lower going to level two are going to level three so it's a good experiment and you guys are you know the first batch probably one of the first batches will come out the experiment so I'm excited to see what comes out of it but yeah very early to tell okay you know whether it will be better than let's say you know a real it col what a real this a real it college but onsite I or onsite tier three or onsite tier say better time will yeah I just like to but in here I mean really resonated with with the point on College like bomb is going to research that he's going to entrepreneur um so a couple of points with the online degree obviously because it is online you don't meet people obviously the guys at Chennai few of them do this full-time so they they have a community they have a desha they have a i and Research Park they have a couple of professors they work with they have the entrepreneurship and they have the library of ss right um but that's not there for the people online so that's number one uh number two harking back to a point previously about how personing two degrees might be stupid I don't think it is because with with this with the online degree you get the tag of the stamp of IIT on your resume you get like a tier three college and the I on your resume as well as you get I mean you get the content but then you can get the content from other YouTubers as well but I think the major thing is uh first of all the stamp secondly like this Society this entire meeting we're doing today is is a part of this huge Community Driven effort to get people together otherwise 174 people on this call wouldn't be together if not for the society so I I just wanted to share a few thoughts I mean no no particular question at this point great point I think there's no downside if you can manage two degrees you should do it U my yeah yeah I agree because not not the worst idea in the world if if you're on tier three college but does it really give you you know the credibility of an i is my question it's very easy to get in that is that is exactly so I talked to a professor from Colombia and I put IIT on my resume uh so he thought I was actually offline IIT uh and then I'm like no it's on BC degree and we're doing it and it's but it's official and all I have ID card and it's like oh no you should put online on it so I I think message for the other 1 170 people there on the call I put a bracket online on it you know but I share a story here when Yash came to the office for the first time he was wearing an IT madas degree sorry t-shirt I was like cool it madas then he said and from online I like degrees associate fake it till you make it I think is the vi it'll hurt you really bad if you use fake it make it if you you know eventually someone realizes agre High L advice for people here speaking of uh you did mention about offline iatm I and online I uh we are doing it in online so we do have this kind of foro because uh most of the people here are either working or they are having their own ENT uh they are entrepreneurs and they have their own companies or uh they have dual degrees and I I have come across so many people and I myself uh I'm doing it as a standalone degree so we really feel foral and I not even in Chen so I feel very left out and I don't know uh how we should come come over this thing and uh we do want to become someone who is worthy of the name iidm so we are kind of in place where we don't know what to do and we do have some people to look up to but we're not sure how we are going to make it or it's kind of what should I say maybe cat and a all kind of situation here interesting so I think the phone that you're feeling is probably no different than someone from a tier three college or a tier 2 college would probably feel similar um how do you hold up to the it name I think one good thing that happens in this program is you know um the number of people who get out is really less like I saw the numbers and you know it's very hard to pass out there's something there like some level of respect you'll get if you know you're able to finish the degree uh so I wouldn't say it's you know completely uh someone would deny can you go to it Madras an online degree if you finished the it Madras degree considering I've looked at the stats I would respect you it's a hard degree to go through you know they Grill you really bad I know anyone can join but not everyone can graduate so that's one and two it goes away with time and years you know uh I did not make it to whatever in xyc but you should you should you guys should meet offline just say 174 people this happens on steroids when you're on campus you're every day having you know meetings like these smaller groups yeah yeah that is super important nothing else onl but if you if you filter out the smart people and put them together they 100 times better than taking smart people but keeping them in their houses so one thing you guys can figure out somehow consider your society and you know um you guys are saving a lot on your fees also so why not spend a little on meeting I don't know Goa meet up Bangalore meet up and you everyone sort of reaches them yeah that is happening actually but uh it's not that everyone can go and meet on the specific time in so there are some uh drawbacks one more thing by which I wanted to ask is um um which I wanted to convey is that to all the people um one of my cousin was watching anime okay so I told him that oh you are watching cartoon so I I did that because I wanted to see the reaction so see U here's the agenda If he if he wants you know uh to prove that anime is not a cartoon he will be in the aggression or he will be in Lost Sensation that no no it's not a cartoon thing it's a anime or it's a different kind of class but he was not about that okay uh he said that okay no worries uh it's it's a cartoon for you it's a anime for me let's be Let's uh you know accept that so here's this thing for all the online people who are you know in the it Madras if you are know defending that I'm I'm in know online you are doing the wrong things on the on that step itself what's your call on this yeah I mean be Elling towards it bro like someone saying let them say I mean if someone is taking out the time and beting your degree or spending two minutes thinking it any ITB let them be people will say whatever want what difference will it make in your Liv arguing with them or agreeing with them we can do it as about that so um we cannot let like people openly ask because so guys like we got your questions We shortlisted Them Say set them into proper questions so we'll be asking soon since you have only like 12 more minutes we'll we'll get can I ask something not really please uh try to like you know keep it contained we have your questions here don't worry we'll cover everything which is which is repeated which was important so sh start so uh so the first question is there are two categories here so uh first category is people who are who are knowledgeable I mean they do have some coding uh knowledge but they don't have any formal degree in the coding aspect as not they not from the computers background so they want to get into Tech and the other situation is that there are people who don't have any work experience they are from uh Tire three college and they have a age Gap and they are doing this degree and they want to get into Tech so what advice will you give for these two category of people you're saying most people here are in these two categories madas this degree is not going to help you too much help you crack some prerequisits in a Google or somewhere else you need to work extremely hard on your skills you anything you work really hard and do DSA Dev and get really good at it and second choice is you get into a degree and chill you take the first one to that less paid or free thing of looking at a lot of videos and working really hard should be your goal that's 99% of the effort a degree will help you 1% here are some prerequisites and sure I'm sure there are placements and other things that you get from you this needs to be done even more for people are from nonch makes sense I mean yeah that totally makes sense I mean the next question though uh people most of the responses were were likey most of them are in the first year offline College Med dual degree people uh they're like okay there are multiple Pathways for me to look at they came into this thinking key half of them came into thinking madas well enough good enough for me but now they're like okay there are hackathons there's compet programming and then there is you know increasing my knowledge in data or AI should I like go into research as I asked and uh when you are already occupied with two degrees one offline one online and there's a lot of things laid out for you what is your suggestion like like is there any other option that you can suggest colle course have to manage a lot of things U yeah to drop out from one would be first advice U I don't think I mean unless you find something very good in your degree I don't know um but within a year figure out this one makes more sense for me and and you know probably because handling academics handing making sure you're passing through your examinations considering it's so hard you'll spend all of your time there only and what with what final outcome um is that really worth it maybe I don't know man I mean everyone has their own situation so think about it I I think you have to spend a lot of time working hard yourself on things that are happening in the industry which is most probably not being taught in your col makes sense now the next question though uh do you think decentralizing AI is possible from like a blockchain perspective out of honestly I mean this is no can try lot of people have tried it lot of somec money there but no one has been able to figure it out I think web AI exists very well on web2 traditional systems web3 is all something else merging them people have tried no sticky use case until now no stick use Cas until now I mean would you suggest people exploring though like your personal suggestion no makes sense now uh so many questions and I mean it so many questions asked about chok it is the Talk of the Town right now in CS for all the tech people and uh it is it goes without saying most of J is for web developers people with JS skills or like you know Java now dealing with data and AI most of the people like here what is your advice for people for G in data and specifically so many questions on yeah generally I would say don't stick too much to a degree as I said don't sck yourself you should look at standard things that you know lead to sometimes research outcomes sometimes ICPC sometimes D sometimes a Google job sometimes a startup job sometimes open source so said most of the companies uh do come in web def python JavaScript Java the three common stacks and this is look at college and judge it the best way to Jud iture um so you guys should do it you know you'll probably as I said be the first ones full pioneer when I was at it RI there used to be five people or six people who got into G by the time I graduated we did 42 we were the highest college you know doing G you should do that next madas online is 50 selection you have so many people but you know the real people you have to figure out what the bestes andus that makes that makes sense I mean conc on the standard stuff to while moving forward with your own with your own uh things so guys to a suggestion by the man himself make sure that you Explore More don't restrain yourself to data and AI sounds good anything else sounds good that's that's pretty much it yeah thank you thank you so much congratulations [Music] here"}], "Stanford CS236: Deep Generative Models I 2023 I Lecture 3 - Autoregressive Models": [{"content": "all right so let's get started the plan for today is to talk about Auto regressive models which is going to be the first uh type of first family of uh generative models uh that we're going to uh consider in the class this is the kind of technology behind large language models things like CH GPT um so yeah just as a recap uh remember sort of like this high level overview whenever you want to train a generative model you need data so samples from some IID unknown probability distribution P data and then uh you need to define a model family which is going to be a set of probability distributions uh over the same space over which you know your data is defined mind and uh these probability distributions are typically parameterized somehow um for example using uh it could be conditional probability tables in the case of a ban Network as we have seen in the in the last lecture for the most part we're going to be thinking about probability distributions that are defined in terms of neural networks so you can think of theta there in that picture as being kind of like the parameters of uh the neural network that you're going to use to define Define this probability distribution and then you're going to Define some sort of notion of similarity or Divergence between the data distribution and your model distribution and then we're going to try to optimize the parameters of the neural network to make your model distribution as close as possible to the data distribution uh the caveat being that you only have access to samples from the data distribution right so you don't know you can't evaluate the probability of an image under the data distribution the only thing you have access to a bunch of samples and uh once you have this probability distribution then you can do several things you can sample from it uh so you can choose a vector x with probability uh you know there's many different axes that you could choose from each one of them is assign a probability by your model and you can choose one uh with the the probability uh according to this probability distribution you samples from it uh and this is what you need to generate new data uh we're going to be interested in evaluating probabilities um for several reasons one is that evaluating probabilities is useful for training the models so if somehow you have a way of figuring out How likely is any particular image according to your model then that gives you a pretty natural way of training the model kind of like solving this optimization problem of trying to find the point that is close as possible to the data distribution and one way to do that is to just do maximum likelihood you can try to find the parameters of your model that maximize the probability of observing a particular data set the other thing you can do if you have access to probabilities is you can do things like anomaly detection so you can given an input you can see you know is this input likely or not so kind of like but we discussed in the last lecture one advantage of generative models compared to discriminative models is that you can reason about the possible inputs that you have that you might be given access to so you might for example try to detect adversarial examples uh because perhaps you know they they are different from the kind of like natural images that you've used for training your model and so if your generative model is good you might be able to identify that something is odd about a particular input maybe the likelihood is lower than it should be and so you can say okay this is this is perhaps an anomaly maybe I should I shouldn't I shouldn't be very confident about the kind of decisions uh or the kind of predictions that I make about this particular data point and as we discussed another thing you can do is potentially on supervised representation learning uh and so in order to do well uh at learning a good a good approximation of the data distribution you often need to understand the structure of the data and so in some cases uh it's going to be a little bit tricky for auto regressive models which is what we're going to talk about today but for other types of model models is going to be pretty natural there's going to be a pretty natural way of extracting features um as a byproduct basically of training a good generative model so the first question uh is kind of like how to represent this proability distributions uh so how do you define this set in a meaningful way and today we're going to talk about Auto regressive models right which are built on the idea of using chain rule essentially and uh next we're going to talk about how to learn it so recall that U there is this General result that you can take any probability distribution Define over a arbitrary large number of variables n and you can always Factor it as a product of conditionals so if you have four random variables X1 through X4 uh you can always write it down as the probability of X1 the probability of X2 given X1 and so forth and uh this is just fully General you don't to you don't need to make any assumptions on the on the distribution every distribution can be factorized this way exactly and in particular you can also use any ordering you want so in this case I'm factorizing it based on the ordering X1 X2 X3 and X4 but you could choose a different ordering so you could decide you could write it down as the probability of X4 times the probability of x3 given X4 and so forth and here you start to see that yeah in general you can always do it but perhaps some orderings might be better than others um so if there is some kind of like natural causal structure in the data then perhaps modeling the data along that direction is easier but chain rule doesn't care it works regardless of whatever ordering you you you're going to use uh baset essentially exploit this uh this idea and uh they make progress by basically simplifying these conditionals so we've seen that in general representing even when the random variables are discrete representing those conditionals as staes doesn't scale doesn't work and so B net ban networks essentially make some kind of conditional Independence assumption they assume the certain things are conditional independent from other things and uh and then that gives you potential simpler factors that you can represent as tables and the other way to go about it is to use a neural model well instead where instead uh you're going to give up on the tabular representations it's no longer a lookup table now it's going to be some kind of function parameterized by a neural network that you're going to use to uh map different kind of uh assignments to the variables you're conditioning on to parameters uh for the conditional distribution over the the the the next variable in this ordering that you're using so in this kind of neural models what we're going to do is we're going to start from chain Rule and then we're going to try to approximate the true conditionals uh using neural networks and this works to the extent that the neural network is sufficiently powerful that it can well approximate the conditional probabilities which could be potentially very complicated if you think about those as tables there could be really complicated relationships between the entries in the table and this kind of factorization using neural models Works to the extent that the neural network is sufficiently flexible that it can capture the structure of what you would get if you had a you know a fully General tabular representation and uh the good news is that uh efficiently deep neural network can in principle approximate any function and so that's kind of like where the magic of deep learning comes in if you can use very deep neural networks there's a good chance you might be able to actually come up with a decent approximation to these conditionals and that's why this these models tend to tend to work in practice so remember that you know the the Machinery we're going to use is going to be the same as the one you use using regular let's say classification so you want to predict a binary label give it a bunch of input features uh you just care about the conditional distribution of a single variable given a potentially large number of other variables but the important thing is that you're just trying to predict one thing at a time a single variable Y and so you can use things like logistic regression or Ral networks to do this kind of things and uh in particular we've seen that logistic regression is kind of like assuming a relatively simple dependency between the values of the covariates x or the features that you're conditioning on and the conditional probability of Y given X it's basically assuming that there is a linear dependency that then is fed through a sigmoid uh to get a a non- negative number that has the right kind of like normalization and uh you can make things more flexible by assuming some kind of nonlinear dependence and there that's where you use NE networks right so you can take your inputs act you can transform them by applying linear Transformations nonlinearities you can stack them in any way you want and then at the end of the day you still have some sort of transformation that gives you the parameters of this conditional distribution over what you're trying to predict given what you have access to and so maybe at the end you use a some kind of sigmoid function or a soft Max function to to basically normalize the the output to a probability distribution so it's more flexible you have more parameters which is good because the model you know you can capture a richer set of dependencies between the variables the price you pay is that you have more parameters to learn you need more memory and you might imagine that you might need more data uh cool so that's the building block and then basically the whole idea what Progressive models is that once you know how to predict one thing using a neural network you can kind of like combine them and you can always think of a high dimensional output let's say uh an image as a number of individual components and chain rule gives you a way of predicting individual components given the the previous ones and so then you can plug in your neural network to get a generative model and that's what neural Auto regressive models do right so for example uh let's say that you wanted to learn a generative model over images so just for Simplicity let's say that you wanted to work with a binarized mnist so mnist is kind of like a classic data set of handwritten digits um so that if you binarize them so that every pixel is either zero or one black or white um then they might look like this so you see that they kind of like look like handwritten digits and each image has uh 28x 28 pixels so you have 28 * 28 random variables to model and uh the variables are binary 0 1 Black or White and the goal is to basically learn a probability distribution over these 784 random variables uh such that uh you know when you sample from it they that you get hopefully look like the ones that you have in the training set or that in other words you're hoping that the distribution that you learn is a good approximation to the data distribution uh that generated these samples IID independent identically distributed samples that you have access to in the training set and again this is challenging because there's a lot of possible images you need to be able to assign a probability to each one of them and so uh recall the recipe is uh you define a family of probability distributions parameterized by Theta which we're going to see in this lecture and then you define some kind of learning objective to search over the parameter space to do some kind of optimization reduce the learning problem to optimization over Theta over the parameters that Define the distribution to try to find a good approximation of the data distribution which is going to be the next lecture uh so the way to use an auto regressive model to Define this probability distribution is you first need to pick an ordering so remember if you want to use chain rule you have to pick an ordering and for an image is not even obvious what the ordering should be um there is not an obvious kind of causal structure like you're not modeling a Time series where you might expect that you know there is some causal structure and maybe predicting the future the past is easier than going backwards but any ordering Works in principle and so for example you can take a raster scan ordering and so you can go from um top left to bottom right you can order the 784 pixels that way and then you can apply chain rule to this probability distribution and so you always you know that without loss of generality there's always a way to write down this distribution that way basically as the probability of choosing an arbitrary value for the first random variable then choosing a value for the second given the first and so forth and so that's how you break down a generative modeling problem that is tricky to a sequence a small number of classification regression something we know how to handle each one of these conditionals is only over a single random variable and that's the kind of setting you know how to deal with from or you typically consider when you think about classification regression those kind of problems and uh you know uh you cannot do tabular form so a ban network is is out of the question here and so instead we're going to try to basically model these conditionals using some kind of like neural model some kind of functional form that will allow us to map the different config figurations of the pixels we're conditioning on to a probability distribution or the next pixel that we need to to work with in this particular ordering that we've Chosen and uh so in particular I mean if you think about the first uh probability distribution you know you can represent it as a conditional probability table that's just a you know binary random variable you just need one parameter for that so that's why I'm saying pcpt here means that you can actually store that one set cly uh but the other ones become complicated and so you kind of have to make some sort of approximation and one simple thing you can do is to just lose logistic regression so you can try to use logistic regression to basically predict the next pixel given the previous pixels and that gives you a generative model basically and uh if you do that notice that you don't have a single classification problem you have a a sequence of classification problems like you need to be able to predict the second pixel given the first one you need to be able to predict the third pixel given the first two you need to be able to predict the last pixel the one in the bottom right given everything else so all these classification problems are basically different and separate do you even have a different number of covariates or or or Fe variables that you're conditioning on and so in general you're going to you can potentially use different parameters different models for each one of them and this is kind of like what I'm alluding here there is a different Vector of coefficients Alpha for your logistic regression model for each classification problem and uh so more explicitly for example you would have the first uh prior distribution over the first pixel which is just a single number it tells you how often do you choose the first pixel to be white versus black so if you think about the structure of these images you know the top this pixel here the top left is almost always black so you probably would want to choose this number to be to be close to zero assuming zero means black sort of like you want that pixel to be often black uh and then uh you know you need to be able to specify a way of predicting the first pix the second pixel again the first one and you can do it using a simple logistic regression model and and so forth right and uh that you know that's a modeling assumption whether or not this type of generative model works well depends on whether or not it's easy to predict the value of a pixel given the previous ones in this particular arbitrary order that I've chosen for the pixels and uh you know whether this works again depends on how how good this this how good this approximation is so it might work well or it might not work well because maybe these dependencies are too simple maybe regardless of how you choose this Alphas there is not a good way of figuring out how you should choose the the value whether or not a pixel is white or black in this case and uh but you can think of it as an AO regressive model and that's what because essentially what you're doing is you're trying to regress you're trying to predict the the data PA the structure of the data itself right so uh you're regressing on yourself like you're trying to predict parts of each of each data point given other parts of the data point and uh that's you know this kind of a modeling assumption has been tried before um this kind of model is called a fully visible sigmoid belief Network it's kind of like a relatively simple uh early type of generative model that as we will see is not going to work particularly well but it's kind of like useful to to work it through so that you get a certain level of understanding of exactly what it means to model a joint distribution in terms of a simple kind of like classification models so when you think about what we're doing here when you think about chain rule uh we have all these individual pixels that we're modeling conditionally and all the ones that come before it in the order and so when you model the probability of XI given all the variables that come before it in the ordering let's say using a logistic regression model uh you know you're basically outputting the conditional probability of the pixel being on or off given what you've given the values of the previous pixels and uh we're often going to denote this using this symbol here x minus I smaller than I uh which basically means given all the indexes I that are strictly smaller than than all the indexes J that are strictly smaller than I and uh which you know in the case of logistic regression that conditional probability is given by this relatively simple expression linear combination and then you pass it through a sigmoid now how would you evaluate you know if somebody gives you a data point and you want to know How likely is this data point according to my model which is the kind of computation you would have to do if you want to train a model by maximum likelihood how would you how would you evaluate that joint probability given that somehow you have all these values for for Alpha so what you would have to do is you would have go back to back to chain Ru so you will basically just multiply together all these factors and so more specifically you know the the first pixel X1 will have a value well I guess here I have an example with the let's say imagine that you only have four pixels uh there's four random variable and let's say that we are observing the value Z one one zero um then you basically need to multiply together uh all these values which are basically the predicted probability that a pixel takes a particular value given the others and these predicted probabilities depend on the values of the previous pixels in the ordering right and so they depend on so X hat I which is the predicted probability for the I pixel depends on all the pixels that come before it in the ordering so a little bit more explicitly it would look something like this um where you would have to compute the conditional probability of the second pixel when the first pixel is zero you would have to compute the conditional probability of the third pixel being let's say on in this case given that the previous two are zero and one and so forth and then you would basically replace that expression here for xat with the standard sigmoid logistic function thing and that would give you the the number how would you sample from this distribution so let's say that somehow you've trained a model and now you want to generate images according to this model the good thing about an autoregressive model is that you can basically it also gives you a recipe to sample from it like in general it might not be obvious how you do this like okay you have a recipe to evaluate how like different samples are but then how do you pick one with the right probability right so would you randomly generate one image probability and then do some sort of rejection sampling you could do things like that uh that seems you could use generic kind of like inference schemes if you have a way of evaluating probabilities you could try to you even brute force and kind of like invert the CDF and try to do something uh something like that that of course would never scale in to to the situation where you have hundreds of random variables the good news is that you can basically do it you can use chain rule again and kind of like decide the values of the pixels one by one so what you would do is we know what is the prior essentially probability that the first pixel is on or off and we can just pick a value for the first pixel now once we know the value of the first pixel we know how to figure out a value for probabilistically for the second pixel so we can plug it into the previous expression you could do you know something like this just to be very pedantic you have there's some prior probability and perhaps you always choose it to be black because all the images are like that but then you pick a value and then you basically sample the second random variable given the conditional distribution and this conditional distribution you can get the parameter by fitting it by using this expression so the the logistic regression model will try to predict the second pixel given the first one and uh you're going to get a number from this and then you can sample from it then you can pick you know you're generating two you have two pixels now that you've chosen values for then you can fit it to the next logistic regression model and you can keep generating the image one pixel at a time so that's the recipe and and it's good news because uh you know sampling is to some extent uh easy I mean it's uh not great because you have to sequentially go through every random variable that you're that you're working with but it's better than Alternatives like having to run out you know using Marco chain mon Carlo methods or other more complicated techniques that we might have to resort to for other classes of models the good news is that for these kind of models sampling is relatively is relatively easy conditional sampling might not be so if you wanted to sample pixel values uh based on you know if you wanted to do in painting because you have some you already have a piece of the image you want to generate the rest depending on what you know about the image it might be easy or it might be hard so it's not straightforward the fact that you can do this efficiently is a nice benefit of these type of models okay now how many parameters do we have so you know we have a bunch of alpha vectors these Alpha vectors have different lengths because there are different they are logistical regression models of different sizes basically any guess like for this model that's say two parameters and this one three and then four then five it's uh in n squ like it's n squ one plus roughly n squ right so you know potentially not great but maybe manageable cool now as as I kind of mentioned before this doesn't actually work particularly well so now I don't have the results on Mist but if you train it on this data set of uh the CCH 101 so the samples are on the left and you can see that they kind of have shapes like there is like objects of different types and then uh you know you can kind of train this simple model based on logistic regression classifiers then you can sample from it and you get this kind of blobs so not great and the reason is that basically the logistic aggression model is not sufficiently powerful to describe this potentially relatively complicated dependencies that you have on the pixel values so how can we make things more comp better let's use a deeper neural network right that's the that's the natural thing to do um when and if you do that you get a model that is called n Neo regressive density estimation and the simplest thing you can do is just use a single layer Neal Network to replace the logistic regression classifier and so what would it look like uh basically what you do is for every uh index I so for every pixel you take all the previous pixel values and you pass them through uh first a linear layer then some nonlinearity and then uh uh you pass the nonlinearity um what you get these features this vectors that you get through a logistic regression final output layer that would give you the the parameters of this B random variable so it will tell you how whether or not what is the probability that the I pixel is on or off and as you can see now we have a slightly more flexible model because uh you don't just have the alphas the parameters of the logistic regression classifier of the final layer of the network but now you also have the the first layer so you have a slightly more flexible model and uh and so it would look something like this so you would uh and again the issue here is that you you know you have if have n random variables you have n separate kind of classification problems and so in general you would you could use completely sort of like decoupled models and so the first model would have let say a single uh input X1 and so the the shape of this Matrix would be just a column Vector basically and then if you have two inputs X1 and X2 to predict the third pixel then this Matrix would have two columns essentially and and so forth and uh yeah do we have Sig like why do we have a Sig over H and then Sig over like the second Sigma makes sense but why do we have a sigma for H I don't think don't necessarily have it to have it it's just yeah here I'm having an external linearity there but yeah you don't necessarily need it yeah if you don't have that Sig wouldn't just lar layer yeah so it's better to have linearity yeah but you know this is just for illustration purposes you could imagine different architectures different doesn't have to be a sigmoid could be a Ru could be other things it's just yeah um so over here you have three rows in your a matrix like are we trying to predict three separate features for why I thought it was just one probility um I have oh I see what you mean so this is just like the there's basically a hidden Vector H which could have it's not necessarily a scalar that hidden Vector is then passed to a logistic regression classifier and so it's then mapped down to a scalar through this uh expression here which might be so there's a DOT product there right and so this you know in principle all works but you can kind of see the issue is that you are basically we're separately training different models for every pixel which doesn't seem great perhaps there is some common structure at the end of the day we're kind of like solving related problems we're kind of like trying to predict a pixel given part of an image given another given the previous part of the image and so there might be opportunity for doing something slightly better by tying the weights to reduce the number of parameters and as a by product speed up the computation and so what you can do here is you can basically tie together all these matrices A2 A3 A4 that you would have if you were to think of them as separate uh classification problems what you can do is you can basically just have a single Matrix and then you kind of like tie together uh all this uh the the weights that you use in the prediction Problems by basically selecting the corresponding slice of some bigger Matrix right so before we had this the first Matrix that we used to call A2 and then A3 and then A4 and they were completely you know decoupled you could choose any values you want for the entries of those matrices what you can do here is you can basically choose the first row the First Column to take some uh set of values and then you're going to use that for all the subsequent kind of like classification problems so you're equivalently kind of like trying to extract the same features about the first about X1 and then you're kind of like going to use them uh throughout all the classification problems that you have in the in the you know when you're trying to model the full image yeah um is reducing overfitting also motivation for this yeah so the question is reducing over over is you know overfitting also potentially a concern yeah reducing the number of parameters is also good uh for uh overfitting issues tying together the classification problems might be good uh you might learn a better solution that generalizes better and as we see it also makes it faster I'm curious like empirically it makes more sense to invert your X's you're saying like you always depend the same way based off the last thing you predict instead of like saying the n term should have the same weight for X1 for example uh what's the suggestion sorry I didn't quite so I guess over here we're always multiplying the first W1 X1 W1 X1 for every single x i we're predicting instead of that would it make more sense to invert your X's so that W1 looks at X IUS one W2 looks at X IUS 2 and so on and so forth you're just looking at one preceding entry two preceding entries and so on oh that could also work yeah that's a different kind of parameterization that is more like a convolutional kind of thing I would say that we're going to talk about that too this is what they did in this particular model a question about notation what is the w dot uh comma smaller than 9 mean what is the DOT it's just D Matrix yeah I don't think yeah probably didn't need to dot or I guess it means the piece of a bigger Matrix I think that was the intended notation but yeah you got the idea sure uh and the good news is that this can reduce the number of parameters so if you have size d uh for this hidden Vector H that you're using to uh make the predictions how many parameters do you need 2 * uh it's not longer quadratic in N that's the kind of big takeaway before we had something that was quadratic in N uh now it's basically linear because there's b a single Matrix that you have to store and then you canate reuse it all the time right um so that's good um now the other advantage that you have with this kind of model is that you can evaluate probabilities more efficiently uh because basically whenever you go remember if you want to evaluate the probability of a data point you have to evaluate all these conditionals so you have to go through every conditional and you basically have to evaluate the kind of computation if there is no structure on the matrices and you have to redo the computation because there is no nothing shared but if you have some sh shared structure and you can kind of like reuse the computation so if you've already computed this dot product this product here this Matrix Vector product here and then if you are adding an extra uh column then you you can reuse the computation that you've done before you can just add in an extra call is the is factor C also shared amongst all the hidden layers yeah I guess it could be or it doesn't have to be I think you could you could make it either way yeah I think I actually forgot to because it didn't fit but yeah you would have there should be a c and you could change it yeah are the um W columns like updated in each step so like in the fourth step here it also updates the first and and second column uh what do you mean update like minus setting was with the weight Matrix you basically you build it um column by column and but you try to learn right like over seeing like many examples so I was wondering like as a model learns it basically updates also in every step all the previous columns that it has learned right yeah yeah yeah so it's all tied together and then we haven't talked about how you would do learning but yeah so then you can see that kind of like the First Column matters for all the prediction tasks so you would be able to learn it you would get some signal from every sing learning problem yeah yeah yeah just to clarify um in this model you are sharing weights uh right yeah and does that uh imply any like assumptions you're making about the data you're looking at there is an assumption again you're kind of saying that these conditional probability tables we could could be arbitrary somehow can be captured by prediction models that have this sort of structure uh so somehow that there is some relationship between the way you would predict one pixel different pixels in an image whether or not it's reasonable it's it's it becomes an empirical question uh I think I have the results here and it tends to work significantly better than let's say uh the previous logistic regression model so it does seem like this kind of structure helps modeling natural images or toy kind of images like amist um and so here you can see some examples you have amist binarize the oh no actually I don't have I don't have the samples from here what you have here is samples from the model train on Mist on the left and the conditional probabilities corresponding to the samples on the right so remember that when you generate samples Auto regressively you actually get probabilities for each pixel given the previous ones and then you sample from them to generate to actually pick a value and so the images on the left are binary 01 the images on the right are kind of soft because for every pixel you got a number between 0o and one that then you sample from to generate a color in this case 01 and so you can see they kind of look a little bit better because they are a little bit more soft but that you can see that it's doing a reasonable job at capturing the the structure of these images what are the numbers on the like on right uh on the right a table look just almost exactly like that one why aren they why don't they just create some variation I mean some other kind of they are so the numbers are corresponding to the to the samples that you see so basically what this is saying is that what what you would actually do when you sample is you would take the first pixel you have a probability then you plot it on the right then you sample a value from that on the left then you go based on that value based on the actual binary value you come up with a probability for the second pixel which is just a number between Z and one you plot it on the Right image then you sample from it and you keep going so the right is notes doesn't come from like the things what factor learning yeah yeah it does it does so it's basically these numbers the predicted probabilities for every pixel which are the X at I so the probability that that pixel is on or off and then but they are matching so that's why look the same because the sample that you see on the left is what you get by by sampling from those distributions yeah I am noticing that like it is agnostic of what the label should be is that like the right call to make for Generation so the question is should we take advantage of the fact that maybe we have labels for the data set and so we know that you know there is different types of digits that there is maybe 10 digits and then we want to uh you know take advantage of that so here I'm assuming that we don't have access to the the label why if you had access to the label y you could imagine trying to learn a joint distribution between X and Y and perhaps you would get a better model or perhaps you can assume you don't have that kind of structure you just learn a model and you can kind of try to use the model to see whether it indeed figured out that there are 10 clusters of data points and that you know there's a bunch of data points that kind of have this shape of a that look like a c kind of like an oval and that's a zero and that's the kind of third point of how do you get features out of these models like presumably if you have a model that can generate digits that have the right structure and it generates them in the right proportions it has learned something about the structure of the images and what they have in common and so that was kind of like the third point of getting features and supervis learning we'll talk about how to do that but uh yeah there's two ways to see it you can either do it unsupervised or if you have access to the label then perhaps you can include it into into the model you can do conditional generation or you can jointly learn a distribution over X and Y yeah so in this case when you sample you can get any one of the 10 digits well if the model does well yes uh you know for example you to check whether the model is doing a good job you could try to see what is the proportion like if in the original training set all the images come they're uniformly you know you see an equal proportion of the different digits then you apply an Mist classifier to your samples and you can see does it generate uh digits in the right proportion if it doesn't then there's probably something wrong with the model if it does it's doing something right whether it's correct or not it's it's it's hard to say so like here it seems like you're injecting the stronger prior into the model so if you had an infinite data set would you expect the original approach to per better than this one meaning the that one's less structure imposed by us right so the representation it should learn should theoretically be richer that one is actually more structure like you're imposing like you have less parameters is less flexible uh if you had infinite data and infinite compute the best thing would be conditional probability tables ban Network that one would be able to in principle capture any relationship with infinite data you would be able to learn that table that would give you perfect module overfitting I mean but if you have infinite data you don't have to worry about that either uh something so on the left picture is the the actual samples generated from the model the right is we somehow code the conditional probabilities into a scale yeah just between zero one like the conditional probabilities would be numbers in between zero and one and it's just the gray scale yeah cool so that's the N um now you might wonder what do you do if you want to model uh color images let's say so if uh the B the variables are no longer binary but if they can take let's say k different values how do you maybe pixel intensi is ranging from 0 to 255 how do you do it now what you need to do is the output of the model has to be a categorical distribution over however many different values the random variables can take so you can basically do the same thing you first get this kind of hidden vector or latent representation H and then you instead of applying some kind of mapping it down to just the the parameters of a berol random variable you can use some kind of soft Max output layer to map it down to a vector of um if you have K different outputs that you care about a vector of K probabilities uh Pi i1 through p i k which basically would represent the probability that the I random variable should take one of the K different values that the random variable can take and uh that's the natural generalization of the sigmoid function we had before it's just one way to take K uh numbers which are not necessarily non- negative and they might not be normalized and it's just a way to normalize them so that they they become uh a valid probability distribution so specifically you just do something like this if you have a vector or arbitrary numbers you apply the soft Max operation it produces another Vector you apply an exponential to every component to make sure it's not negative and then you divide by the sum of these exponentials which is basically making sure that uh the entries are normalized so that it's if you sum the probabilities of all the possible things that can happen you get one and uh so natural generalization of what we had before now you might wonder what do you do if you want to model continuous data so maybe you have you're dealing with speech and it's more n it's not very natural to discretize the the I mean even for images perhaps you don't want to discretise the the random variables and you want to model them as continuous random variables so the solution is basically again use the same architecture but now the output of the neural network will be the parameters of some continuous distribution so it's no longer the parameter of a ber the parameters of a categorical it could be the parameters of a gaussian or a logistic or some U continuous probability density function that you think should work well for your data set and so for example one thing you could do is you could use a mixture of K Gauss so what you have to do is you need to make sure the output of your neural network gives you the parameters of K different GS uh which are then mixtured together let's say uniformly to obtain a relatively flexible kind of probability density function like you see here an example where there's three Gauss with different means and different standard deviations then you combine them together and you get a nice kind of GRE uh red curve where you're kind of allowed to move the probability mass and you're allowed to say maybe you know there is two different uh values that the random variable can take two modes one here and one here and you're allowed to move the probability Mass around by changing the mean and the standard deviation of the gut in this Cas have like 2 vales so I think I have the the the more precise thing here so you would say the conditional probability of XI given all the previous values is a mixture of K gos each one of them having a different mean and a different standard deviation and as usually you have to to basically use the neural network to get the parameters of this distribution so in this case as was suggested you could use the same trick and then as an output layer you can no longer use a soft Max or a sigmoid you have to use something else that gives you the parameters of these random variables and so you need 2K numbers you need K means and you need K standard deviations and you know the uh I guess you know you need to be careful about if you use depending on how you parameterize like if you parameterize a variance then has to be no negative but that's relatively easy to enforce okay now as a way to kind of like get a deeper understanding of what these kind of models do you might notice that they look a lot like out encoders like if you look at this kind of computation graph that I have here where you have the the data point X1 X2 and X3 and X4 that is been mapped to this predicted probability X1 hat X2 hat X3 hat and so forth it kind of looks a little bit like an out encoder where you take your input X and then you map it to some kind of predicted uh reconstruction of the input and so more specifically an out encoder is just a a model that is often used again in unsupervised learning it has two components it's an encoder takes a data point and Maps it to some kind of latent representation and then uh for example it could be again a simple neural networks a two layer net like this and then there is a decoder whose job is to try to invert this transformation and the job of the decoder is to take the output of the encoder and map it back to the original data point and uh you know in this case in this graph that I have here it could be another neural network that takes the output of the encoder and Maps it back to some reconstruction of the input and uh the loss function that you would use would be some kind of reconstruction loss so you would kind of like try to train the encoder and the decoder so that uh for every data point these kind of when you apply the decoder to the encoder you get back something close to the original data point so depending on whether the data is discreet or continues this could be something like a square loss where you try to make sure that at every coordinate your reconstructed I variable is close to the original one if you have discrete data it's more like does the model is the model doing a good job of predicting uh the value for the I uh let's say in this case it's binary here or the I random variable that I'm actually observing so if the I random variable is true is one is the model giving me a high probability for for the value one right not super important but kind of like this is how you would you would try to learn the decoder and the encoder so that they they they satisfy this condition and of course there is a trivial solution that is the identity mapping so if the uh encoder is just an identity function and the decoder is some identity function then you you do very well at this and it's not what you want typically so typically you would constrain the architecture somehow so that it cannot learn an identity function but that uh has kind of like the flavor of what we're doing uh with this sort of like Auto regressive models we're taking the data point and then we're trying to use parts of the data point to reconstruct itself or we fit it through these networks and then we output these predicted values and if you were to think about how you would train one of these models by let's say maximum likelihood you would get losses that are very similar to this you would want to you know if you were to train these logistic regression classifiers you would get something very similar to this where you would try to predict the value that you actually see in the in the data point I'm just trying to understand put it in coder decoder kind of mechanism is it uh is it the main point for encoder uh is just to kind of com uh compress all the previous informations into a very low dimensional kind of like is that the main yeah yeah so the question is why are what are out what are out encoders used for yes the the typical one typical use case would be to learn a compressed representation of the of the data somehow if you can do this you know maybe you force the output dimension of of the encoder to be small and then in order to do a good job at reconstruction it has to capture the key factors of variation in the data and so you can kind of think of it as some sort of like nonlinear PCA kind of thing that will try to discover uh structuring the data in an unsupervised way yeah can we do sampling when TR the the question is can we do sampling with an out encoder no an out encoder is not quite a generative model so these two things not quite the same but they are related and that's what we're going to see next um so yeah this was coming up you know typically you would train this to do representation learning try to find good representations uh what is exactly the you know if you think about kind of like what we just said now if you have an out encoder there is not it's not really a generative model like how do you generate data from an outter coder we just re but what's the input to the so the the suggestion is okay let's throw away the encoder let's just use the decoder what do you feed into the decoder to generate data some just handcrafted effect yeah that's the solution for a variational out encoder actually so the variational out encoder will be let's try to learn a simple generative model to feed inputs fake inputs to to your to your decoder uh and so you can kind of fake the the process and you can use it to generate so that's the variational out encoder solution I will talk about later but if you just have you know there's not an obvious way to generate the inputs to the decoder unless you have data but at that point you're not really sampling right could you like feable yeah that's the VA solution basically that we'll talk about yeah what if you like add a regularization term that for as your hidden representation to just look like a gausian or something like that yes so again that's the solution imposed by the that's basically a variational out encoder literally a variational out encoder is this plus what you suggested forcing the latent representations to be distributed according to a simple distribution a gausian and if that happens to work well then you can sample from that distribution fit the inputs to the to the decoder and that works but you know that requires a different kind of regularization the relationship here is that uh you know although this two things look similar it's not quite the same and the reason is that uh you know we cannot get a generative model from an out encoder because somehow we're not putting enough structure on this kind of computation graph and there is not an ordering remember that to get an auto regressive model we need an ordering mini chain rule so one way to actually get uh or to connect these two things is to enforce an ordering on the out encoder and if you do that you get back basically an auto regressive model and so basically if uh you're willing to put constraints on the weight matrices of these neural networks so that there is a corresponding basically evasion Network or or chain rule factorization then you can actually get an an outo regressive model from an out encoder and the idea is that basically if you think about it the issue is that we don't know what to fit to the decoder so somehow we need a way to generate the data sequentially to fit it into this decoder that we have access to and so one way to do it is to kind of like set up the computation graph so that the first reconstructed random variable does not depend on any of the inputs if that's the case then you can come up with the first output of this decoder yourself because you don't need any particular input to do that and then you can feed your predicted first random variable into then let's say that the you know at generation time then you don't need it now if you can it's fine if the predicted value for the second random variable depends on X1 that's fine because we can make up a value for X1 then we can fit it into the computation and we can predict a value for X2 then we can take this value we can take the first two fit them into the outter quar kind of thing and predict a value for X3 and we can keep going and it's the same thing as an auto regressive model so if you look at this kind of computation graph you can see that the predicted value for X1 depends on all the inputs in general and so you know if you look at the arrows all the inputs have an effect on the first predicted value and so that's a problem because we cannot get an auto regressive model if we do it that way but if we somehow mask the weights in the right way we can get an auto regressive model and then as a bonus then we have a single neural network that does the whole thing so it's not like before that we had the different classification models or that they were tied together somehow uh if uh we can do this then it's a single neural network that in a single forward pass can produce all the parameters that we need I was wondering in some tasks for example this digit task we earlier discussed um is there not a risk of the model learning just how to shift it by like one pixel or something uh not OB obvious that you can just shift because the I mean you're not you cannot cheat right so you cannot look at the next Pi they cannot you can only use there's gonna you have to pick an ordering and you have to predict yes but you can like begin with the L and then begin putting like the pixels to the left of it for example but what do you put you haven't seen them they haven't seen the right pixel so you don't know exactly what to copy right no no you do because like if we before order goes left right you will know what the uh pixel in the input image to the left of it is so you can just put that uh and you can draw like a black line on the left so like or I was wondering if or metric need to to like really prevent that from happening no you don't you don't need to prevent that from happening and partially it's because these B would then be trained by maximum likelihood so and that's a separate thing that we're going to talk about how to evaluate so that that solution might not actually give you a good score from the perspective of a learning algorithm even though maybe the samples would look fine uh but yeah I haven't seen that happening in practice so okay the bonus would be single pass you can get everything as opposed to and different passes and uh the way you do it is to basically mask right so what you have to enforce is some kind of ordering and so you basically have to take the general computation graph that you have from an out encoder and you have to mask out some connections so that there is some ordering that then you can use to generate data and the ordering can be anything uh so for example you can pick an ordering where we choose this X2 X3 and X1 which corresponds to the chain rule factorization of probability of X2 X3 given X2 and X1 given the other two and then what you can do is you can mask out some connections in this neural network so that X the Reconstruction for X2 does not depend on any of the inputs and then you can mask out the parameters of this neural network so that the parameter uh of x3 is only allowed to depend on x2 and uh uh the parameter of X1 is allowed to depend on everything just like according to the chain rule factorization and so one way to do it yeah so that's I think what I just said one way to do it is you can basically keep track for every hidden for every unit in your your hidden layers you can basically keep track of what inputs it depends on and so what you could do is you could pick for every unit you can pick an integer I and you can say I'm only going to allow this run this unit to depend on the inputs up to the I index I and so you can see here that uh you know there's this 2 one 2 two this B basically means it's only allowed to depend for example this unit is only allowed to depend on the unit one and two this unit here is labeled one so it's only allowed to depend on the first input according to the ordering which is X2 and then you basically um recursively ask add the masks to preserve this invariant so when you go to the next layer and you have a node that is labeled one then you are only allowing a connection to the nodes that are labeled uh up to one in the previous layer and the way you achieve it is by basically masking out and setting to zero basically some of the elements of the of the Matrix that you would use for that layer of the neural network and if you do that then you preserve this invariant and you can see that indeed uh the parameter of X the probability of X2 which is the output the second output of the neural network does not depend on any input which is what we want for a chain rule factorization and if you look at the parameter of x3 which is the third output you'll see that if you follow all these paths they should only uh depend on basically the second on x2 which is the variable that come before it in the ordering and so by maintaining this invariant you get out encoder which is actually an auto regressive model you are essentially forcing the model not to cheat by looking at Future outputs to predict uh and you can only use past output past inputs to predict future outputs essenti and this is one architecture that would enforce uh this kind of invariant yeah sorry is it something that's like done during training or do you like train an auto encoder and then mask certain generation this is done during training so you have to during train like you basically have to set up an architecture that is masked so that uh it's not allowed to cheat while you train because if you didn't mask then it could uh when trying to predict the X2 you just look at the actual value and you use it right and so this is very similar if you seen language models you also have to mask to basically not allow it to look into future uh tokens to to make a prediction if you're allowed to look into the future to predict uh tokens then it's going to cheat and you're not going to do the right thing and this is the same thing uh at the level of the comput different computation graph that basically achieves the same sort of result and the benefits of single passes during training time yes good question yeah yeah so the question is is the benefit only a training time or INF time so the benefit is only at training time because at inference time you still have the sequential thing that you would have to come up with a value for for the first variable and fit it in so it will still have to be sequential that's unavoidable every outo regressive model has that kind of annoying uh flavor basically how do you choose the so the recipe in this paper Is Random so you mean the the the the the value or the the ordering oh the ordering that's also very hard I think uh you know if you have something where you know the structure and you know again that there is some causal or there is time maybe there is a reasonable way of picking an ordering otherwise you would have to either choose many orderings if you have basically have a mixture uh choose one at random but there is not a good way of basically selecting an ordering there is actually research where people have been trying to learn how to regressive models and an ordering so you can like Define a family of models where you can search over possible orderings and search over factorizations that over that ordering but you can imagine there's like M factorial different orderings to search over and it's discrete so it's a very tough kind of optimization problem to find uh the right ordering if one is not dependent on anything how does the model output one there should output it should only Al two three right should be uh you would have to I mean depending on the loss fun it cannot depend on anything but you can still basically make a a guess based on no evidence so you would basically choose the prior right so if the let's say the second variable is always true then you would still depending on the training objective you would still try to choose an output here it's a constant but you would try to match basically the most likely value in the training set or if you have a proper scoring rule then would try to match the distribution that you see in the training set depending on the loss function you still try to choose a a value that makes sense but it's fixed so you can only choose one and so you can't do much but you're still you would still try to do your best to to to capture the data depending on the training loss yeah are there redundancies like in the second to last layer there's two uh nodes which just have one as an input so is it kind of redundant to have multiple nod just have one in uh I mean the weights are different so even though there is multiple nodes that have only one an input they might be extracting different features for that input so it's not necessarily predominant I would say so the objective of the auto is to deconstruct yes so how do you reconcile the loss function it's pring one thing at how do you like make the function reconstruction yeah so the function would be the ones that we have here uh which uh would be you know basically you would try to make the predictions close to what you have in the data so the loss function wouldn't change it's just that the way you make predictions is you're not allowed to cheat for example you're not allowed to look at XI when you predict XI and you're only allowed to predict it based on previous variables in some ordering and it turns out that that would be exactly the same loss that you would have if you were to train the AO regress model it depends on kind of the model family that you choose but if you have logistic regression models it would be exactly the same laws for example in your last layer like you said you pick each of the I guess the number of times it looks previously randomly so if you happen to pick 222 how would you predict the first entry after that yeah so you would basically be you're not allowed many connections and you would do a pretty bad job because you you would be less uh Flex ible that you could be it would still be a valid model uh it wouldn't be a good one I guess so that's why people often have kind of like an ensemble of these mods where you have multiple masks and you just do it that way yeah cool um let's see now an alternative way to to approach this is to um use uh RNN some kind of like recursive style Compu ation to basically predict uh the next uh random variable given the previous ones According to some ordering right at the end of the day this is what the key problem whenever you build an auto regressive model is solving a bunch of coupled kind of prediction problems where you predict a single variables single variable given the other variables that come before it in so moring and uh the issue is that this history kind of keeps getting longer so you're conditioning more and more things and uh rnns are pretty good at or or it's one way to kind of like handle this this uh kind of situation and uh kind of like try to keep a summary of all the information of all the things you've conditioned on so far and recursively update and so a computation graph would look something like this so there is a summary H let's say h of t or h of t + one which basically is a vector that summarizes all the inputs up to that time and you initialize it somehow based on some initialization and then you recursively update it by saying the new summary of the history is some transformation of the history you have seen so far and the new input for that times step XT + one and maybe you know this is one way to to kind of implement it you do some kind of linear transformation of HT XT + one you apply some nonlinearity and that gives you the new uh summary up to time t + one and then what you can do is just like what we've done so far is then you use H to basically or you transform it Ag and you map it to either let's say uh a category the parameters of a categorical random variable or a berol random variable or a mixture of gaussians whatever it is that you need to predict uh you do it through uh well I guess you probably also would need some nonlinearities here but there is some output which is the thing you use for prediction which is going to depend only on this uh history vector or the summary Vector of all the things you've seen so far and uh the good thing about this is that uh basically it has a very small number of parameters like regardless of how long the history is there is a fixed number of learnable parameters which are all these matrixes matrices that you use to recursively kind of like update your summary of all the information you've seen so far and so it's constant with respect to when remember we had the things that were linear in N we quadratic in N this thing is actually constant the mees are fixed and you just keep applying them exactly it's it's extreme weight sharing and that you try to do everything throughout a cion yes here we're imposing a mark assumption on the addition probabilities this is still not so the question is is this a mark of assumption there not a mark of assumption in the sense that if you think about XT is not just a function of the previous XT minus one right uh it still depends on all the past random variables in again not entirely General way so you can only capture the dependencies that you can write down in terms of this sort of recursion and so you know it's not uh it's definitely not a mark of assumption this is that if you think about the computation graph it does depend on all the previous inputs and uh so this is an example uh of how you would use this kind of model to model text so the idea is that in this simple example we have only let's say four different characters h e l and O and then uh you would basically encode them let's say using some kind of one hot encoding so H is one0 0 e is 0 1 0 0 and so forth and then as usual you would use some kind of Auto regressive factorization so you write it down this case from the ordering is the one from left to right so you you write the probability of choosing the first character in your piece of text and the probability of choosing the second character given the first one and so forth and uh what you would do is you would uh basically obtain these probabilities uh from the hidden layer of this recurrent neural network so you have these hidden layers that are updated according to that recursion that I show you before and then you would use the hidden layer you would uh transform it uh into an output layer which is just four numbers and then you can take a soft Max to basically map that to uh for non negative numbers between 0 and one the Su to one and so in this case for example uh we have a hidden layer and then we apply some linear transformation to get these four numbers and uh we're trying to basically choose the values such that the second entry of the vector is very large because that would put a lot of probability on the second sort of uh possible character which happens to be e which is the one we want for the second position and so then when you train these models the game is to choose values for these matrices so that you know let's say you maximize the probability of observing a particular data data point or data set um and yeah so again the the kind of like key thing here is that you have a very small number of parameters and then you use the hidden state of the neural of the of the RNN to get the conditional probabilities that you need in an AO regressive factorization and uh and then and then you can see kind of like the recursion then you would compute the next hidden state by taking the current history then every you know the new character that you have access to you update your recursion and you get a new hidden State you use that hidden state to come up with a vector of predicted probabilities for the next character and so forth it's the same Machinery as before but instead of having multiple kind of like linear reg or logistic regression classifiers we have a bunch of classifiers that are tied together by this recursion and uh the pro is that you can apply to sequences of arbitrary length and it's actually in theory at least rnns are pretty General in the sense that uh they are they can essentially represent any computable function at least in theory in practice uh they are tricky to learn and uh you know you still need to pick an ordering which is always a problem for AO regressive models the key thing the key issue with this sort of like rnns is that they requires they're very slow during training time uh because you have to unroll this recursion to compute the probabilities and uh that's a problem but I'll just show you some examples and then I think we can end here it actually works reasonably well like if you take a simple three layer RNN and you train it on the all the works of Shakespeare at the Character level so it's literally what I just showed you just a three layer RN um and then you sample from the model you can get things like this which has a little bit of the flavor of sh X I guess not I if you think about this is at the Character level you know it's this literally generating character by character it's actually pretty impressive like it learns it needs to learn which words are valid and which ones are not Grammar punctuation like it's pretty impressive that a relatively simple model like this working at the level of characters can do can do like this you could train it on Wikipedia and then you can sample and you can just you can make up fake Wikipedia Pages like this one on the Italy that conqu conquering India really interesting made up stuff but again you can see pretty interesting how it it's able to has the right markdown syntax and it's closing the brackets after opening them which has to remember through this single hidden state right that it's carrying over uh yeah so you know he even making up links to to for for this madeup facts that it generates and uh you know train it on baby names and then you can sample from the model you can get new new names so yeah it's a it's a pretty you know surprise works surprisingly well I guess the the main issue that hopefully then maybe I guess we'll go over it next time that the reason this is now used for state-of-the-art language models is that you have this bottl that you need to capture all the information up to time T in a single Vector which is a problem and the sequential evaluation that's the main bottleneck so it cannot take advantage of modern kind of gpus because in order to compute the probabilities you really have to unroll the computation and you have to go through it step by step and that's kind of like the the the main challenge"}]}